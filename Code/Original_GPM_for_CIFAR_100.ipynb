{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Original GPM for CIFAR_100.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6641d1bdce4a4d83bf86bad0e7a351ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c0e640dbf104de68bd514e3ccab4ef4",
              "IPY_MODEL_f4cba9a8646b46aba3e8cdc5ff04111b",
              "IPY_MODEL_331501410aae4ee9bfa956fcebbf622a"
            ],
            "layout": "IPY_MODEL_98cf1344ea854e4187f9a7c36b6b1556"
          }
        },
        "5c0e640dbf104de68bd514e3ccab4ef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ce9b6b8968940f0a9bd94fe68945104",
            "placeholder": "​",
            "style": "IPY_MODEL_79cc41807a32493c83e5c0c7c0bdde42",
            "value": ""
          }
        },
        "f4cba9a8646b46aba3e8cdc5ff04111b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39bc7de8fb844ccfb63a590961546407",
            "max": 169001437,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11a20b0ea4674f089c78e1271e2e563b",
            "value": 169001437
          }
        },
        "331501410aae4ee9bfa956fcebbf622a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_965b9a03c59c435081897f2a2d4ad1e8",
            "placeholder": "​",
            "style": "IPY_MODEL_6a2825be3634409db49d0e2f9453303b",
            "value": " 169001984/? [00:05&lt;00:00, 32641992.38it/s]"
          }
        },
        "98cf1344ea854e4187f9a7c36b6b1556": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ce9b6b8968940f0a9bd94fe68945104": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79cc41807a32493c83e5c0c7c0bdde42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39bc7de8fb844ccfb63a590961546407": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11a20b0ea4674f089c78e1271e2e563b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "965b9a03c59c435081897f2a2d4ad1e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a2825be3634409db49d0e2f9453303b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne2fTmpjjIiQ",
        "outputId": "9f73c80b-f88c-498a-fafd-c77222327640"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 12 01:50:49 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8    27W / 149W |      3MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bBuLoWAo0i0"
      },
      "outputs": [],
      "source": [
        "import os,sys\n",
        "import os.path\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import random\n",
        "import pdb\n",
        "import argparse,time\n",
        "import math\n",
        "from copy import deepcopy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cf100_dir = '/content/drive/MyDrive/CSN-300 Lab based project Advanced/Gradient Projection Memory for continual learning/data'\n",
        "file_dir = '/content/drive/MyDrive/CSN-300 Lab based project Advanced/Gradient Projection Memory for continual learning/data/binary_cifar100'"
      ],
      "metadata": {
        "id": "Oq3gRxn8ZYzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get(seed=0,pc_valid=0.10):\n",
        "    data={}\n",
        "    taskcla=[]\n",
        "    size=[3,32,32]\n",
        "\n",
        "    if not os.path.isdir(file_dir):\n",
        "        os.makedirs(file_dir)\n",
        "\n",
        "        mean=[x/255 for x in [125.3,123.0,113.9]]\n",
        "        std=[x/255 for x in [63.0,62.1,66.7]]\n",
        "\n",
        "        # CIFAR100\n",
        "        dat={}\n",
        "        dat['train']=datasets.CIFAR100(cf100_dir,train=True,download=True,transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean,std)]))\n",
        "        dat['test']=datasets.CIFAR100(cf100_dir,train=False,download=True,transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean,std)]))\n",
        "        # dat['train'] = datasets.CIFAR100(cf100_dir,train=True,download=False,transform=transforms.Compose([transforms.ToTensor()]))\n",
        "        # dat['test']  = datasets.CIFAR100(cf100_dir,train=False,download=False,transform=transforms.Compose([transforms.ToTensor()]))\n",
        "        for n in range(10):\n",
        "            data[n]={}\n",
        "            data[n]['name']='cifar100'\n",
        "            data[n]['ncla']=10\n",
        "            data[n]['train']={'x': [],'y': []}\n",
        "            data[n]['test']={'x': [],'y': []}\n",
        "        for s in ['train','test']:\n",
        "            loader=torch.utils.data.DataLoader(dat[s],batch_size=1,shuffle=False)\n",
        "            for image,target in loader:\n",
        "                n=target.numpy()[0]\n",
        "                nn=(n//10)\n",
        "                data[nn][s]['x'].append(image) # 255 \n",
        "                data[nn][s]['y'].append(n%10)\n",
        "\n",
        "        # \"Unify\" and save\n",
        "        for t in data.keys():\n",
        "            for s in ['train','test']:\n",
        "                data[t][s]['x']=torch.stack(data[t][s]['x']).view(-1,size[0],size[1],size[2])\n",
        "                data[t][s]['y']=torch.LongTensor(np.array(data[t][s]['y'],dtype=int)).view(-1)\n",
        "                torch.save(data[t][s]['x'], os.path.join(os.path.expanduser(file_dir),'data'+str(t)+s+'x.bin'))\n",
        "                torch.save(data[t][s]['y'], os.path.join(os.path.expanduser(file_dir),'data'+str(t)+s+'y.bin'))\n",
        "\n",
        "    # Load binary files\n",
        "    data={}\n",
        "    # ids=list(shuffle(np.arange(5),random_state=seed))\n",
        "    ids=list(np.arange(10))\n",
        "    print('Task order =',ids)\n",
        "    for i in range(10):\n",
        "        data[i] = dict.fromkeys(['name','ncla','train','test'])\n",
        "        for s in ['train','test']:\n",
        "            data[i][s]={'x':[],'y':[]}\n",
        "            data[i][s]['x']=torch.load(os.path.join(os.path.expanduser(file_dir),'data'+str(ids[i])+s+'x.bin'))\n",
        "            data[i][s]['y']=torch.load(os.path.join(os.path.expanduser(file_dir),'data'+str(ids[i])+s+'y.bin'))\n",
        "        data[i]['ncla']=len(np.unique(data[i]['train']['y'].numpy()))\n",
        "        if data[i]['ncla']==2:\n",
        "            data[i]['name']='cifar10-'+str(ids[i])\n",
        "        else:\n",
        "            data[i]['name']='cifar100-'+str(ids[i])\n",
        "\n",
        "    # Validation\n",
        "    for t in data.keys():\n",
        "        r=np.arange(data[t]['train']['x'].size(0))\n",
        "        r=np.array(shuffle(r,random_state=seed),dtype=int)\n",
        "        nvalid=int(pc_valid*len(r))\n",
        "        ivalid=torch.LongTensor(r[:nvalid])\n",
        "        itrain=torch.LongTensor(r[nvalid:])\n",
        "        data[t]['valid']={}\n",
        "        data[t]['valid']['x']=data[t]['train']['x'][ivalid].clone()\n",
        "        data[t]['valid']['y']=data[t]['train']['y'][ivalid].clone()\n",
        "        data[t]['train']['x']=data[t]['train']['x'][itrain].clone()\n",
        "        data[t]['train']['y']=data[t]['train']['y'][itrain].clone()\n",
        "\n",
        "    # Others\n",
        "    n=0\n",
        "    for t in data.keys():\n",
        "        taskcla.append((t,data[t]['ncla']))\n",
        "        n+=data[t]['ncla']\n",
        "    data['ncla']=n\n",
        "\n",
        "    return data,taskcla,size"
      ],
      "metadata": {
        "id": "qYc3T2fCXHcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_conv_output_size(Lin,kernel_size,stride=1,padding=0,dilation=1):\n",
        "    return int(np.floor((Lin+2*padding-dilation*(kernel_size-1)-1)/float(stride)+1))"
      ],
      "metadata": {
        "id": "RayVK9brXXXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self,taskcla):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.act=OrderedDict()\n",
        "        self.map =[]\n",
        "        self.ksize=[]\n",
        "        self.in_channel =[]\n",
        "        self.map.append(32)\n",
        "        self.conv1 = nn.Conv2d(3, 64, 4, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64, track_running_stats=False)\n",
        "        s=compute_conv_output_size(32,4)\n",
        "        s=s//2\n",
        "        self.ksize.append(4)\n",
        "        self.in_channel.append(3)\n",
        "        self.map.append(s)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(128, track_running_stats=False)\n",
        "        s=compute_conv_output_size(s,3)\n",
        "        s=s//2\n",
        "        self.ksize.append(3)\n",
        "        self.in_channel.append(64)\n",
        "        self.map.append(s)\n",
        "        self.conv3 = nn.Conv2d(128, 256, 2, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(256, track_running_stats=False)\n",
        "        s=compute_conv_output_size(s,2)\n",
        "        s=s//2\n",
        "        self.smid=s\n",
        "        self.ksize.append(2)\n",
        "        self.in_channel.append(128)\n",
        "        self.map.append(256*self.smid*self.smid)\n",
        "        self.maxpool=torch.nn.MaxPool2d(2)\n",
        "        self.relu=torch.nn.ReLU()\n",
        "        self.drop1=torch.nn.Dropout(0.2)\n",
        "        self.drop2=torch.nn.Dropout(0.5)\n",
        "\n",
        "        self.fc1 = nn.Linear(256*self.smid*self.smid,2048, bias=False)\n",
        "        self.bn4 = nn.BatchNorm1d(2048, track_running_stats=False)\n",
        "        self.fc2 = nn.Linear(2048,2048, bias=False)\n",
        "        self.bn5 = nn.BatchNorm1d(2048, track_running_stats=False)\n",
        "        self.map.extend([2048])\n",
        "        \n",
        "        self.taskcla = taskcla\n",
        "        self.fc3=torch.nn.ModuleList()\n",
        "        for t,n in self.taskcla:\n",
        "            self.fc3.append(torch.nn.Linear(2048,n,bias=False))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        bsz = deepcopy(x.size(0))\n",
        "        self.act['conv1']=x\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool(self.drop1(self.relu(self.bn1(x))))\n",
        "\n",
        "        self.act['conv2']=x\n",
        "        x = self.conv2(x)\n",
        "        x = self.maxpool(self.drop1(self.relu(self.bn2(x))))\n",
        "\n",
        "        self.act['conv3']=x\n",
        "        x = self.conv3(x)\n",
        "        x = self.maxpool(self.drop2(self.relu(self.bn3(x))))\n",
        "\n",
        "        x=x.view(bsz,-1)\n",
        "        self.act['fc1']=x\n",
        "        x = self.fc1(x)\n",
        "        x = self.drop2(self.relu(self.bn4(x)))\n",
        "\n",
        "        self.act['fc2']=x        \n",
        "        x = self.fc2(x)\n",
        "        x = self.drop2(self.relu(self.bn5(x)))\n",
        "        y=[]\n",
        "        for t,i in self.taskcla:\n",
        "            y.append(self.fc3[t](x))\n",
        "            \n",
        "        return y"
      ],
      "metadata": {
        "id": "Gw5MR7RLXY1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(model):\n",
        "    return deepcopy(model.state_dict())"
      ],
      "metadata": {
        "id": "_NpFNrwIXroX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_model_(model,state_dict):\n",
        "    model.load_state_dict(deepcopy(state_dict))\n",
        "    return"
      ],
      "metadata": {
        "id": "QJTTKYeWXvSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_learning_rate(optimizer, epoch, args):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        if (epoch ==1):\n",
        "            param_group['lr']=args.lr\n",
        "        else:\n",
        "            param_group['lr'] /= args.lr_factor"
      ],
      "metadata": {
        "id": "7FZGogWKXwr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(args, model, device, x,y, optimizer,criterion, task_id):\n",
        "    model.train()\n",
        "    r=np.arange(x.size(0))\n",
        "    np.random.shuffle(r)\n",
        "    r=torch.LongTensor(r).to(device)\n",
        "    # Loop batches\n",
        "    for i in range(0,len(r),args.batch_size_train):\n",
        "        if i+args.batch_size_train<=len(r): b=r[i:i+args.batch_size_train]\n",
        "        else: b=r[i:]\n",
        "        data = x[b]\n",
        "        data, target = data.to(device), y[b].to(device)\n",
        "        optimizer.zero_grad()        \n",
        "        output = model(data)\n",
        "        loss = criterion(output[task_id], target)        \n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "gBFRqVgEX5Be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_projected(args,model,device,x,y,optimizer,criterion,feature_mat,task_id):\n",
        "    model.train()\n",
        "    r=np.arange(x.size(0))\n",
        "    np.random.shuffle(r)\n",
        "    r=torch.LongTensor(r).to(device)\n",
        "    # Loop batches\n",
        "    for i in range(0,len(r),args.batch_size_train):\n",
        "        if i+args.batch_size_train<=len(r): b=r[i:i+args.batch_size_train]\n",
        "        else: b=r[i:]\n",
        "        data = x[b]\n",
        "        data, target = data.to(device), y[b].to(device)\n",
        "        optimizer.zero_grad()        \n",
        "        output = model(data)\n",
        "        loss = criterion(output[task_id], target)         \n",
        "        loss.backward()\n",
        "        # Gradient Projections \n",
        "        kk = 0 \n",
        "        for k, (m,params) in enumerate(model.named_parameters()):\n",
        "            if k<15 and len(params.size())!=1:\n",
        "                sz =  params.grad.data.size(0)\n",
        "                params.grad.data = params.grad.data - torch.mm(params.grad.data.view(sz,-1),\\\n",
        "                                                        feature_mat[kk]).view(params.size())\n",
        "                kk +=1\n",
        "            elif (k<15 and len(params.size())==1) and task_id !=0 :\n",
        "                params.grad.data.fill_(0)\n",
        "\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "jybgW9mNX7n2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(args, model, device, x, y, criterion, task_id):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_num = 0 \n",
        "    correct = 0\n",
        "    r=np.arange(x.size(0))\n",
        "    np.random.shuffle(r)\n",
        "    r=torch.LongTensor(r).to(device)\n",
        "    with torch.no_grad():\n",
        "        # Loop batches\n",
        "        for i in range(0,len(r),args.batch_size_test):\n",
        "            if i+args.batch_size_test<=len(r): b=r[i:i+args.batch_size_test]\n",
        "            else: b=r[i:]\n",
        "            data = x[b]\n",
        "            data, target = data.to(device), y[b].to(device)\n",
        "            output = model(data)\n",
        "            loss = criterion(output[task_id], target)\n",
        "            pred = output[task_id].argmax(dim=1, keepdim=True) \n",
        "            \n",
        "            correct    += pred.eq(target.view_as(pred)).sum().item()\n",
        "            total_loss += loss.data.cpu().numpy().item()*len(b)\n",
        "            total_num  += len(b)\n",
        "\n",
        "    acc = 100. * correct / total_num\n",
        "    final_loss = total_loss / total_num\n",
        "    return final_loss, acc"
      ],
      "metadata": {
        "id": "Bf9uamTFX-9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_representation_matrix (net, device, x, y=None): \n",
        "    # Collect activations by forward pass\n",
        "    r=np.arange(x.size(0))\n",
        "    np.random.shuffle(r)\n",
        "    r=torch.LongTensor(r).to(device)\n",
        "    b=r[0:125] # Take 125 random samples \n",
        "    example_data = x[b]\n",
        "    example_data = example_data.to(device)\n",
        "    example_out  = net(example_data)\n",
        "    \n",
        "    batch_list=[2*12,100,100,125,125] \n",
        "    mat_list=[]\n",
        "    act_key=list(net.act.keys())\n",
        "    for i in range(len(net.map)):\n",
        "        bsz=batch_list[i]\n",
        "        k=0\n",
        "        if i<3:\n",
        "            ksz= net.ksize[i]\n",
        "            s=compute_conv_output_size(net.map[i],net.ksize[i])\n",
        "            mat = np.zeros((net.ksize[i]*net.ksize[i]*net.in_channel[i],s*s*bsz))\n",
        "            act = net.act[act_key[i]].detach().cpu().numpy()\n",
        "            for kk in range(bsz):\n",
        "                for ii in range(s):\n",
        "                    for jj in range(s):\n",
        "                        mat[:,k]=act[kk,:,ii:ksz+ii,jj:ksz+jj].reshape(-1) \n",
        "                        k +=1\n",
        "            mat_list.append(mat)\n",
        "        else:\n",
        "            act = net.act[act_key[i]].detach().cpu().numpy()\n",
        "            activation = act[0:bsz].transpose()\n",
        "            mat_list.append(activation)\n",
        "\n",
        "    print('-'*30)\n",
        "    print('Representation Matrix')\n",
        "    print('-'*30)\n",
        "    for i in range(len(mat_list)):\n",
        "        print ('Layer {} : {}'.format(i+1,mat_list[i].shape))\n",
        "    print('-'*30)\n",
        "    return mat_list"
      ],
      "metadata": {
        "id": "B7Eocwy2YBlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_GPM (model, mat_list, threshold, feature_list=[],):\n",
        "    print ('Threshold: ', threshold) \n",
        "    if not feature_list:\n",
        "        # After First Task \n",
        "        for i in range(len(mat_list)):\n",
        "            activation = mat_list[i]\n",
        "            U,S,Vh = np.linalg.svd(activation, full_matrices=False)\n",
        "            # criteria (Eq-5)\n",
        "            sval_total = (S**2).sum()\n",
        "            sval_ratio = (S**2)/sval_total\n",
        "            r = np.sum(np.cumsum(sval_ratio)<threshold[i]) #+1  \n",
        "            feature_list.append(U[:,0:r])\n",
        "    else:\n",
        "        for i in range(len(mat_list)):\n",
        "            activation = mat_list[i]\n",
        "            U1,S1,Vh1=np.linalg.svd(activation, full_matrices=False)\n",
        "            sval_total = (S1**2).sum()\n",
        "            # Projected Representation (Eq-8)\n",
        "            act_hat = activation - np.dot(np.dot(feature_list[i],feature_list[i].transpose()),activation)\n",
        "            U,S,Vh = np.linalg.svd(act_hat, full_matrices=False)\n",
        "            # criteria (Eq-9)\n",
        "            sval_hat = (S**2).sum()\n",
        "            sval_ratio = (S**2)/sval_total               \n",
        "            accumulated_sval = (sval_total-sval_hat)/sval_total\n",
        "            \n",
        "            r = 0\n",
        "            for ii in range (sval_ratio.shape[0]):\n",
        "                if accumulated_sval < threshold[i]:\n",
        "                    accumulated_sval += sval_ratio[ii]\n",
        "                    r += 1\n",
        "                else:\n",
        "                    break\n",
        "            if r == 0:\n",
        "                print ('Skip Updating GPM for layer: {}'.format(i+1)) \n",
        "                continue\n",
        "            # update GPM\n",
        "            Ui=np.hstack((feature_list[i],U[:,0:r]))  \n",
        "            if Ui.shape[1] > Ui.shape[0] :\n",
        "                feature_list[i]=Ui[:,0:Ui.shape[0]]\n",
        "            else:\n",
        "                feature_list[i]=Ui\n",
        "    \n",
        "    print('-'*40)\n",
        "    print('Gradient Constraints Summary')\n",
        "    print('-'*40)\n",
        "    for i in range(len(feature_list)):\n",
        "        print ('Layer {} : {}/{}'.format(i+1,feature_list[i].shape[1], feature_list[i].shape[0]))\n",
        "    print('-'*40)\n",
        "    return feature_list "
      ],
      "metadata": {
        "id": "EpmlmdfBYIH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(args):\n",
        "    tstart=time.time()\n",
        "    ## Device Setting \n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    torch.manual_seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    ## Load CIFAR100 DATASET\n",
        "    data,taskcla,inputsize=get(seed=args.seed, pc_valid=args.pc_valid)\n",
        "\n",
        "    acc_matrix=np.zeros((10,10))\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    task_id = 0\n",
        "    task_list = []\n",
        "    for k,ncla in taskcla:\n",
        "        # specify threshold hyperparameter\n",
        "        threshold = np.array([0.97] * 5) + task_id*np.array([0.003] * 5)\n",
        "     \n",
        "        print('*'*100)\n",
        "        print('Task {:2d} ({:s})'.format(k,data[k]['name']))\n",
        "        print('*'*100)\n",
        "        xtrain=data[k]['train']['x']\n",
        "        ytrain=data[k]['train']['y']\n",
        "        xvalid=data[k]['valid']['x']\n",
        "        yvalid=data[k]['valid']['y']\n",
        "        xtest =data[k]['test']['x']\n",
        "        ytest =data[k]['test']['y']\n",
        "        task_list.append(k)\n",
        "\n",
        "        lr = args.lr \n",
        "        best_loss=np.inf\n",
        "        print ('-'*40)\n",
        "        print ('Task ID :{} | Learning Rate : {}'.format(task_id, lr))\n",
        "        print ('-'*40)\n",
        "        \n",
        "        if task_id==0:\n",
        "            model = AlexNet(taskcla).to(device)\n",
        "            print ('Model parameters ---')\n",
        "            for k_t, (m, param) in enumerate(model.named_parameters()):\n",
        "                print (k_t,m,param.shape)\n",
        "            print ('-'*40)\n",
        "\n",
        "            best_model=get_model(model)\n",
        "            feature_list =[]\n",
        "            optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "            for epoch in range(1, args.n_epochs+1):\n",
        "                # Train\n",
        "                clock0=time.time()\n",
        "                train(args, model, device, xtrain, ytrain, optimizer, criterion, k)\n",
        "                clock1=time.time()\n",
        "                tr_loss,tr_acc = test(args, model, device, xtrain, ytrain,  criterion, k)\n",
        "                print('Epoch {:3d} | Train: loss={:.3f}, acc={:5.1f}% | time={:5.1f}ms |'.format(epoch,\\\n",
        "                                                            tr_loss,tr_acc, 1000*(clock1-clock0)),end='')\n",
        "                # Validate\n",
        "                valid_loss,valid_acc = test(args, model, device, xvalid, yvalid,  criterion, k)\n",
        "                print(' Valid: loss={:.3f}, acc={:5.1f}% |'.format(valid_loss, valid_acc),end='')\n",
        "                # Adapt lr\n",
        "                if valid_loss<best_loss:\n",
        "                    best_loss=valid_loss\n",
        "                    best_model=get_model(model)\n",
        "                    patience=args.lr_patience\n",
        "                    print(' *',end='')\n",
        "                else:\n",
        "                    patience-=1\n",
        "                    if patience<=0:\n",
        "                        lr/=args.lr_factor\n",
        "                        print(' lr={:.1e}'.format(lr),end='')\n",
        "                        if lr<args.lr_min:\n",
        "                            print()\n",
        "                            break\n",
        "                        patience=args.lr_patience\n",
        "                        adjust_learning_rate(optimizer, epoch, args)\n",
        "                print()\n",
        "            set_model_(model,best_model)\n",
        "            # Test\n",
        "            print ('-'*40)\n",
        "            test_loss, test_acc = test(args, model, device, xtest, ytest,  criterion, k)\n",
        "            print('Test: loss={:.3f} , acc={:5.1f}%'.format(test_loss,test_acc))\n",
        "            # Memory Update  \n",
        "            mat_list = get_representation_matrix (model, device, xtrain, ytrain)\n",
        "            feature_list = update_GPM (model, mat_list, threshold, feature_list)\n",
        "\n",
        "        else:\n",
        "            optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
        "            feature_mat = []\n",
        "            # Projection Matrix Precomputation\n",
        "            for i in range(len(model.act)):\n",
        "                Uf=torch.Tensor(np.dot(feature_list[i],feature_list[i].transpose())).to(device)\n",
        "                print('Layer {} - Projection Matrix shape: {}'.format(i+1,Uf.shape))\n",
        "                feature_mat.append(Uf)\n",
        "            print ('-'*40)\n",
        "            for epoch in range(1, args.n_epochs+1):\n",
        "                # Train \n",
        "                clock0=time.time()\n",
        "                train_projected(args, model,device,xtrain, ytrain,optimizer,criterion,feature_mat,k)\n",
        "                clock1=time.time()\n",
        "                tr_loss, tr_acc = test(args, model, device, xtrain, ytrain,criterion,k)\n",
        "                print('Epoch {:3d} | Train: loss={:.3f}, acc={:5.1f}% | time={:5.1f}ms |'.format(epoch,\\\n",
        "                                                        tr_loss, tr_acc, 1000*(clock1-clock0)),end='')\n",
        "                # Validate\n",
        "                valid_loss,valid_acc = test(args, model, device, xvalid, yvalid, criterion,k)\n",
        "                print(' Valid: loss={:.3f}, acc={:5.1f}% |'.format(valid_loss, valid_acc),end='')\n",
        "                # Adapt lr\n",
        "                if valid_loss<best_loss:\n",
        "                    best_loss=valid_loss\n",
        "                    best_model=get_model(model)\n",
        "                    patience=args.lr_patience\n",
        "                    print(' *',end='')\n",
        "                else:\n",
        "                    patience-=1\n",
        "                    if patience<=0:\n",
        "                        lr/=args.lr_factor\n",
        "                        print(' lr={:.1e}'.format(lr),end='')\n",
        "                        if lr<args.lr_min:\n",
        "                            print()\n",
        "                            break\n",
        "                        patience=args.lr_patience\n",
        "                        adjust_learning_rate(optimizer, epoch, args)\n",
        "                print()\n",
        "            set_model_(model,best_model)\n",
        "            # Test \n",
        "            test_loss, test_acc = test(args, model, device, xtest, ytest,  criterion,k)\n",
        "            print('Test: loss={:.3f} , acc={:5.1f}%'.format(test_loss,test_acc))  \n",
        "            # Memory Update \n",
        "            mat_list = get_representation_matrix (model, device, xtrain, ytrain)\n",
        "            feature_list = update_GPM (model, mat_list, threshold, feature_list)\n",
        "        \n",
        "        # save accuracy \n",
        "        jj = 0 \n",
        "        for ii in np.array(task_list)[0:task_id+1]:\n",
        "            xtest =data[ii]['test']['x']\n",
        "            ytest =data[ii]['test']['y'] \n",
        "            _, acc_matrix[task_id,jj] = test(args, model, device, xtest, ytest,criterion,ii) \n",
        "            jj +=1\n",
        "        print('Accuracies =')\n",
        "        for i_a in range(task_id+1):\n",
        "            print('\\t',end='')\n",
        "            for j_a in range(acc_matrix.shape[1]):\n",
        "                print('{:5.1f}% '.format(acc_matrix[i_a,j_a]),end='')\n",
        "            print()\n",
        "        # update task id \n",
        "        task_id +=1\n",
        "    print('-'*50)\n",
        "    # Simulation Results \n",
        "    print ('Task Order : {}'.format(np.array(task_list)))\n",
        "    print ('Final Avg Accuracy: {:5.2f}%'.format(acc_matrix[-1].mean())) \n",
        "    bwt=np.mean((acc_matrix[-1]-np.diag(acc_matrix))[:-1]) \n",
        "    print ('Backward transfer: {:5.2f}%'.format(bwt))\n",
        "    print('[Elapsed time = {:.1f} ms]'.format((time.time()-tstart)*1000))\n",
        "    print('-'*50)\n",
        "    # Plots\n",
        "    array = acc_matrix\n",
        "    df_cm = pd.DataFrame(array, index = [i for i in [\"T1\",\"T2\",\"T3\",\"T4\",\"T5\",\"T6\",\"T7\",\"T8\",\"T9\",\"T10\"]],\n",
        "                      columns = [i for i in [\"T1\",\"T2\",\"T3\",\"T4\",\"T5\",\"T6\",\"T7\",\"T8\",\"T9\",\"T10\"]])\n",
        "    sn.set(font_scale=1.4) \n",
        "    sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 10})\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "5HokDGpjYL__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Training parameters\n",
        "    parser = argparse.ArgumentParser(description='Sequential PMNIST with GPM')\n",
        "    parser.add_argument('--batch_size_train', type=int, default=64, metavar='N',\n",
        "                        help='input batch size for training (default: 64)')\n",
        "    parser.add_argument('--batch_size_test', type=int, default=64, metavar='N',\n",
        "                        help='input batch size for testing (default: 64)')\n",
        "    parser.add_argument('--n_epochs', type=int, default=200, metavar='N',\n",
        "                        help='number of training epochs/task (default: 200)')\n",
        "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
        "                        help='random seed (default: 1)')\n",
        "    parser.add_argument('--pc_valid',default=0.05,type=float,\n",
        "                        help='fraction of training data used for validation')\n",
        "    # Optimizer parameters\n",
        "    parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
        "                        help='learning rate (default: 0.01)')\n",
        "    parser.add_argument('--momentum', type=float, default=0.9, metavar='M',\n",
        "                        help='SGD momentum (default: 0.9)')\n",
        "    parser.add_argument('--lr_min', type=float, default=1e-5, metavar='LRM',\n",
        "                        help='minimum lr rate (default: 1e-5)')\n",
        "    parser.add_argument('--lr_patience', type=int, default=6, metavar='LRP',\n",
        "                        help='hold before decaying lr (default: 6)')\n",
        "    parser.add_argument('--lr_factor', type=int, default=2, metavar='LRF',\n",
        "                        help='lr decay factor (default: 2)')\n",
        "\n",
        "    args, unknown = parser.parse_known_args()\n",
        "    print('='*100)\n",
        "    print('Arguments =')\n",
        "    for arg in vars(args):\n",
        "        print('\\t'+arg+':',getattr(args,arg))\n",
        "    print('='*100)\n",
        "\n",
        "    main(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6641d1bdce4a4d83bf86bad0e7a351ba",
            "5c0e640dbf104de68bd514e3ccab4ef4",
            "f4cba9a8646b46aba3e8cdc5ff04111b",
            "331501410aae4ee9bfa956fcebbf622a",
            "98cf1344ea854e4187f9a7c36b6b1556",
            "0ce9b6b8968940f0a9bd94fe68945104",
            "79cc41807a32493c83e5c0c7c0bdde42",
            "39bc7de8fb844ccfb63a590961546407",
            "11a20b0ea4674f089c78e1271e2e563b",
            "965b9a03c59c435081897f2a2d4ad1e8",
            "6a2825be3634409db49d0e2f9453303b"
          ]
        },
        "id": "KyLacrROYNzX",
        "outputId": "4a5eb3dc-b610-483f-e02b-bd17da3e79db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "Arguments =\n",
            "\tbatch_size_train: 64\n",
            "\tbatch_size_test: 64\n",
            "\tn_epochs: 200\n",
            "\tseed: 1\n",
            "\tpc_valid: 0.05\n",
            "\tlr: 0.01\n",
            "\tmomentum: 0.9\n",
            "\tlr_min: 1e-05\n",
            "\tlr_patience: 6\n",
            "\tlr_factor: 2\n",
            "====================================================================================================\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to /content/drive/MyDrive/CSN-300 Lab based project Advanced/Gradient Projection Memory for continual learning/data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/169001437 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6641d1bdce4a4d83bf86bad0e7a351ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/drive/MyDrive/CSN-300 Lab based project Advanced/Gradient Projection Memory for continual learning/data/cifar-100-python.tar.gz to /content/drive/MyDrive/CSN-300 Lab based project Advanced/Gradient Projection Memory for continual learning/data\n",
            "Files already downloaded and verified\n",
            "Task order = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "****************************************************************************************************\n",
            "Task  0 (cifar100-0)\n",
            "****************************************************************************************************\n",
            "----------------------------------------\n",
            "Task ID :0 | Learning Rate : 0.01\n",
            "----------------------------------------\n",
            "Model parameters ---\n",
            "0 conv1.weight torch.Size([64, 3, 4, 4])\n",
            "1 bn1.weight torch.Size([64])\n",
            "2 bn1.bias torch.Size([64])\n",
            "3 conv2.weight torch.Size([128, 64, 3, 3])\n",
            "4 bn2.weight torch.Size([128])\n",
            "5 bn2.bias torch.Size([128])\n",
            "6 conv3.weight torch.Size([256, 128, 2, 2])\n",
            "7 bn3.weight torch.Size([256])\n",
            "8 bn3.bias torch.Size([256])\n",
            "9 fc1.weight torch.Size([2048, 1024])\n",
            "10 bn4.weight torch.Size([2048])\n",
            "11 bn4.bias torch.Size([2048])\n",
            "12 fc2.weight torch.Size([2048, 2048])\n",
            "13 bn5.weight torch.Size([2048])\n",
            "14 bn5.bias torch.Size([2048])\n",
            "15 fc3.0.weight torch.Size([10, 2048])\n",
            "16 fc3.1.weight torch.Size([10, 2048])\n",
            "17 fc3.2.weight torch.Size([10, 2048])\n",
            "18 fc3.3.weight torch.Size([10, 2048])\n",
            "19 fc3.4.weight torch.Size([10, 2048])\n",
            "20 fc3.5.weight torch.Size([10, 2048])\n",
            "21 fc3.6.weight torch.Size([10, 2048])\n",
            "22 fc3.7.weight torch.Size([10, 2048])\n",
            "23 fc3.8.weight torch.Size([10, 2048])\n",
            "24 fc3.9.weight torch.Size([10, 2048])\n",
            "----------------------------------------\n",
            "Epoch   1 | Train: loss=1.532, acc= 47.0% | time=1544.4ms | Valid: loss=1.539, acc= 45.2% | *\n",
            "Epoch   2 | Train: loss=1.473, acc= 50.7% | time=1208.7ms | Valid: loss=1.471, acc= 52.8% | *\n",
            "Epoch   3 | Train: loss=1.230, acc= 58.5% | time=1205.1ms | Valid: loss=1.306, acc= 58.8% | *\n",
            "Epoch   4 | Train: loss=1.386, acc= 55.4% | time=1210.2ms | Valid: loss=1.417, acc= 53.2% |\n",
            "Epoch   5 | Train: loss=1.219, acc= 60.4% | time=1203.6ms | Valid: loss=1.376, acc= 56.4% |\n",
            "Epoch   6 | Train: loss=0.987, acc= 67.9% | time=1207.5ms | Valid: loss=1.223, acc= 60.0% | *\n",
            "Epoch   7 | Train: loss=1.034, acc= 66.3% | time=1206.7ms | Valid: loss=1.231, acc= 60.8% |\n",
            "Epoch   8 | Train: loss=0.949, acc= 69.0% | time=1212.5ms | Valid: loss=1.273, acc= 62.0% |\n",
            "Epoch   9 | Train: loss=0.906, acc= 70.7% | time=1207.7ms | Valid: loss=1.250, acc= 65.2% |\n",
            "Epoch  10 | Train: loss=0.919, acc= 70.9% | time=1204.9ms | Valid: loss=1.311, acc= 63.6% |\n",
            "Epoch  11 | Train: loss=0.798, acc= 74.0% | time=1212.4ms | Valid: loss=1.077, acc= 64.0% | *\n",
            "Epoch  12 | Train: loss=0.847, acc= 73.1% | time=1210.5ms | Valid: loss=1.117, acc= 65.2% |\n",
            "Epoch  13 | Train: loss=0.758, acc= 75.0% | time=1210.4ms | Valid: loss=1.094, acc= 66.8% |\n",
            "Epoch  14 | Train: loss=0.716, acc= 76.8% | time=1215.6ms | Valid: loss=1.218, acc= 64.0% |\n",
            "Epoch  15 | Train: loss=0.562, acc= 81.7% | time=1209.2ms | Valid: loss=1.026, acc= 67.2% | *\n",
            "Epoch  16 | Train: loss=0.619, acc= 80.0% | time=1210.0ms | Valid: loss=1.005, acc= 70.0% | *\n",
            "Epoch  17 | Train: loss=0.559, acc= 81.1% | time=1212.1ms | Valid: loss=0.984, acc= 74.4% | *\n",
            "Epoch  18 | Train: loss=0.727, acc= 76.7% | time=1209.8ms | Valid: loss=1.157, acc= 65.2% |\n",
            "Epoch  19 | Train: loss=0.895, acc= 72.3% | time=1208.9ms | Valid: loss=1.407, acc= 63.2% |\n",
            "Epoch  20 | Train: loss=0.606, acc= 79.6% | time=1211.6ms | Valid: loss=1.144, acc= 63.6% |\n",
            "Epoch  21 | Train: loss=0.462, acc= 84.0% | time=1212.5ms | Valid: loss=1.003, acc= 70.8% |\n",
            "Epoch  22 | Train: loss=0.494, acc= 82.7% | time=1214.1ms | Valid: loss=1.050, acc= 69.6% |\n",
            "Epoch  23 | Train: loss=0.681, acc= 77.5% | time=1207.4ms | Valid: loss=1.136, acc= 67.6% | lr=5.0e-03\n",
            "Epoch  24 | Train: loss=0.553, acc= 82.4% | time=1215.4ms | Valid: loss=1.037, acc= 70.8% |\n",
            "Epoch  25 | Train: loss=0.373, acc= 87.5% | time=1214.4ms | Valid: loss=0.934, acc= 72.4% | *\n",
            "Epoch  26 | Train: loss=0.351, acc= 87.9% | time=1214.1ms | Valid: loss=0.914, acc= 72.0% | *\n",
            "Epoch  27 | Train: loss=0.362, acc= 87.8% | time=1215.3ms | Valid: loss=0.922, acc= 73.6% |\n",
            "Epoch  28 | Train: loss=0.343, acc= 87.8% | time=1214.4ms | Valid: loss=0.942, acc= 73.2% |\n",
            "Epoch  29 | Train: loss=0.319, acc= 88.6% | time=1210.6ms | Valid: loss=0.884, acc= 72.8% | *\n",
            "Epoch  30 | Train: loss=0.320, acc= 89.3% | time=1206.3ms | Valid: loss=0.941, acc= 74.0% |\n",
            "Epoch  31 | Train: loss=0.306, acc= 89.5% | time=1205.3ms | Valid: loss=0.921, acc= 72.8% |\n",
            "Epoch  32 | Train: loss=0.317, acc= 88.9% | time=1217.9ms | Valid: loss=0.982, acc= 72.4% |\n",
            "Epoch  33 | Train: loss=0.361, acc= 87.1% | time=1214.1ms | Valid: loss=1.055, acc= 70.8% |\n",
            "Epoch  34 | Train: loss=0.262, acc= 90.9% | time=1213.3ms | Valid: loss=0.900, acc= 75.2% |\n",
            "Epoch  35 | Train: loss=0.282, acc= 90.3% | time=1212.0ms | Valid: loss=0.921, acc= 76.0% | lr=2.5e-03\n",
            "Epoch  36 | Train: loss=0.241, acc= 91.5% | time=1215.2ms | Valid: loss=0.879, acc= 73.6% | *\n",
            "Epoch  37 | Train: loss=0.226, acc= 92.5% | time=1210.9ms | Valid: loss=0.928, acc= 74.8% |\n",
            "Epoch  38 | Train: loss=0.240, acc= 92.0% | time=1215.0ms | Valid: loss=0.905, acc= 75.2% |\n",
            "Epoch  39 | Train: loss=0.275, acc= 90.8% | time=1218.0ms | Valid: loss=0.998, acc= 73.2% |\n",
            "Epoch  40 | Train: loss=0.210, acc= 92.8% | time=1218.0ms | Valid: loss=0.929, acc= 74.4% |\n",
            "Epoch  41 | Train: loss=0.213, acc= 92.8% | time=1211.2ms | Valid: loss=0.971, acc= 74.4% |\n",
            "Epoch  42 | Train: loss=0.217, acc= 92.8% | time=1219.4ms | Valid: loss=0.885, acc= 74.8% | lr=1.3e-03\n",
            "Epoch  43 | Train: loss=0.206, acc= 92.9% | time=1212.9ms | Valid: loss=0.893, acc= 75.6% |\n",
            "Epoch  44 | Train: loss=0.197, acc= 93.4% | time=1215.9ms | Valid: loss=0.902, acc= 73.6% |\n",
            "Epoch  45 | Train: loss=0.200, acc= 93.1% | time=1215.3ms | Valid: loss=0.866, acc= 72.8% | *\n",
            "Epoch  46 | Train: loss=0.198, acc= 93.0% | time=1221.3ms | Valid: loss=0.871, acc= 76.4% |\n",
            "Epoch  47 | Train: loss=0.188, acc= 93.8% | time=1218.5ms | Valid: loss=0.858, acc= 75.6% | *\n",
            "Epoch  48 | Train: loss=0.183, acc= 93.8% | time=1214.6ms | Valid: loss=0.864, acc= 76.4% |\n",
            "Epoch  49 | Train: loss=0.184, acc= 93.7% | time=1210.8ms | Valid: loss=0.905, acc= 76.0% |\n",
            "Epoch  50 | Train: loss=0.196, acc= 93.3% | time=1209.2ms | Valid: loss=0.912, acc= 76.0% |\n",
            "Epoch  51 | Train: loss=0.180, acc= 93.8% | time=1220.3ms | Valid: loss=0.908, acc= 76.0% |\n",
            "Epoch  52 | Train: loss=0.178, acc= 94.3% | time=1219.3ms | Valid: loss=0.867, acc= 76.0% |\n",
            "Epoch  53 | Train: loss=0.177, acc= 94.0% | time=1210.8ms | Valid: loss=0.883, acc= 77.6% | lr=6.3e-04\n",
            "Epoch  54 | Train: loss=0.166, acc= 94.5% | time=1221.1ms | Valid: loss=0.842, acc= 75.6% | *\n",
            "Epoch  55 | Train: loss=0.177, acc= 94.4% | time=1218.9ms | Valid: loss=0.870, acc= 76.0% |\n",
            "Epoch  56 | Train: loss=0.174, acc= 94.0% | time=1217.6ms | Valid: loss=0.872, acc= 76.0% |\n",
            "Epoch  57 | Train: loss=0.166, acc= 94.5% | time=1211.8ms | Valid: loss=0.873, acc= 76.4% |\n",
            "Epoch  58 | Train: loss=0.174, acc= 94.0% | time=1217.6ms | Valid: loss=0.876, acc= 74.4% |\n",
            "Epoch  59 | Train: loss=0.180, acc= 93.9% | time=1218.2ms | Valid: loss=0.885, acc= 76.4% |\n",
            "Epoch  60 | Train: loss=0.162, acc= 94.7% | time=1217.3ms | Valid: loss=0.875, acc= 76.0% | lr=3.1e-04\n",
            "Epoch  61 | Train: loss=0.169, acc= 94.0% | time=1213.2ms | Valid: loss=0.876, acc= 75.6% |\n",
            "Epoch  62 | Train: loss=0.162, acc= 94.5% | time=1220.6ms | Valid: loss=0.922, acc= 74.8% |\n",
            "Epoch  63 | Train: loss=0.168, acc= 94.6% | time=1221.1ms | Valid: loss=0.880, acc= 73.2% |\n",
            "Epoch  64 | Train: loss=0.162, acc= 94.4% | time=1216.2ms | Valid: loss=0.881, acc= 76.0% |\n",
            "Epoch  65 | Train: loss=0.162, acc= 94.5% | time=1217.4ms | Valid: loss=0.855, acc= 75.2% |\n",
            "Epoch  66 | Train: loss=0.159, acc= 94.8% | time=1219.7ms | Valid: loss=0.857, acc= 77.2% | lr=1.6e-04\n",
            "Epoch  67 | Train: loss=0.169, acc= 94.3% | time=1225.1ms | Valid: loss=0.931, acc= 74.8% |\n",
            "Epoch  68 | Train: loss=0.153, acc= 94.7% | time=1219.7ms | Valid: loss=0.931, acc= 73.6% |\n",
            "Epoch  69 | Train: loss=0.165, acc= 94.4% | time=1210.7ms | Valid: loss=0.901, acc= 74.8% |\n",
            "Epoch  70 | Train: loss=0.170, acc= 94.4% | time=1211.7ms | Valid: loss=0.871, acc= 76.4% |\n",
            "Epoch  71 | Train: loss=0.157, acc= 95.0% | time=1217.5ms | Valid: loss=0.867, acc= 75.2% |\n",
            "Epoch  72 | Train: loss=0.157, acc= 94.5% | time=1221.7ms | Valid: loss=0.958, acc= 74.8% | lr=7.8e-05\n",
            "Epoch  73 | Train: loss=0.159, acc= 94.9% | time=1214.1ms | Valid: loss=0.882, acc= 74.8% |\n",
            "Epoch  74 | Train: loss=0.161, acc= 94.5% | time=1215.6ms | Valid: loss=0.864, acc= 75.2% |\n",
            "Epoch  75 | Train: loss=0.160, acc= 94.5% | time=1212.5ms | Valid: loss=0.878, acc= 76.0% |\n",
            "Epoch  76 | Train: loss=0.155, acc= 95.0% | time=1217.9ms | Valid: loss=0.947, acc= 74.8% |\n",
            "Epoch  77 | Train: loss=0.155, acc= 94.8% | time=1217.2ms | Valid: loss=0.895, acc= 76.4% |\n",
            "Epoch  78 | Train: loss=0.160, acc= 94.8% | time=1214.4ms | Valid: loss=0.872, acc= 77.6% | lr=3.9e-05\n",
            "Epoch  79 | Train: loss=0.161, acc= 94.8% | time=1219.8ms | Valid: loss=0.877, acc= 78.0% |\n",
            "Epoch  80 | Train: loss=0.152, acc= 95.1% | time=1223.3ms | Valid: loss=0.857, acc= 76.4% |\n",
            "Epoch  81 | Train: loss=0.156, acc= 94.7% | time=1220.3ms | Valid: loss=0.845, acc= 77.2% |\n",
            "Epoch  82 | Train: loss=0.154, acc= 94.9% | time=1219.1ms | Valid: loss=0.925, acc= 74.8% |\n",
            "Epoch  83 | Train: loss=0.160, acc= 94.9% | time=1217.3ms | Valid: loss=0.888, acc= 76.4% |\n",
            "Epoch  84 | Train: loss=0.158, acc= 95.0% | time=1220.1ms | Valid: loss=0.854, acc= 76.8% | lr=2.0e-05\n",
            "Epoch  85 | Train: loss=0.163, acc= 94.8% | time=1212.0ms | Valid: loss=0.870, acc= 76.0% |\n",
            "Epoch  86 | Train: loss=0.159, acc= 94.8% | time=1216.3ms | Valid: loss=0.863, acc= 75.2% |\n",
            "Epoch  87 | Train: loss=0.157, acc= 94.8% | time=1218.0ms | Valid: loss=0.906, acc= 76.4% |\n",
            "Epoch  88 | Train: loss=0.157, acc= 94.9% | time=1213.6ms | Valid: loss=0.880, acc= 76.0% |\n",
            "Epoch  89 | Train: loss=0.154, acc= 94.9% | time=1207.9ms | Valid: loss=0.853, acc= 76.8% |\n",
            "Epoch  90 | Train: loss=0.164, acc= 94.6% | time=1214.7ms | Valid: loss=0.873, acc= 78.0% | lr=9.8e-06\n",
            "----------------------------------------\n",
            "Test: loss=0.847 , acc= 76.1%\n",
            "------------------------------\n",
            "Representation Matrix\n",
            "------------------------------\n",
            "Layer 1 : (48, 20184)\n",
            "Layer 2 : (576, 14400)\n",
            "Layer 3 : (512, 2500)\n",
            "Layer 4 : (1024, 125)\n",
            "Layer 5 : (2048, 125)\n",
            "------------------------------\n",
            "Threshold:  [0.97 0.97 0.97 0.97 0.97]\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 9/48\n",
            "Layer 2 : 127/576\n",
            "Layer 3 : 206/512\n",
            "Layer 4 : 81/1024\n",
            "Layer 5 : 98/2048\n",
            "----------------------------------------\n",
            "Accuracies =\n",
            "\t 75.6%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "****************************************************************************************************\n",
            "Task  1 (cifar100-1)\n",
            "****************************************************************************************************\n",
            "----------------------------------------\n",
            "Task ID :1 | Learning Rate : 0.01\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([48, 48])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([576, 576])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([512, 512])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([1024, 1024])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([2048, 2048])\n",
            "----------------------------------------\n",
            "Epoch   1 | Train: loss=1.452, acc= 50.2% | time=2034.8ms | Valid: loss=1.388, acc= 55.2% | *\n",
            "Epoch   2 | Train: loss=1.320, acc= 55.4% | time=1913.1ms | Valid: loss=1.309, acc= 54.4% | *\n",
            "Epoch   3 | Train: loss=1.279, acc= 56.3% | time=1916.7ms | Valid: loss=1.283, acc= 54.8% | *\n",
            "Epoch   4 | Train: loss=1.160, acc= 60.3% | time=1917.0ms | Valid: loss=1.164, acc= 59.2% | *\n",
            "Epoch   5 | Train: loss=1.153, acc= 60.9% | time=1927.1ms | Valid: loss=1.187, acc= 56.0% |\n",
            "Epoch   6 | Train: loss=1.069, acc= 63.6% | time=1919.5ms | Valid: loss=1.120, acc= 63.2% | *\n",
            "Epoch   7 | Train: loss=1.037, acc= 64.9% | time=1920.9ms | Valid: loss=1.147, acc= 58.8% |\n",
            "Epoch   8 | Train: loss=0.979, acc= 66.9% | time=1917.2ms | Valid: loss=1.113, acc= 60.8% | *\n",
            "Epoch   9 | Train: loss=0.949, acc= 67.6% | time=1921.8ms | Valid: loss=1.071, acc= 62.0% | *\n",
            "Epoch  10 | Train: loss=0.913, acc= 68.7% | time=1919.2ms | Valid: loss=1.036, acc= 63.2% | *\n",
            "Epoch  11 | Train: loss=0.891, acc= 69.1% | time=1913.9ms | Valid: loss=1.051, acc= 63.6% |\n",
            "Epoch  12 | Train: loss=0.851, acc= 70.7% | time=1920.7ms | Valid: loss=1.032, acc= 66.8% | *\n",
            "Epoch  13 | Train: loss=0.841, acc= 71.4% | time=1911.0ms | Valid: loss=1.037, acc= 65.2% |\n",
            "Epoch  14 | Train: loss=0.797, acc= 73.3% | time=1921.6ms | Valid: loss=1.003, acc= 66.8% | *\n",
            "Epoch  15 | Train: loss=0.776, acc= 73.1% | time=1909.8ms | Valid: loss=1.002, acc= 66.4% | *\n",
            "Epoch  16 | Train: loss=0.760, acc= 74.0% | time=1913.1ms | Valid: loss=0.999, acc= 66.0% | *\n",
            "Epoch  17 | Train: loss=0.703, acc= 76.0% | time=1921.0ms | Valid: loss=0.960, acc= 68.4% | *\n",
            "Epoch  18 | Train: loss=0.710, acc= 75.9% | time=1918.9ms | Valid: loss=0.966, acc= 68.0% |\n",
            "Epoch  19 | Train: loss=0.701, acc= 76.0% | time=1918.1ms | Valid: loss=1.060, acc= 67.6% |\n",
            "Epoch  20 | Train: loss=0.643, acc= 77.9% | time=1907.7ms | Valid: loss=1.006, acc= 66.0% |\n",
            "Epoch  21 | Train: loss=0.616, acc= 78.7% | time=1919.1ms | Valid: loss=1.025, acc= 68.0% |\n",
            "Epoch  22 | Train: loss=0.654, acc= 77.9% | time=1913.0ms | Valid: loss=1.004, acc= 68.4% |\n",
            "Epoch  23 | Train: loss=0.582, acc= 79.8% | time=1917.4ms | Valid: loss=1.015, acc= 66.8% | lr=5.0e-03\n",
            "Epoch  24 | Train: loss=0.572, acc= 80.5% | time=1905.4ms | Valid: loss=1.011, acc= 67.6% |\n",
            "Epoch  25 | Train: loss=0.570, acc= 80.5% | time=1900.6ms | Valid: loss=0.984, acc= 70.0% |\n",
            "Epoch  26 | Train: loss=0.550, acc= 81.6% | time=1910.4ms | Valid: loss=0.980, acc= 68.4% |\n",
            "Epoch  27 | Train: loss=0.540, acc= 82.0% | time=1910.9ms | Valid: loss=0.960, acc= 69.2% | *\n",
            "Epoch  28 | Train: loss=0.530, acc= 81.7% | time=1915.8ms | Valid: loss=0.965, acc= 70.0% |\n",
            "Epoch  29 | Train: loss=0.532, acc= 81.7% | time=1911.8ms | Valid: loss=0.960, acc= 67.6% |\n",
            "Epoch  30 | Train: loss=0.532, acc= 81.6% | time=1912.1ms | Valid: loss=0.989, acc= 67.2% |\n",
            "Epoch  31 | Train: loss=0.518, acc= 82.4% | time=1916.6ms | Valid: loss=0.966, acc= 69.2% |\n",
            "Epoch  32 | Train: loss=0.498, acc= 83.6% | time=1917.9ms | Valid: loss=0.943, acc= 69.2% | *\n",
            "Epoch  33 | Train: loss=0.490, acc= 83.2% | time=1920.8ms | Valid: loss=0.960, acc= 70.0% |\n",
            "Epoch  34 | Train: loss=0.498, acc= 83.4% | time=1915.7ms | Valid: loss=0.939, acc= 71.6% | *\n",
            "Epoch  35 | Train: loss=0.478, acc= 83.8% | time=1912.3ms | Valid: loss=0.961, acc= 69.2% |\n",
            "Epoch  36 | Train: loss=0.470, acc= 83.9% | time=1913.6ms | Valid: loss=0.964, acc= 69.6% |\n",
            "Epoch  37 | Train: loss=0.459, acc= 84.5% | time=1915.3ms | Valid: loss=0.944, acc= 69.6% |\n",
            "Epoch  38 | Train: loss=0.449, acc= 84.7% | time=1907.5ms | Valid: loss=1.022, acc= 66.0% |\n",
            "Epoch  39 | Train: loss=0.449, acc= 84.8% | time=1917.0ms | Valid: loss=0.991, acc= 67.2% |\n",
            "Epoch  40 | Train: loss=0.430, acc= 85.3% | time=1916.9ms | Valid: loss=0.947, acc= 70.8% | lr=2.5e-03\n",
            "Epoch  41 | Train: loss=0.432, acc= 85.3% | time=1925.5ms | Valid: loss=0.980, acc= 68.0% |\n",
            "Epoch  42 | Train: loss=0.432, acc= 85.2% | time=1908.4ms | Valid: loss=0.981, acc= 72.0% |\n",
            "Epoch  43 | Train: loss=0.423, acc= 86.0% | time=1917.1ms | Valid: loss=0.964, acc= 73.6% |\n",
            "Epoch  44 | Train: loss=0.412, acc= 86.2% | time=1910.5ms | Valid: loss=0.991, acc= 69.6% |\n",
            "Epoch  45 | Train: loss=0.416, acc= 85.9% | time=1919.3ms | Valid: loss=0.966, acc= 70.8% |\n",
            "Epoch  46 | Train: loss=0.413, acc= 86.0% | time=1912.3ms | Valid: loss=0.951, acc= 71.6% | lr=1.3e-03\n",
            "Epoch  47 | Train: loss=0.416, acc= 85.8% | time=1918.8ms | Valid: loss=0.934, acc= 71.2% | *\n",
            "Epoch  48 | Train: loss=0.404, acc= 86.8% | time=1912.1ms | Valid: loss=0.937, acc= 72.4% |\n",
            "Epoch  49 | Train: loss=0.404, acc= 86.3% | time=1914.4ms | Valid: loss=0.993, acc= 70.4% |\n",
            "Epoch  50 | Train: loss=0.399, acc= 87.0% | time=1911.2ms | Valid: loss=0.931, acc= 71.2% | *\n",
            "Epoch  51 | Train: loss=0.402, acc= 86.8% | time=1907.3ms | Valid: loss=0.959, acc= 70.8% |\n",
            "Epoch  52 | Train: loss=0.395, acc= 86.5% | time=1907.6ms | Valid: loss=0.952, acc= 71.2% |\n",
            "Epoch  53 | Train: loss=0.400, acc= 86.2% | time=1907.9ms | Valid: loss=0.934, acc= 69.2% |\n",
            "Epoch  54 | Train: loss=0.391, acc= 87.3% | time=1919.7ms | Valid: loss=0.947, acc= 70.8% |\n",
            "Epoch  55 | Train: loss=0.401, acc= 86.9% | time=1909.3ms | Valid: loss=0.994, acc= 71.2% |\n",
            "Epoch  56 | Train: loss=0.388, acc= 87.0% | time=1918.5ms | Valid: loss=0.961, acc= 72.0% | lr=6.3e-04\n",
            "Epoch  57 | Train: loss=0.393, acc= 86.6% | time=1906.9ms | Valid: loss=1.016, acc= 70.8% |\n",
            "Epoch  58 | Train: loss=0.392, acc= 87.1% | time=1918.8ms | Valid: loss=0.962, acc= 69.2% |\n",
            "Epoch  59 | Train: loss=0.392, acc= 86.8% | time=1916.6ms | Valid: loss=0.956, acc= 71.2% |\n",
            "Epoch  60 | Train: loss=0.399, acc= 86.5% | time=1915.8ms | Valid: loss=0.943, acc= 71.6% |\n",
            "Epoch  61 | Train: loss=0.384, acc= 87.0% | time=1914.4ms | Valid: loss=0.966, acc= 70.0% |\n",
            "Epoch  62 | Train: loss=0.387, acc= 87.3% | time=1918.5ms | Valid: loss=0.963, acc= 71.6% | lr=3.1e-04\n",
            "Epoch  63 | Train: loss=0.385, acc= 87.0% | time=1907.8ms | Valid: loss=0.920, acc= 72.4% | *\n",
            "Epoch  64 | Train: loss=0.388, acc= 86.7% | time=1912.2ms | Valid: loss=0.949, acc= 71.2% |\n",
            "Epoch  65 | Train: loss=0.387, acc= 87.1% | time=1912.2ms | Valid: loss=0.955, acc= 70.4% |\n",
            "Epoch  66 | Train: loss=0.381, acc= 87.2% | time=1921.8ms | Valid: loss=0.977, acc= 68.8% |\n",
            "Epoch  67 | Train: loss=0.391, acc= 87.0% | time=1920.8ms | Valid: loss=0.947, acc= 69.6% |\n",
            "Epoch  68 | Train: loss=0.388, acc= 87.3% | time=1917.8ms | Valid: loss=0.942, acc= 72.4% |\n",
            "Epoch  69 | Train: loss=0.388, acc= 87.1% | time=1919.4ms | Valid: loss=0.970, acc= 71.6% | lr=1.6e-04\n",
            "Epoch  70 | Train: loss=0.387, acc= 87.5% | time=1916.2ms | Valid: loss=0.968, acc= 71.2% |\n",
            "Epoch  71 | Train: loss=0.370, acc= 87.6% | time=1916.7ms | Valid: loss=0.938, acc= 68.8% |\n",
            "Epoch  72 | Train: loss=0.386, acc= 87.0% | time=1913.6ms | Valid: loss=0.921, acc= 71.6% |\n",
            "Epoch  73 | Train: loss=0.380, acc= 87.1% | time=1910.4ms | Valid: loss=0.960, acc= 71.6% |\n",
            "Epoch  74 | Train: loss=0.381, acc= 87.5% | time=1922.1ms | Valid: loss=0.991, acc= 70.4% |\n",
            "Epoch  75 | Train: loss=0.380, acc= 87.3% | time=1923.4ms | Valid: loss=0.987, acc= 69.6% | lr=7.8e-05\n",
            "Epoch  76 | Train: loss=0.377, acc= 87.6% | time=1910.5ms | Valid: loss=0.978, acc= 69.6% |\n",
            "Epoch  77 | Train: loss=0.380, acc= 87.7% | time=1917.0ms | Valid: loss=0.966, acc= 71.2% |\n",
            "Epoch  78 | Train: loss=0.380, acc= 86.8% | time=1909.3ms | Valid: loss=0.922, acc= 72.0% |\n",
            "Epoch  79 | Train: loss=0.389, acc= 87.2% | time=1916.0ms | Valid: loss=0.979, acc= 70.0% |\n",
            "Epoch  80 | Train: loss=0.379, acc= 87.2% | time=1918.2ms | Valid: loss=0.949, acc= 72.8% |\n",
            "Epoch  81 | Train: loss=0.388, acc= 86.7% | time=1916.3ms | Valid: loss=0.925, acc= 71.6% | lr=3.9e-05\n",
            "Epoch  82 | Train: loss=0.382, acc= 87.0% | time=1919.7ms | Valid: loss=0.918, acc= 73.2% | *\n",
            "Epoch  83 | Train: loss=0.380, acc= 87.2% | time=1915.3ms | Valid: loss=0.955, acc= 70.0% |\n",
            "Epoch  84 | Train: loss=0.383, acc= 87.3% | time=1919.1ms | Valid: loss=1.008, acc= 67.2% |\n",
            "Epoch  85 | Train: loss=0.379, acc= 87.1% | time=1910.7ms | Valid: loss=1.004, acc= 70.4% |\n",
            "Epoch  86 | Train: loss=0.379, acc= 87.2% | time=1920.0ms | Valid: loss=0.983, acc= 69.2% |\n",
            "Epoch  87 | Train: loss=0.375, acc= 87.8% | time=1917.6ms | Valid: loss=0.909, acc= 72.4% | *\n",
            "Epoch  88 | Train: loss=0.369, acc= 87.6% | time=1920.0ms | Valid: loss=0.919, acc= 74.0% |\n",
            "Epoch  89 | Train: loss=0.386, acc= 87.1% | time=1911.7ms | Valid: loss=0.980, acc= 69.2% |\n",
            "Epoch  90 | Train: loss=0.388, acc= 87.0% | time=1917.4ms | Valid: loss=0.968, acc= 69.2% |\n",
            "Epoch  91 | Train: loss=0.381, acc= 87.3% | time=1918.9ms | Valid: loss=0.933, acc= 73.6% |\n",
            "Epoch  92 | Train: loss=0.379, acc= 87.3% | time=1911.4ms | Valid: loss=0.943, acc= 71.6% |\n",
            "Epoch  93 | Train: loss=0.384, acc= 86.9% | time=1911.3ms | Valid: loss=0.980, acc= 69.2% | lr=2.0e-05\n",
            "Epoch  94 | Train: loss=0.373, acc= 87.3% | time=1912.2ms | Valid: loss=0.976, acc= 72.0% |\n",
            "Epoch  95 | Train: loss=0.383, acc= 86.6% | time=1915.9ms | Valid: loss=0.992, acc= 71.6% |\n",
            "Epoch  96 | Train: loss=0.375, acc= 87.7% | time=1919.0ms | Valid: loss=0.941, acc= 73.6% |\n",
            "Epoch  97 | Train: loss=0.374, acc= 87.4% | time=1915.3ms | Valid: loss=0.940, acc= 70.8% |\n",
            "Epoch  98 | Train: loss=0.372, acc= 87.4% | time=1916.5ms | Valid: loss=0.965, acc= 72.0% |\n",
            "Epoch  99 | Train: loss=0.374, acc= 87.7% | time=1910.3ms | Valid: loss=0.959, acc= 72.0% | lr=9.8e-06\n",
            "Test: loss=1.056 , acc= 68.7%\n",
            "------------------------------\n",
            "Representation Matrix\n",
            "------------------------------\n",
            "Layer 1 : (48, 20184)\n",
            "Layer 2 : (576, 14400)\n",
            "Layer 3 : (512, 2500)\n",
            "Layer 4 : (1024, 125)\n",
            "Layer 5 : (2048, 125)\n",
            "------------------------------\n",
            "Threshold:  [0.973 0.973 0.973 0.973 0.973]\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 10/48\n",
            "Layer 2 : 167/576\n",
            "Layer 3 : 278/512\n",
            "Layer 4 : 159/1024\n",
            "Layer 5 : 197/2048\n",
            "----------------------------------------\n",
            "Accuracies =\n",
            "\t 75.6%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 76.4%  68.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "****************************************************************************************************\n",
            "Task  2 (cifar100-2)\n",
            "****************************************************************************************************\n",
            "----------------------------------------\n",
            "Task ID :2 | Learning Rate : 0.01\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([48, 48])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([576, 576])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([512, 512])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([1024, 1024])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([2048, 2048])\n",
            "----------------------------------------\n",
            "Epoch   1 | Train: loss=1.275, acc= 57.1% | time=2040.7ms | Valid: loss=1.308, acc= 55.6% | *\n",
            "Epoch   2 | Train: loss=1.122, acc= 61.7% | time=1917.3ms | Valid: loss=1.165, acc= 59.2% | *\n",
            "Epoch   3 | Train: loss=1.022, acc= 65.6% | time=1929.7ms | Valid: loss=1.056, acc= 65.2% | *\n",
            "Epoch   4 | Train: loss=1.009, acc= 65.7% | time=1922.2ms | Valid: loss=1.054, acc= 66.4% | *\n",
            "Epoch   5 | Train: loss=0.931, acc= 68.5% | time=1931.9ms | Valid: loss=1.028, acc= 65.6% | *\n",
            "Epoch   6 | Train: loss=0.966, acc= 68.3% | time=1931.1ms | Valid: loss=1.020, acc= 66.0% | *\n",
            "Epoch   7 | Train: loss=0.876, acc= 70.9% | time=1923.9ms | Valid: loss=0.982, acc= 69.6% | *\n",
            "Epoch   8 | Train: loss=0.850, acc= 71.3% | time=1934.9ms | Valid: loss=1.022, acc= 66.4% |\n",
            "Epoch   9 | Train: loss=0.841, acc= 72.0% | time=1934.4ms | Valid: loss=1.019, acc= 66.0% |\n",
            "Epoch  10 | Train: loss=0.795, acc= 73.3% | time=1939.1ms | Valid: loss=0.962, acc= 69.6% | *\n",
            "Epoch  11 | Train: loss=0.764, acc= 74.7% | time=1939.4ms | Valid: loss=0.940, acc= 72.4% | *\n",
            "Epoch  12 | Train: loss=0.743, acc= 75.2% | time=1929.3ms | Valid: loss=0.914, acc= 72.0% | *\n",
            "Epoch  13 | Train: loss=0.727, acc= 76.0% | time=1925.7ms | Valid: loss=0.923, acc= 72.4% |\n",
            "Epoch  14 | Train: loss=0.703, acc= 76.2% | time=1924.4ms | Valid: loss=0.894, acc= 71.2% | *\n",
            "Epoch  15 | Train: loss=0.683, acc= 76.5% | time=1933.7ms | Valid: loss=0.952, acc= 71.6% |\n",
            "Epoch  16 | Train: loss=0.655, acc= 77.6% | time=1926.6ms | Valid: loss=0.952, acc= 71.2% |\n",
            "Epoch  17 | Train: loss=0.653, acc= 78.1% | time=1932.6ms | Valid: loss=0.946, acc= 70.8% |\n",
            "Epoch  18 | Train: loss=0.618, acc= 79.6% | time=1938.4ms | Valid: loss=0.923, acc= 71.2% |\n",
            "Epoch  19 | Train: loss=0.615, acc= 79.3% | time=1923.7ms | Valid: loss=0.972, acc= 70.0% |\n",
            "Epoch  20 | Train: loss=0.603, acc= 79.9% | time=1933.2ms | Valid: loss=0.977, acc= 73.6% | lr=5.0e-03\n",
            "Epoch  21 | Train: loss=0.580, acc= 80.9% | time=1926.6ms | Valid: loss=0.894, acc= 73.6% | *\n",
            "Epoch  22 | Train: loss=0.571, acc= 80.9% | time=1917.4ms | Valid: loss=0.914, acc= 70.8% |\n",
            "Epoch  23 | Train: loss=0.563, acc= 80.5% | time=1923.9ms | Valid: loss=0.950, acc= 71.2% |\n",
            "Epoch  24 | Train: loss=0.555, acc= 80.9% | time=1922.9ms | Valid: loss=0.885, acc= 74.0% | *\n",
            "Epoch  25 | Train: loss=0.540, acc= 82.1% | time=1926.3ms | Valid: loss=0.919, acc= 72.0% |\n",
            "Epoch  26 | Train: loss=0.537, acc= 82.3% | time=1931.3ms | Valid: loss=0.911, acc= 71.6% |\n",
            "Epoch  27 | Train: loss=0.517, acc= 82.5% | time=1929.6ms | Valid: loss=0.874, acc= 74.0% | *\n",
            "Epoch  28 | Train: loss=0.527, acc= 82.3% | time=1939.7ms | Valid: loss=0.917, acc= 72.8% |\n",
            "Epoch  29 | Train: loss=0.518, acc= 82.7% | time=1915.6ms | Valid: loss=0.891, acc= 72.4% |\n",
            "Epoch  30 | Train: loss=0.494, acc= 83.4% | time=1937.5ms | Valid: loss=0.899, acc= 73.2% |\n",
            "Epoch  31 | Train: loss=0.495, acc= 83.3% | time=1928.1ms | Valid: loss=0.895, acc= 73.6% |\n",
            "Epoch  32 | Train: loss=0.486, acc= 83.3% | time=1933.9ms | Valid: loss=0.876, acc= 74.0% |\n",
            "Epoch  33 | Train: loss=0.479, acc= 84.1% | time=1936.7ms | Valid: loss=0.905, acc= 72.8% | lr=2.5e-03\n",
            "Epoch  34 | Train: loss=0.480, acc= 84.1% | time=1922.4ms | Valid: loss=0.928, acc= 75.2% |\n",
            "Epoch  35 | Train: loss=0.470, acc= 84.4% | time=1923.6ms | Valid: loss=0.909, acc= 74.0% |\n",
            "Epoch  36 | Train: loss=0.480, acc= 84.0% | time=1919.3ms | Valid: loss=0.882, acc= 74.8% |\n",
            "Epoch  37 | Train: loss=0.468, acc= 84.4% | time=1918.0ms | Valid: loss=0.923, acc= 73.2% |\n",
            "Epoch  38 | Train: loss=0.475, acc= 83.9% | time=1923.6ms | Valid: loss=0.886, acc= 73.2% |\n",
            "Epoch  39 | Train: loss=0.465, acc= 84.4% | time=1929.5ms | Valid: loss=0.924, acc= 74.0% | lr=1.3e-03\n",
            "Epoch  40 | Train: loss=0.461, acc= 84.5% | time=1937.9ms | Valid: loss=0.915, acc= 70.8% |\n",
            "Epoch  41 | Train: loss=0.459, acc= 84.2% | time=1933.2ms | Valid: loss=0.904, acc= 74.0% |\n",
            "Epoch  42 | Train: loss=0.456, acc= 84.8% | time=1924.9ms | Valid: loss=0.889, acc= 72.4% |\n",
            "Epoch  43 | Train: loss=0.458, acc= 84.0% | time=1929.9ms | Valid: loss=0.895, acc= 73.2% |\n",
            "Epoch  44 | Train: loss=0.465, acc= 84.4% | time=1925.1ms | Valid: loss=0.912, acc= 72.0% |\n",
            "Epoch  45 | Train: loss=0.451, acc= 84.9% | time=1930.3ms | Valid: loss=0.889, acc= 73.2% | lr=6.3e-04\n",
            "Epoch  46 | Train: loss=0.456, acc= 85.0% | time=1932.3ms | Valid: loss=0.903, acc= 72.8% |\n",
            "Epoch  47 | Train: loss=0.454, acc= 84.4% | time=1928.6ms | Valid: loss=0.900, acc= 74.8% |\n",
            "Epoch  48 | Train: loss=0.447, acc= 85.1% | time=1934.7ms | Valid: loss=0.917, acc= 72.0% |\n",
            "Epoch  49 | Train: loss=0.453, acc= 84.6% | time=1931.7ms | Valid: loss=0.932, acc= 72.8% |\n",
            "Epoch  50 | Train: loss=0.451, acc= 84.9% | time=1932.0ms | Valid: loss=0.903, acc= 74.0% |\n",
            "Epoch  51 | Train: loss=0.453, acc= 84.6% | time=1935.0ms | Valid: loss=0.877, acc= 75.2% | lr=3.1e-04\n",
            "Epoch  52 | Train: loss=0.451, acc= 84.8% | time=1924.0ms | Valid: loss=0.841, acc= 75.6% | *\n",
            "Epoch  53 | Train: loss=0.447, acc= 84.8% | time=1932.7ms | Valid: loss=0.884, acc= 74.4% |\n",
            "Epoch  54 | Train: loss=0.447, acc= 84.9% | time=1929.6ms | Valid: loss=0.882, acc= 74.4% |\n",
            "Epoch  55 | Train: loss=0.445, acc= 84.9% | time=1929.3ms | Valid: loss=0.909, acc= 73.2% |\n",
            "Epoch  56 | Train: loss=0.440, acc= 85.5% | time=1927.7ms | Valid: loss=0.912, acc= 72.8% |\n",
            "Epoch  57 | Train: loss=0.447, acc= 84.8% | time=1932.1ms | Valid: loss=0.885, acc= 73.6% |\n",
            "Epoch  58 | Train: loss=0.453, acc= 84.9% | time=1937.0ms | Valid: loss=0.881, acc= 75.2% | lr=1.6e-04\n",
            "Epoch  59 | Train: loss=0.450, acc= 84.6% | time=1929.2ms | Valid: loss=0.900, acc= 73.6% |\n",
            "Epoch  60 | Train: loss=0.447, acc= 85.0% | time=1933.0ms | Valid: loss=0.904, acc= 74.4% |\n",
            "Epoch  61 | Train: loss=0.447, acc= 84.6% | time=1936.1ms | Valid: loss=0.921, acc= 74.0% |\n",
            "Epoch  62 | Train: loss=0.447, acc= 85.2% | time=1935.0ms | Valid: loss=0.878, acc= 73.2% |\n",
            "Epoch  63 | Train: loss=0.454, acc= 84.8% | time=1927.3ms | Valid: loss=0.887, acc= 74.8% |\n",
            "Epoch  64 | Train: loss=0.444, acc= 84.8% | time=1929.7ms | Valid: loss=0.913, acc= 73.2% | lr=7.8e-05\n",
            "Epoch  65 | Train: loss=0.444, acc= 85.1% | time=1935.1ms | Valid: loss=0.886, acc= 73.2% |\n",
            "Epoch  66 | Train: loss=0.446, acc= 84.8% | time=1931.9ms | Valid: loss=0.890, acc= 73.6% |\n",
            "Epoch  67 | Train: loss=0.450, acc= 84.4% | time=1929.1ms | Valid: loss=0.917, acc= 72.4% |\n",
            "Epoch  68 | Train: loss=0.437, acc= 85.7% | time=1933.2ms | Valid: loss=0.913, acc= 74.8% |\n",
            "Epoch  69 | Train: loss=0.445, acc= 84.9% | time=1930.0ms | Valid: loss=0.892, acc= 74.0% |\n",
            "Epoch  70 | Train: loss=0.445, acc= 85.1% | time=1936.7ms | Valid: loss=0.895, acc= 73.2% | lr=3.9e-05\n",
            "Epoch  71 | Train: loss=0.439, acc= 85.2% | time=1936.2ms | Valid: loss=0.890, acc= 73.6% |\n",
            "Epoch  72 | Train: loss=0.443, acc= 85.3% | time=1939.5ms | Valid: loss=0.856, acc= 74.8% |\n",
            "Epoch  73 | Train: loss=0.440, acc= 85.1% | time=1926.6ms | Valid: loss=0.898, acc= 75.2% |\n",
            "Epoch  74 | Train: loss=0.446, acc= 85.1% | time=1923.8ms | Valid: loss=0.873, acc= 76.0% |\n",
            "Epoch  75 | Train: loss=0.446, acc= 84.8% | time=1933.6ms | Valid: loss=0.919, acc= 73.2% |\n",
            "Epoch  76 | Train: loss=0.444, acc= 84.9% | time=1926.4ms | Valid: loss=0.902, acc= 74.4% | lr=2.0e-05\n",
            "Epoch  77 | Train: loss=0.441, acc= 85.2% | time=1928.7ms | Valid: loss=0.890, acc= 73.2% |\n",
            "Epoch  78 | Train: loss=0.444, acc= 84.9% | time=1924.1ms | Valid: loss=0.907, acc= 73.6% |\n",
            "Epoch  79 | Train: loss=0.439, acc= 85.2% | time=1926.9ms | Valid: loss=0.904, acc= 74.0% |\n",
            "Epoch  80 | Train: loss=0.439, acc= 85.2% | time=1931.0ms | Valid: loss=0.877, acc= 73.2% |\n",
            "Epoch  81 | Train: loss=0.447, acc= 84.5% | time=1936.8ms | Valid: loss=0.888, acc= 74.0% |\n",
            "Epoch  82 | Train: loss=0.450, acc= 84.9% | time=1920.1ms | Valid: loss=0.910, acc= 74.0% | lr=9.8e-06\n",
            "Test: loss=0.902 , acc= 71.5%\n",
            "------------------------------\n",
            "Representation Matrix\n",
            "------------------------------\n",
            "Layer 1 : (48, 20184)\n",
            "Layer 2 : (576, 14400)\n",
            "Layer 3 : (512, 2500)\n",
            "Layer 4 : (1024, 125)\n",
            "Layer 5 : (2048, 125)\n",
            "------------------------------\n",
            "Threshold:  [0.976 0.976 0.976 0.976 0.976]\n",
            "Skip Updating GPM for layer: 1\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 10/48\n",
            "Layer 2 : 181/576\n",
            "Layer 3 : 305/512\n",
            "Layer 4 : 231/1024\n",
            "Layer 5 : 292/2048\n",
            "----------------------------------------\n",
            "Accuracies =\n",
            "\t 75.6%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 76.4%  68.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 75.2%  66.6%  72.4%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "****************************************************************************************************\n",
            "Task  3 (cifar100-3)\n",
            "****************************************************************************************************\n",
            "----------------------------------------\n",
            "Task ID :3 | Learning Rate : 0.01\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([48, 48])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([576, 576])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([512, 512])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([1024, 1024])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([2048, 2048])\n",
            "----------------------------------------\n",
            "Epoch   1 | Train: loss=1.376, acc= 54.1% | time=2037.2ms | Valid: loss=1.395, acc= 54.8% | *\n",
            "Epoch   2 | Train: loss=1.248, acc= 58.4% | time=1916.1ms | Valid: loss=1.317, acc= 55.6% | *\n",
            "Epoch   3 | Train: loss=1.163, acc= 60.8% | time=1922.8ms | Valid: loss=1.231, acc= 58.4% | *\n",
            "Epoch   4 | Train: loss=1.101, acc= 63.0% | time=1924.9ms | Valid: loss=1.163, acc= 63.6% | *\n",
            "Epoch   5 | Train: loss=1.069, acc= 64.7% | time=1920.0ms | Valid: loss=1.152, acc= 64.8% | *\n",
            "Epoch   6 | Train: loss=1.052, acc= 64.7% | time=1933.4ms | Valid: loss=1.125, acc= 64.8% | *\n",
            "Epoch   7 | Train: loss=0.986, acc= 66.8% | time=1934.0ms | Valid: loss=1.081, acc= 64.8% | *\n",
            "Epoch   8 | Train: loss=1.002, acc= 66.2% | time=1942.2ms | Valid: loss=1.135, acc= 66.0% |\n",
            "Epoch   9 | Train: loss=0.933, acc= 69.7% | time=1939.4ms | Valid: loss=1.088, acc= 64.8% |\n",
            "Epoch  10 | Train: loss=0.939, acc= 69.1% | time=1929.3ms | Valid: loss=1.058, acc= 65.2% | *\n",
            "Epoch  11 | Train: loss=0.894, acc= 70.8% | time=1925.0ms | Valid: loss=1.043, acc= 65.6% | *\n",
            "Epoch  12 | Train: loss=0.862, acc= 71.9% | time=1931.5ms | Valid: loss=1.030, acc= 67.2% | *\n",
            "Epoch  13 | Train: loss=0.852, acc= 71.9% | time=1935.3ms | Valid: loss=1.022, acc= 68.4% | *\n",
            "Epoch  14 | Train: loss=0.840, acc= 72.4% | time=1929.3ms | Valid: loss=1.007, acc= 68.4% | *\n",
            "Epoch  15 | Train: loss=0.801, acc= 73.7% | time=1925.5ms | Valid: loss=0.971, acc= 70.8% | *\n",
            "Epoch  16 | Train: loss=0.801, acc= 73.2% | time=1930.2ms | Valid: loss=1.080, acc= 64.4% |\n",
            "Epoch  17 | Train: loss=0.764, acc= 74.6% | time=1926.4ms | Valid: loss=1.009, acc= 68.0% |\n",
            "Epoch  18 | Train: loss=0.760, acc= 75.0% | time=1929.4ms | Valid: loss=1.008, acc= 68.0% |\n",
            "Epoch  19 | Train: loss=0.730, acc= 75.7% | time=1928.8ms | Valid: loss=0.981, acc= 69.6% |\n",
            "Epoch  20 | Train: loss=0.737, acc= 75.5% | time=1923.4ms | Valid: loss=1.011, acc= 69.6% |\n",
            "Epoch  21 | Train: loss=0.709, acc= 76.9% | time=1936.6ms | Valid: loss=0.948, acc= 71.2% | *\n",
            "Epoch  22 | Train: loss=0.692, acc= 76.8% | time=1924.6ms | Valid: loss=0.952, acc= 72.0% |\n",
            "Epoch  23 | Train: loss=0.673, acc= 77.7% | time=1931.9ms | Valid: loss=0.957, acc= 72.0% |\n",
            "Epoch  24 | Train: loss=0.656, acc= 78.3% | time=1926.7ms | Valid: loss=0.985, acc= 69.6% |\n",
            "Epoch  25 | Train: loss=0.641, acc= 78.9% | time=1927.4ms | Valid: loss=0.965, acc= 69.2% |\n",
            "Epoch  26 | Train: loss=0.618, acc= 79.4% | time=1928.7ms | Valid: loss=0.920, acc= 73.2% | *\n",
            "Epoch  27 | Train: loss=0.621, acc= 79.7% | time=1925.5ms | Valid: loss=0.928, acc= 72.4% |\n",
            "Epoch  28 | Train: loss=0.600, acc= 80.4% | time=1927.5ms | Valid: loss=0.904, acc= 72.4% | *\n",
            "Epoch  29 | Train: loss=0.605, acc= 80.1% | time=1929.7ms | Valid: loss=0.965, acc= 68.4% |\n",
            "Epoch  30 | Train: loss=0.557, acc= 81.4% | time=1932.5ms | Valid: loss=0.915, acc= 70.8% |\n",
            "Epoch  31 | Train: loss=0.558, acc= 81.7% | time=1932.0ms | Valid: loss=0.962, acc= 71.6% |\n",
            "Epoch  32 | Train: loss=0.545, acc= 81.7% | time=1924.4ms | Valid: loss=0.923, acc= 68.8% |\n",
            "Epoch  33 | Train: loss=0.514, acc= 83.0% | time=1924.7ms | Valid: loss=0.908, acc= 72.8% |\n",
            "Epoch  34 | Train: loss=0.517, acc= 82.6% | time=1931.1ms | Valid: loss=0.905, acc= 72.8% | lr=5.0e-03\n",
            "Epoch  35 | Train: loss=0.502, acc= 83.4% | time=1930.2ms | Valid: loss=0.901, acc= 72.0% | *\n",
            "Epoch  36 | Train: loss=0.488, acc= 83.8% | time=1939.5ms | Valid: loss=0.910, acc= 74.0% |\n",
            "Epoch  37 | Train: loss=0.507, acc= 83.3% | time=1921.2ms | Valid: loss=0.953, acc= 72.8% |\n",
            "Epoch  38 | Train: loss=0.487, acc= 84.1% | time=1928.4ms | Valid: loss=0.935, acc= 72.4% |\n",
            "Epoch  39 | Train: loss=0.487, acc= 83.3% | time=1926.7ms | Valid: loss=0.928, acc= 71.6% |\n",
            "Epoch  40 | Train: loss=0.477, acc= 84.3% | time=1930.4ms | Valid: loss=0.899, acc= 74.0% | *\n",
            "Epoch  41 | Train: loss=0.467, acc= 84.8% | time=1929.8ms | Valid: loss=0.921, acc= 72.8% |\n",
            "Epoch  42 | Train: loss=0.458, acc= 85.1% | time=1931.8ms | Valid: loss=0.890, acc= 72.4% | *\n",
            "Epoch  43 | Train: loss=0.473, acc= 84.3% | time=1932.2ms | Valid: loss=0.908, acc= 70.8% |\n",
            "Epoch  44 | Train: loss=0.445, acc= 85.6% | time=1925.5ms | Valid: loss=0.919, acc= 73.6% |\n",
            "Epoch  45 | Train: loss=0.448, acc= 85.2% | time=1925.6ms | Valid: loss=0.890, acc= 72.4% | *\n",
            "Epoch  46 | Train: loss=0.440, acc= 85.5% | time=1931.5ms | Valid: loss=0.884, acc= 73.2% | *\n",
            "Epoch  47 | Train: loss=0.429, acc= 85.8% | time=1922.9ms | Valid: loss=0.889, acc= 76.0% |\n",
            "Epoch  48 | Train: loss=0.434, acc= 85.6% | time=1928.9ms | Valid: loss=0.892, acc= 71.6% |\n",
            "Epoch  49 | Train: loss=0.416, acc= 86.1% | time=1927.8ms | Valid: loss=0.933, acc= 71.6% |\n",
            "Epoch  50 | Train: loss=0.421, acc= 86.2% | time=1927.3ms | Valid: loss=0.914, acc= 74.4% |\n",
            "Epoch  51 | Train: loss=0.402, acc= 86.6% | time=1916.0ms | Valid: loss=0.891, acc= 73.6% |\n",
            "Epoch  52 | Train: loss=0.400, acc= 86.5% | time=1928.8ms | Valid: loss=0.876, acc= 75.2% | *\n",
            "Epoch  53 | Train: loss=0.401, acc= 87.1% | time=1921.6ms | Valid: loss=0.912, acc= 73.6% |\n",
            "Epoch  54 | Train: loss=0.404, acc= 86.5% | time=1928.1ms | Valid: loss=0.932, acc= 73.6% |\n",
            "Epoch  55 | Train: loss=0.401, acc= 86.9% | time=1925.6ms | Valid: loss=0.923, acc= 73.6% |\n",
            "Epoch  56 | Train: loss=0.375, acc= 87.5% | time=1921.9ms | Valid: loss=0.876, acc= 74.4% |\n",
            "Epoch  57 | Train: loss=0.379, acc= 87.2% | time=1928.8ms | Valid: loss=0.880, acc= 76.0% |\n",
            "Epoch  58 | Train: loss=0.379, acc= 87.4% | time=1923.0ms | Valid: loss=0.893, acc= 74.8% | lr=2.5e-03\n",
            "Epoch  59 | Train: loss=0.376, acc= 87.5% | time=1926.1ms | Valid: loss=0.910, acc= 74.4% |\n",
            "Epoch  60 | Train: loss=0.379, acc= 87.5% | time=1922.5ms | Valid: loss=0.882, acc= 73.6% |\n",
            "Epoch  61 | Train: loss=0.362, acc= 88.0% | time=1926.7ms | Valid: loss=0.867, acc= 74.0% | *\n",
            "Epoch  62 | Train: loss=0.366, acc= 87.8% | time=1927.0ms | Valid: loss=0.892, acc= 73.2% |\n",
            "Epoch  63 | Train: loss=0.370, acc= 87.8% | time=1933.7ms | Valid: loss=0.885, acc= 74.8% |\n",
            "Epoch  64 | Train: loss=0.366, acc= 87.9% | time=1921.5ms | Valid: loss=0.901, acc= 73.6% |\n",
            "Epoch  65 | Train: loss=0.353, acc= 88.4% | time=1923.6ms | Valid: loss=0.964, acc= 70.4% |\n",
            "Epoch  66 | Train: loss=0.360, acc= 88.3% | time=1922.9ms | Valid: loss=0.880, acc= 73.6% |\n",
            "Epoch  67 | Train: loss=0.357, acc= 88.4% | time=1917.3ms | Valid: loss=0.938, acc= 73.2% | lr=1.3e-03\n",
            "Epoch  68 | Train: loss=0.351, acc= 88.5% | time=1925.5ms | Valid: loss=0.882, acc= 75.6% |\n",
            "Epoch  69 | Train: loss=0.353, acc= 88.4% | time=1923.7ms | Valid: loss=0.934, acc= 76.4% |\n",
            "Epoch  70 | Train: loss=0.346, acc= 88.8% | time=1922.6ms | Valid: loss=0.918, acc= 73.2% |\n",
            "Epoch  71 | Train: loss=0.347, acc= 88.6% | time=1918.4ms | Valid: loss=0.882, acc= 72.4% |\n",
            "Epoch  72 | Train: loss=0.349, acc= 88.4% | time=1924.6ms | Valid: loss=0.901, acc= 73.2% |\n",
            "Epoch  73 | Train: loss=0.344, acc= 88.9% | time=1929.0ms | Valid: loss=0.937, acc= 72.8% | lr=6.3e-04\n",
            "Epoch  74 | Train: loss=0.355, acc= 88.2% | time=1927.3ms | Valid: loss=0.885, acc= 73.6% |\n",
            "Epoch  75 | Train: loss=0.346, acc= 88.9% | time=1923.3ms | Valid: loss=0.914, acc= 74.0% |\n",
            "Epoch  76 | Train: loss=0.341, acc= 88.8% | time=1934.1ms | Valid: loss=0.853, acc= 74.4% | *\n",
            "Epoch  77 | Train: loss=0.347, acc= 88.7% | time=1922.6ms | Valid: loss=0.892, acc= 75.2% |\n",
            "Epoch  78 | Train: loss=0.345, acc= 89.3% | time=1928.3ms | Valid: loss=0.983, acc= 74.4% |\n",
            "Epoch  79 | Train: loss=0.350, acc= 88.4% | time=1939.7ms | Valid: loss=0.848, acc= 74.4% | *\n",
            "Epoch  80 | Train: loss=0.347, acc= 88.4% | time=1933.5ms | Valid: loss=0.882, acc= 74.4% |\n",
            "Epoch  81 | Train: loss=0.340, acc= 89.3% | time=1920.1ms | Valid: loss=0.929, acc= 76.8% |\n",
            "Epoch  82 | Train: loss=0.351, acc= 88.4% | time=1930.6ms | Valid: loss=0.909, acc= 74.4% |\n",
            "Epoch  83 | Train: loss=0.344, acc= 88.8% | time=1927.4ms | Valid: loss=0.886, acc= 75.2% |\n",
            "Epoch  84 | Train: loss=0.340, acc= 88.7% | time=1930.4ms | Valid: loss=0.912, acc= 74.0% |\n",
            "Epoch  85 | Train: loss=0.338, acc= 88.9% | time=1925.8ms | Valid: loss=0.884, acc= 73.2% | lr=3.1e-04\n",
            "Epoch  86 | Train: loss=0.343, acc= 88.6% | time=1921.7ms | Valid: loss=0.893, acc= 74.0% |\n",
            "Epoch  87 | Train: loss=0.346, acc= 88.5% | time=1925.3ms | Valid: loss=0.962, acc= 70.8% |\n",
            "Epoch  88 | Train: loss=0.343, acc= 89.0% | time=1936.0ms | Valid: loss=0.884, acc= 75.2% |\n",
            "Epoch  89 | Train: loss=0.332, acc= 89.3% | time=1926.0ms | Valid: loss=0.863, acc= 73.6% |\n",
            "Epoch  90 | Train: loss=0.340, acc= 88.9% | time=1924.6ms | Valid: loss=0.918, acc= 74.0% |\n",
            "Epoch  91 | Train: loss=0.343, acc= 88.7% | time=1923.5ms | Valid: loss=0.831, acc= 76.4% | *\n",
            "Epoch  92 | Train: loss=0.336, acc= 88.6% | time=1924.4ms | Valid: loss=0.877, acc= 73.2% |\n",
            "Epoch  93 | Train: loss=0.336, acc= 89.2% | time=1927.3ms | Valid: loss=0.888, acc= 75.2% |\n",
            "Epoch  94 | Train: loss=0.332, acc= 89.4% | time=1925.7ms | Valid: loss=0.895, acc= 74.0% |\n",
            "Epoch  95 | Train: loss=0.333, acc= 89.0% | time=1928.1ms | Valid: loss=0.904, acc= 74.4% |\n",
            "Epoch  96 | Train: loss=0.339, acc= 89.0% | time=1923.2ms | Valid: loss=0.892, acc= 74.8% |\n",
            "Epoch  97 | Train: loss=0.339, acc= 88.8% | time=1925.5ms | Valid: loss=0.902, acc= 74.0% | lr=1.6e-04\n",
            "Epoch  98 | Train: loss=0.336, acc= 88.7% | time=1930.3ms | Valid: loss=0.893, acc= 72.8% |\n",
            "Epoch  99 | Train: loss=0.336, acc= 89.1% | time=1928.4ms | Valid: loss=0.891, acc= 73.6% |\n",
            "Epoch 100 | Train: loss=0.329, acc= 89.3% | time=1921.5ms | Valid: loss=0.884, acc= 73.6% |\n",
            "Epoch 101 | Train: loss=0.330, acc= 89.0% | time=1926.5ms | Valid: loss=0.959, acc= 73.2% |\n",
            "Epoch 102 | Train: loss=0.340, acc= 88.7% | time=1927.2ms | Valid: loss=0.895, acc= 74.8% |\n",
            "Epoch 103 | Train: loss=0.335, acc= 88.9% | time=1934.9ms | Valid: loss=0.898, acc= 74.4% | lr=7.8e-05\n",
            "Epoch 104 | Train: loss=0.337, acc= 88.9% | time=1923.6ms | Valid: loss=0.881, acc= 74.0% |\n",
            "Epoch 105 | Train: loss=0.339, acc= 88.9% | time=1919.4ms | Valid: loss=0.897, acc= 74.4% |\n",
            "Epoch 106 | Train: loss=0.336, acc= 89.2% | time=1928.7ms | Valid: loss=0.868, acc= 73.6% |\n",
            "Epoch 107 | Train: loss=0.336, acc= 89.2% | time=1930.0ms | Valid: loss=0.899, acc= 76.4% |\n",
            "Epoch 108 | Train: loss=0.338, acc= 88.9% | time=1931.8ms | Valid: loss=0.935, acc= 74.0% |\n",
            "Epoch 109 | Train: loss=0.337, acc= 89.4% | time=1923.1ms | Valid: loss=0.883, acc= 76.8% | lr=3.9e-05\n",
            "Epoch 110 | Train: loss=0.338, acc= 88.7% | time=1920.5ms | Valid: loss=0.907, acc= 73.2% |\n",
            "Epoch 111 | Train: loss=0.335, acc= 89.3% | time=1926.4ms | Valid: loss=0.918, acc= 75.2% |\n",
            "Epoch 112 | Train: loss=0.336, acc= 89.1% | time=1917.8ms | Valid: loss=0.869, acc= 74.0% |\n",
            "Epoch 113 | Train: loss=0.345, acc= 88.7% | time=1928.3ms | Valid: loss=0.865, acc= 74.8% |\n",
            "Epoch 114 | Train: loss=0.339, acc= 88.8% | time=1926.6ms | Valid: loss=0.877, acc= 73.6% |\n",
            "Epoch 115 | Train: loss=0.341, acc= 89.1% | time=1925.9ms | Valid: loss=0.875, acc= 75.6% | lr=2.0e-05\n",
            "Epoch 116 | Train: loss=0.340, acc= 88.8% | time=1929.0ms | Valid: loss=0.873, acc= 76.0% |\n",
            "Epoch 117 | Train: loss=0.338, acc= 89.1% | time=1926.6ms | Valid: loss=0.886, acc= 72.4% |\n",
            "Epoch 118 | Train: loss=0.338, acc= 88.9% | time=1925.7ms | Valid: loss=0.882, acc= 73.2% |\n",
            "Epoch 119 | Train: loss=0.338, acc= 89.0% | time=1923.8ms | Valid: loss=0.938, acc= 72.0% |\n",
            "Epoch 120 | Train: loss=0.334, acc= 89.1% | time=1922.7ms | Valid: loss=0.889, acc= 72.4% |\n",
            "Epoch 121 | Train: loss=0.334, acc= 88.8% | time=1929.5ms | Valid: loss=0.879, acc= 75.2% | lr=9.8e-06\n",
            "Test: loss=0.946 , acc= 70.5%\n",
            "------------------------------\n",
            "Representation Matrix\n",
            "------------------------------\n",
            "Layer 1 : (48, 20184)\n",
            "Layer 2 : (576, 14400)\n",
            "Layer 3 : (512, 2500)\n",
            "Layer 4 : (1024, 125)\n",
            "Layer 5 : (2048, 125)\n",
            "------------------------------\n",
            "Threshold:  [0.979 0.979 0.979 0.979 0.979]\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 11/48\n",
            "Layer 2 : 213/576\n",
            "Layer 3 : 335/512\n",
            "Layer 4 : 306/1024\n",
            "Layer 5 : 390/2048\n",
            "----------------------------------------\n",
            "Accuracies =\n",
            "\t 75.6%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 76.4%  68.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 75.2%  66.6%  72.4%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 75.0%  66.3%  72.0%  71.4%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "****************************************************************************************************\n",
            "Task  4 (cifar100-4)\n",
            "****************************************************************************************************\n",
            "----------------------------------------\n",
            "Task ID :4 | Learning Rate : 0.01\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([48, 48])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([576, 576])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([512, 512])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([1024, 1024])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([2048, 2048])\n",
            "----------------------------------------\n",
            "Epoch   1 | Train: loss=1.158, acc= 62.3% | time=1978.4ms | Valid: loss=1.241, acc= 57.6% | *\n",
            "Epoch   2 | Train: loss=1.044, acc= 64.3% | time=1914.3ms | Valid: loss=1.150, acc= 59.6% | *\n",
            "Epoch   3 | Train: loss=0.992, acc= 66.2% | time=1929.1ms | Valid: loss=1.145, acc= 64.0% | *\n",
            "Epoch   4 | Train: loss=0.929, acc= 67.9% | time=1920.1ms | Valid: loss=1.105, acc= 62.4% | *\n",
            "Epoch   5 | Train: loss=0.909, acc= 69.7% | time=1927.9ms | Valid: loss=1.139, acc= 63.2% |\n",
            "Epoch   6 | Train: loss=0.874, acc= 70.0% | time=1931.3ms | Valid: loss=1.102, acc= 63.2% | *\n",
            "Epoch   7 | Train: loss=0.846, acc= 70.9% | time=1933.4ms | Valid: loss=1.099, acc= 64.8% | *\n",
            "Epoch   8 | Train: loss=0.799, acc= 72.4% | time=1926.5ms | Valid: loss=1.052, acc= 64.0% | *\n",
            "Epoch   9 | Train: loss=0.818, acc= 72.1% | time=1935.3ms | Valid: loss=1.120, acc= 64.0% |\n",
            "Epoch  10 | Train: loss=0.780, acc= 73.5% | time=1923.8ms | Valid: loss=1.054, acc= 64.4% |\n",
            "Epoch  11 | Train: loss=0.771, acc= 73.5% | time=1925.9ms | Valid: loss=1.089, acc= 63.6% |\n",
            "Epoch  12 | Train: loss=0.718, acc= 75.3% | time=1928.4ms | Valid: loss=1.007, acc= 67.6% | *\n",
            "Epoch  13 | Train: loss=0.726, acc= 75.3% | time=1921.6ms | Valid: loss=1.033, acc= 66.4% |\n",
            "Epoch  14 | Train: loss=0.691, acc= 76.7% | time=1920.5ms | Valid: loss=0.988, acc= 65.6% | *\n",
            "Epoch  15 | Train: loss=0.682, acc= 76.7% | time=1931.1ms | Valid: loss=1.091, acc= 62.0% |\n",
            "Epoch  16 | Train: loss=0.674, acc= 77.1% | time=1927.5ms | Valid: loss=1.019, acc= 64.8% |\n",
            "Epoch  17 | Train: loss=0.647, acc= 78.1% | time=1928.3ms | Valid: loss=0.954, acc= 67.2% | *\n",
            "Epoch  18 | Train: loss=0.664, acc= 77.7% | time=1923.5ms | Valid: loss=1.039, acc= 66.8% |\n",
            "Epoch  19 | Train: loss=0.624, acc= 79.2% | time=1933.3ms | Valid: loss=0.993, acc= 67.6% |\n",
            "Epoch  20 | Train: loss=0.603, acc= 79.5% | time=1920.8ms | Valid: loss=0.972, acc= 68.8% |\n",
            "Epoch  21 | Train: loss=0.576, acc= 80.4% | time=1921.9ms | Valid: loss=0.960, acc= 68.0% |\n",
            "Epoch  22 | Train: loss=0.587, acc= 79.9% | time=1919.1ms | Valid: loss=1.038, acc= 65.6% |\n",
            "Epoch  23 | Train: loss=0.586, acc= 80.0% | time=1930.6ms | Valid: loss=1.005, acc= 66.8% | lr=5.0e-03\n",
            "Epoch  24 | Train: loss=0.554, acc= 81.2% | time=1930.5ms | Valid: loss=0.965, acc= 68.0% |\n",
            "Epoch  25 | Train: loss=0.545, acc= 81.5% | time=1927.8ms | Valid: loss=0.985, acc= 69.6% |\n",
            "Epoch  26 | Train: loss=0.538, acc= 81.8% | time=1922.3ms | Valid: loss=0.967, acc= 69.6% |\n",
            "Epoch  27 | Train: loss=0.539, acc= 81.9% | time=1933.5ms | Valid: loss=0.996, acc= 68.4% |\n",
            "Epoch  28 | Train: loss=0.541, acc= 81.5% | time=1920.7ms | Valid: loss=0.980, acc= 70.4% |\n",
            "Epoch  29 | Train: loss=0.518, acc= 82.4% | time=1923.3ms | Valid: loss=0.949, acc= 69.6% | *\n",
            "Epoch  30 | Train: loss=0.515, acc= 82.5% | time=1924.5ms | Valid: loss=0.950, acc= 69.2% |\n",
            "Epoch  31 | Train: loss=0.511, acc= 82.6% | time=1926.3ms | Valid: loss=0.951, acc= 70.8% |\n",
            "Epoch  32 | Train: loss=0.495, acc= 83.2% | time=1922.1ms | Valid: loss=0.920, acc= 70.8% | *\n",
            "Epoch  33 | Train: loss=0.499, acc= 83.1% | time=1924.6ms | Valid: loss=0.956, acc= 70.0% |\n",
            "Epoch  34 | Train: loss=0.490, acc= 83.5% | time=1921.0ms | Valid: loss=0.961, acc= 70.0% |\n",
            "Epoch  35 | Train: loss=0.493, acc= 83.2% | time=1920.6ms | Valid: loss=0.972, acc= 70.4% |\n",
            "Epoch  36 | Train: loss=0.479, acc= 84.3% | time=1919.6ms | Valid: loss=0.919, acc= 71.6% | *\n",
            "Epoch  37 | Train: loss=0.471, acc= 83.9% | time=1918.8ms | Valid: loss=0.981, acc= 70.4% |\n",
            "Epoch  38 | Train: loss=0.479, acc= 83.5% | time=1925.8ms | Valid: loss=0.919, acc= 70.8% |\n",
            "Epoch  39 | Train: loss=0.475, acc= 83.8% | time=1920.3ms | Valid: loss=0.990, acc= 68.8% |\n",
            "Epoch  40 | Train: loss=0.436, acc= 84.5% | time=1929.8ms | Valid: loss=0.919, acc= 70.4% |\n",
            "Epoch  41 | Train: loss=0.451, acc= 84.8% | time=1914.3ms | Valid: loss=0.882, acc= 70.8% | *\n",
            "Epoch  42 | Train: loss=0.445, acc= 84.8% | time=1931.3ms | Valid: loss=0.940, acc= 72.8% |\n",
            "Epoch  43 | Train: loss=0.443, acc= 85.1% | time=1920.0ms | Valid: loss=0.906, acc= 67.2% |\n",
            "Epoch  44 | Train: loss=0.439, acc= 84.9% | time=1924.7ms | Valid: loss=0.940, acc= 68.0% |\n",
            "Epoch  45 | Train: loss=0.444, acc= 84.5% | time=1927.9ms | Valid: loss=0.935, acc= 71.2% |\n",
            "Epoch  46 | Train: loss=0.424, acc= 85.5% | time=1920.3ms | Valid: loss=0.941, acc= 70.8% |\n",
            "Epoch  47 | Train: loss=0.418, acc= 85.9% | time=1916.2ms | Valid: loss=0.985, acc= 71.2% | lr=2.5e-03\n",
            "Epoch  48 | Train: loss=0.407, acc= 86.0% | time=1937.8ms | Valid: loss=0.933, acc= 68.0% |\n",
            "Epoch  49 | Train: loss=0.411, acc= 86.0% | time=1931.9ms | Valid: loss=0.930, acc= 70.0% |\n",
            "Epoch  50 | Train: loss=0.415, acc= 86.0% | time=1928.5ms | Valid: loss=0.942, acc= 70.8% |\n",
            "Epoch  51 | Train: loss=0.416, acc= 85.4% | time=1924.8ms | Valid: loss=0.894, acc= 72.4% |\n",
            "Epoch  52 | Train: loss=0.409, acc= 86.1% | time=1922.6ms | Valid: loss=0.918, acc= 70.4% |\n",
            "Epoch  53 | Train: loss=0.405, acc= 86.1% | time=1918.2ms | Valid: loss=0.926, acc= 70.4% | lr=1.3e-03\n",
            "Epoch  54 | Train: loss=0.409, acc= 86.2% | time=1928.3ms | Valid: loss=0.940, acc= 71.6% |\n",
            "Epoch  55 | Train: loss=0.405, acc= 86.2% | time=1924.9ms | Valid: loss=0.910, acc= 69.6% |\n",
            "Epoch  56 | Train: loss=0.407, acc= 86.3% | time=1922.3ms | Valid: loss=0.978, acc= 70.8% |\n",
            "Epoch  57 | Train: loss=0.396, acc= 86.5% | time=1920.6ms | Valid: loss=0.905, acc= 70.8% |\n",
            "Epoch  58 | Train: loss=0.402, acc= 86.5% | time=1920.2ms | Valid: loss=0.897, acc= 70.8% |\n",
            "Epoch  59 | Train: loss=0.406, acc= 85.9% | time=1916.7ms | Valid: loss=0.976, acc= 68.4% | lr=6.3e-04\n",
            "Epoch  60 | Train: loss=0.401, acc= 86.3% | time=1932.7ms | Valid: loss=0.945, acc= 70.0% |\n",
            "Epoch  61 | Train: loss=0.397, acc= 86.6% | time=1918.6ms | Valid: loss=0.912, acc= 69.2% |\n",
            "Epoch  62 | Train: loss=0.401, acc= 86.2% | time=1925.2ms | Valid: loss=0.928, acc= 69.2% |\n",
            "Epoch  63 | Train: loss=0.404, acc= 86.2% | time=1929.5ms | Valid: loss=0.935, acc= 69.2% |\n",
            "Epoch  64 | Train: loss=0.399, acc= 86.9% | time=1922.9ms | Valid: loss=0.898, acc= 73.6% |\n",
            "Epoch  65 | Train: loss=0.400, acc= 86.3% | time=1926.0ms | Valid: loss=0.920, acc= 72.0% | lr=3.1e-04\n",
            "Epoch  66 | Train: loss=0.394, acc= 86.6% | time=1919.3ms | Valid: loss=0.936, acc= 70.4% |\n",
            "Epoch  67 | Train: loss=0.400, acc= 86.7% | time=1921.8ms | Valid: loss=0.931, acc= 71.2% |\n",
            "Epoch  68 | Train: loss=0.395, acc= 86.3% | time=1930.3ms | Valid: loss=0.966, acc= 70.0% |\n",
            "Epoch  69 | Train: loss=0.398, acc= 86.3% | time=1923.7ms | Valid: loss=0.915, acc= 71.2% |\n",
            "Epoch  70 | Train: loss=0.399, acc= 86.1% | time=1917.6ms | Valid: loss=0.897, acc= 70.8% |\n",
            "Epoch  71 | Train: loss=0.390, acc= 86.5% | time=1930.5ms | Valid: loss=0.913, acc= 73.6% | lr=1.6e-04\n",
            "Epoch  72 | Train: loss=0.392, acc= 86.8% | time=1925.0ms | Valid: loss=0.937, acc= 72.8% |\n",
            "Epoch  73 | Train: loss=0.398, acc= 86.4% | time=1930.6ms | Valid: loss=0.971, acc= 68.8% |\n",
            "Epoch  74 | Train: loss=0.394, acc= 86.2% | time=1918.6ms | Valid: loss=0.918, acc= 72.4% |\n",
            "Epoch  75 | Train: loss=0.391, acc= 86.5% | time=1924.5ms | Valid: loss=0.943, acc= 69.6% |\n",
            "Epoch  76 | Train: loss=0.395, acc= 86.9% | time=1922.5ms | Valid: loss=0.939, acc= 70.0% |\n",
            "Epoch  77 | Train: loss=0.389, acc= 87.1% | time=1925.0ms | Valid: loss=0.944, acc= 68.8% | lr=7.8e-05\n",
            "Epoch  78 | Train: loss=0.401, acc= 86.4% | time=1931.9ms | Valid: loss=0.937, acc= 70.8% |\n",
            "Epoch  79 | Train: loss=0.397, acc= 86.6% | time=1921.1ms | Valid: loss=0.919, acc= 69.6% |\n",
            "Epoch  80 | Train: loss=0.395, acc= 86.7% | time=1925.1ms | Valid: loss=0.901, acc= 73.6% |\n",
            "Epoch  81 | Train: loss=0.395, acc= 86.7% | time=1923.4ms | Valid: loss=0.941, acc= 70.0% |\n",
            "Epoch  82 | Train: loss=0.398, acc= 86.4% | time=1929.0ms | Valid: loss=0.936, acc= 72.4% |\n",
            "Epoch  83 | Train: loss=0.389, acc= 86.5% | time=1921.5ms | Valid: loss=0.918, acc= 71.2% | lr=3.9e-05\n",
            "Epoch  84 | Train: loss=0.393, acc= 86.0% | time=1925.1ms | Valid: loss=0.948, acc= 72.8% |\n",
            "Epoch  85 | Train: loss=0.392, acc= 86.9% | time=1928.4ms | Valid: loss=0.913, acc= 70.4% |\n",
            "Epoch  86 | Train: loss=0.392, acc= 86.4% | time=1919.4ms | Valid: loss=0.927, acc= 72.0% |\n",
            "Epoch  87 | Train: loss=0.405, acc= 85.9% | time=1925.1ms | Valid: loss=0.921, acc= 72.4% |\n",
            "Epoch  88 | Train: loss=0.396, acc= 86.5% | time=1932.0ms | Valid: loss=0.927, acc= 70.0% |\n",
            "Epoch  89 | Train: loss=0.397, acc= 86.7% | time=1920.6ms | Valid: loss=0.894, acc= 73.6% | lr=2.0e-05\n",
            "Epoch  90 | Train: loss=0.393, acc= 86.7% | time=1927.3ms | Valid: loss=0.890, acc= 71.2% |\n",
            "Epoch  91 | Train: loss=0.395, acc= 86.5% | time=1921.3ms | Valid: loss=0.935, acc= 69.6% |\n",
            "Epoch  92 | Train: loss=0.390, acc= 86.8% | time=1916.3ms | Valid: loss=0.912, acc= 71.6% |\n",
            "Epoch  93 | Train: loss=0.385, acc= 86.8% | time=1923.3ms | Valid: loss=0.933, acc= 71.2% |\n",
            "Epoch  94 | Train: loss=0.395, acc= 86.4% | time=1920.4ms | Valid: loss=0.889, acc= 72.8% |\n",
            "Epoch  95 | Train: loss=0.388, acc= 86.2% | time=1923.6ms | Valid: loss=0.946, acc= 69.6% | lr=9.8e-06\n",
            "Test: loss=0.913 , acc= 72.9%\n",
            "------------------------------\n",
            "Representation Matrix\n",
            "------------------------------\n",
            "Layer 1 : (48, 20184)\n",
            "Layer 2 : (576, 14400)\n",
            "Layer 3 : (512, 2500)\n",
            "Layer 4 : (1024, 125)\n",
            "Layer 5 : (2048, 125)\n",
            "------------------------------\n",
            "Threshold:  [0.982 0.982 0.982 0.982 0.982]\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 12/48\n",
            "Layer 2 : 243/576\n",
            "Layer 3 : 360/512\n",
            "Layer 4 : 377/1024\n",
            "Layer 5 : 487/2048\n",
            "----------------------------------------\n",
            "Accuracies =\n",
            "\t 75.6%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 76.4%  68.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 75.2%  66.6%  72.4%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 75.0%  66.3%  72.0%  71.4%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 74.6%  67.2%  71.8%  71.2%  74.4%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "****************************************************************************************************\n",
            "Task  5 (cifar100-5)\n",
            "****************************************************************************************************\n",
            "----------------------------------------\n",
            "Task ID :5 | Learning Rate : 0.01\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([48, 48])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([576, 576])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([512, 512])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([1024, 1024])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([2048, 2048])\n",
            "----------------------------------------\n",
            "Epoch   1 | Train: loss=1.149, acc= 59.8% | time=1955.7ms | Valid: loss=1.101, acc= 63.2% | *\n",
            "Epoch   2 | Train: loss=1.035, acc= 63.3% | time=1916.3ms | Valid: loss=1.049, acc= 61.6% | *\n",
            "Epoch   3 | Train: loss=0.967, acc= 66.1% | time=1918.7ms | Valid: loss=1.003, acc= 63.2% | *\n",
            "Epoch   4 | Train: loss=0.924, acc= 67.6% | time=1913.7ms | Valid: loss=0.949, acc= 65.6% | *\n",
            "Epoch   5 | Train: loss=0.906, acc= 68.2% | time=1925.8ms | Valid: loss=0.968, acc= 66.4% |\n",
            "Epoch   6 | Train: loss=0.919, acc= 67.7% | time=1918.7ms | Valid: loss=0.997, acc= 65.2% |\n",
            "Epoch   7 | Train: loss=0.857, acc= 70.2% | time=1921.2ms | Valid: loss=0.925, acc= 67.2% | *\n",
            "Epoch   8 | Train: loss=0.803, acc= 71.2% | time=1922.8ms | Valid: loss=0.856, acc= 69.6% | *\n",
            "Epoch   9 | Train: loss=0.804, acc= 71.0% | time=1924.0ms | Valid: loss=0.856, acc= 68.0% |\n",
            "Epoch  10 | Train: loss=0.783, acc= 72.9% | time=1924.6ms | Valid: loss=0.831, acc= 70.0% | *\n",
            "Epoch  11 | Train: loss=0.773, acc= 72.4% | time=1913.8ms | Valid: loss=0.885, acc= 66.8% |\n",
            "Epoch  12 | Train: loss=0.747, acc= 73.6% | time=1929.1ms | Valid: loss=0.871, acc= 68.0% |\n",
            "Epoch  13 | Train: loss=0.741, acc= 73.7% | time=1925.5ms | Valid: loss=0.822, acc= 68.4% | *\n",
            "Epoch  14 | Train: loss=0.734, acc= 73.9% | time=1916.4ms | Valid: loss=0.833, acc= 68.8% |\n",
            "Epoch  15 | Train: loss=0.709, acc= 74.8% | time=1918.3ms | Valid: loss=0.864, acc= 68.4% |\n",
            "Epoch  16 | Train: loss=0.682, acc= 76.0% | time=1912.2ms | Valid: loss=0.871, acc= 69.6% |\n",
            "Epoch  17 | Train: loss=0.704, acc= 74.7% | time=1924.6ms | Valid: loss=0.830, acc= 68.8% |\n",
            "Epoch  18 | Train: loss=0.650, acc= 76.7% | time=1926.4ms | Valid: loss=0.813, acc= 68.8% | *\n",
            "Epoch  19 | Train: loss=0.654, acc= 76.7% | time=1917.1ms | Valid: loss=0.818, acc= 70.8% |\n",
            "Epoch  20 | Train: loss=0.639, acc= 77.1% | time=1936.2ms | Valid: loss=0.834, acc= 70.4% |\n",
            "Epoch  21 | Train: loss=0.630, acc= 77.6% | time=1925.2ms | Valid: loss=0.752, acc= 73.2% | *\n",
            "Epoch  22 | Train: loss=0.610, acc= 77.7% | time=1926.2ms | Valid: loss=0.816, acc= 69.6% |\n",
            "Epoch  23 | Train: loss=0.596, acc= 78.3% | time=1926.0ms | Valid: loss=0.806, acc= 71.2% |\n",
            "Epoch  24 | Train: loss=0.609, acc= 77.6% | time=1924.2ms | Valid: loss=0.840, acc= 72.4% |\n",
            "Epoch  25 | Train: loss=0.594, acc= 78.9% | time=1925.6ms | Valid: loss=0.814, acc= 72.4% |\n",
            "Epoch  26 | Train: loss=0.572, acc= 79.6% | time=1931.0ms | Valid: loss=0.825, acc= 72.0% |\n",
            "Epoch  27 | Train: loss=0.551, acc= 80.7% | time=1924.7ms | Valid: loss=0.774, acc= 73.2% | lr=5.0e-03\n",
            "Epoch  28 | Train: loss=0.559, acc= 80.1% | time=1933.0ms | Valid: loss=0.781, acc= 71.6% |\n",
            "Epoch  29 | Train: loss=0.552, acc= 80.1% | time=1913.1ms | Valid: loss=0.795, acc= 71.2% |\n",
            "Epoch  30 | Train: loss=0.538, acc= 80.5% | time=1923.2ms | Valid: loss=0.764, acc= 73.2% |\n",
            "Epoch  31 | Train: loss=0.546, acc= 80.3% | time=1925.6ms | Valid: loss=0.814, acc= 72.0% |\n",
            "Epoch  32 | Train: loss=0.528, acc= 81.1% | time=1923.8ms | Valid: loss=0.787, acc= 69.6% |\n",
            "Epoch  33 | Train: loss=0.536, acc= 80.4% | time=1921.0ms | Valid: loss=0.762, acc= 73.6% | lr=2.5e-03\n",
            "Epoch  34 | Train: loss=0.517, acc= 81.2% | time=1921.0ms | Valid: loss=0.734, acc= 72.8% | *\n",
            "Epoch  35 | Train: loss=0.528, acc= 80.7% | time=1927.6ms | Valid: loss=0.759, acc= 71.6% |\n",
            "Epoch  36 | Train: loss=0.528, acc= 80.8% | time=1922.9ms | Valid: loss=0.814, acc= 73.6% |\n",
            "Epoch  37 | Train: loss=0.515, acc= 81.7% | time=1930.8ms | Valid: loss=0.748, acc= 72.0% |\n",
            "Epoch  38 | Train: loss=0.510, acc= 81.3% | time=1923.3ms | Valid: loss=0.798, acc= 71.6% |\n",
            "Epoch  39 | Train: loss=0.512, acc= 81.6% | time=1922.8ms | Valid: loss=0.817, acc= 70.4% |\n",
            "Epoch  40 | Train: loss=0.513, acc= 81.4% | time=1926.7ms | Valid: loss=0.765, acc= 72.0% | lr=1.3e-03\n",
            "Epoch  41 | Train: loss=0.505, acc= 81.8% | time=1922.8ms | Valid: loss=0.759, acc= 72.4% |\n",
            "Epoch  42 | Train: loss=0.508, acc= 81.5% | time=1916.2ms | Valid: loss=0.741, acc= 73.6% |\n",
            "Epoch  43 | Train: loss=0.500, acc= 82.3% | time=1923.2ms | Valid: loss=0.736, acc= 73.6% |\n",
            "Epoch  44 | Train: loss=0.498, acc= 82.3% | time=1926.2ms | Valid: loss=0.760, acc= 73.2% |\n",
            "Epoch  45 | Train: loss=0.501, acc= 81.3% | time=1919.6ms | Valid: loss=0.763, acc= 71.2% |\n",
            "Epoch  46 | Train: loss=0.501, acc= 81.9% | time=1930.6ms | Valid: loss=0.771, acc= 73.2% | lr=6.3e-04\n",
            "Epoch  47 | Train: loss=0.505, acc= 81.9% | time=1924.0ms | Valid: loss=0.803, acc= 69.2% |\n",
            "Epoch  48 | Train: loss=0.489, acc= 82.3% | time=1921.1ms | Valid: loss=0.732, acc= 73.2% | *\n",
            "Epoch  49 | Train: loss=0.510, acc= 81.7% | time=1926.5ms | Valid: loss=0.785, acc= 71.6% |\n",
            "Epoch  50 | Train: loss=0.498, acc= 82.2% | time=1925.1ms | Valid: loss=0.738, acc= 73.2% |\n",
            "Epoch  51 | Train: loss=0.501, acc= 81.9% | time=1916.2ms | Valid: loss=0.762, acc= 71.6% |\n",
            "Epoch  52 | Train: loss=0.499, acc= 81.6% | time=1927.6ms | Valid: loss=0.806, acc= 71.6% |\n",
            "Epoch  53 | Train: loss=0.493, acc= 82.2% | time=1919.5ms | Valid: loss=0.791, acc= 71.2% |\n",
            "Epoch  54 | Train: loss=0.495, acc= 82.1% | time=1928.4ms | Valid: loss=0.756, acc= 71.2% | lr=3.1e-04\n",
            "Epoch  55 | Train: loss=0.492, acc= 82.0% | time=1927.5ms | Valid: loss=0.754, acc= 72.4% |\n",
            "Epoch  56 | Train: loss=0.500, acc= 82.0% | time=1921.7ms | Valid: loss=0.735, acc= 72.0% |\n",
            "Epoch  57 | Train: loss=0.494, acc= 82.4% | time=1932.8ms | Valid: loss=0.822, acc= 71.6% |\n",
            "Epoch  58 | Train: loss=0.485, acc= 82.5% | time=1919.0ms | Valid: loss=0.718, acc= 73.6% | *\n",
            "Epoch  59 | Train: loss=0.491, acc= 82.7% | time=1923.5ms | Valid: loss=0.768, acc= 73.6% |\n",
            "Epoch  60 | Train: loss=0.495, acc= 82.1% | time=1920.4ms | Valid: loss=0.748, acc= 71.6% |\n",
            "Epoch  61 | Train: loss=0.490, acc= 82.3% | time=1918.5ms | Valid: loss=0.761, acc= 72.8% |\n",
            "Epoch  62 | Train: loss=0.502, acc= 81.9% | time=1925.2ms | Valid: loss=0.765, acc= 72.4% |\n",
            "Epoch  63 | Train: loss=0.494, acc= 82.6% | time=1931.3ms | Valid: loss=0.798, acc= 72.0% |\n",
            "Epoch  64 | Train: loss=0.498, acc= 82.4% | time=1924.3ms | Valid: loss=0.765, acc= 70.4% | lr=1.6e-04\n",
            "Epoch  65 | Train: loss=0.507, acc= 81.5% | time=1929.9ms | Valid: loss=0.756, acc= 74.0% |\n",
            "Epoch  66 | Train: loss=0.493, acc= 82.4% | time=1937.6ms | Valid: loss=0.758, acc= 71.6% |\n",
            "Epoch  67 | Train: loss=0.492, acc= 82.5% | time=1922.7ms | Valid: loss=0.772, acc= 71.6% |\n",
            "Epoch  68 | Train: loss=0.496, acc= 82.3% | time=1920.7ms | Valid: loss=0.772, acc= 70.8% |\n",
            "Epoch  69 | Train: loss=0.490, acc= 82.3% | time=1926.8ms | Valid: loss=0.725, acc= 72.4% |\n",
            "Epoch  70 | Train: loss=0.489, acc= 82.3% | time=1916.0ms | Valid: loss=0.759, acc= 72.4% | lr=7.8e-05\n",
            "Epoch  71 | Train: loss=0.494, acc= 82.4% | time=1921.6ms | Valid: loss=0.779, acc= 72.4% |\n",
            "Epoch  72 | Train: loss=0.489, acc= 82.5% | time=1927.1ms | Valid: loss=0.743, acc= 73.2% |\n",
            "Epoch  73 | Train: loss=0.490, acc= 82.7% | time=1938.0ms | Valid: loss=0.776, acc= 69.2% |\n",
            "Epoch  74 | Train: loss=0.493, acc= 82.4% | time=1924.6ms | Valid: loss=0.776, acc= 72.0% |\n",
            "Epoch  75 | Train: loss=0.485, acc= 82.9% | time=1920.5ms | Valid: loss=0.747, acc= 74.0% |\n",
            "Epoch  76 | Train: loss=0.497, acc= 82.5% | time=1918.9ms | Valid: loss=0.769, acc= 72.0% | lr=3.9e-05\n",
            "Epoch  77 | Train: loss=0.492, acc= 81.9% | time=1923.6ms | Valid: loss=0.749, acc= 70.8% |\n",
            "Epoch  78 | Train: loss=0.490, acc= 82.1% | time=1920.9ms | Valid: loss=0.795, acc= 70.8% |\n",
            "Epoch  79 | Train: loss=0.494, acc= 82.2% | time=1931.2ms | Valid: loss=0.741, acc= 72.8% |\n",
            "Epoch  80 | Train: loss=0.489, acc= 82.3% | time=1920.9ms | Valid: loss=0.755, acc= 71.2% |\n",
            "Epoch  81 | Train: loss=0.484, acc= 82.5% | time=1923.9ms | Valid: loss=0.744, acc= 72.4% |\n",
            "Epoch  82 | Train: loss=0.489, acc= 82.7% | time=1919.5ms | Valid: loss=0.802, acc= 72.4% | lr=2.0e-05\n",
            "Epoch  83 | Train: loss=0.489, acc= 82.2% | time=1919.2ms | Valid: loss=0.766, acc= 74.0% |\n",
            "Epoch  84 | Train: loss=0.490, acc= 82.3% | time=1920.2ms | Valid: loss=0.782, acc= 73.2% |\n",
            "Epoch  85 | Train: loss=0.487, acc= 82.8% | time=1924.9ms | Valid: loss=0.743, acc= 71.6% |\n",
            "Epoch  86 | Train: loss=0.483, acc= 83.0% | time=1928.2ms | Valid: loss=0.758, acc= 72.4% |\n",
            "Epoch  87 | Train: loss=0.488, acc= 82.4% | time=1922.0ms | Valid: loss=0.759, acc= 72.8% |\n",
            "Epoch  88 | Train: loss=0.485, acc= 82.5% | time=1921.7ms | Valid: loss=0.735, acc= 72.8% | lr=9.8e-06\n",
            "Test: loss=0.839 , acc= 70.6%\n",
            "------------------------------\n",
            "Representation Matrix\n",
            "------------------------------\n",
            "Layer 1 : (48, 20184)\n",
            "Layer 2 : (576, 14400)\n",
            "Layer 3 : (512, 2500)\n",
            "Layer 4 : (1024, 125)\n",
            "Layer 5 : (2048, 125)\n",
            "------------------------------\n",
            "Threshold:  [0.985 0.985 0.985 0.985 0.985]\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 13/48\n",
            "Layer 2 : 261/576\n",
            "Layer 3 : 378/512\n",
            "Layer 4 : 449/1024\n",
            "Layer 5 : 586/2048\n",
            "----------------------------------------\n",
            "Accuracies =\n",
            "\t 75.6%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 76.4%  68.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 75.2%  66.6%  72.4%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 75.0%  66.3%  72.0%  71.4%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 74.6%  67.2%  71.8%  71.2%  74.4%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 76.0%  65.1%  70.7%  70.1%  74.6%  72.1%   0.0%   0.0%   0.0%   0.0% \n",
            "****************************************************************************************************\n",
            "Task  6 (cifar100-6)\n",
            "****************************************************************************************************\n",
            "----------------------------------------\n",
            "Task ID :6 | Learning Rate : 0.01\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([48, 48])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([576, 576])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([512, 512])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([1024, 1024])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([2048, 2048])\n",
            "----------------------------------------\n",
            "Epoch   1 | Train: loss=1.104, acc= 61.8% | time=1942.1ms | Valid: loss=1.223, acc= 56.0% | *\n",
            "Epoch   2 | Train: loss=1.015, acc= 63.7% | time=1902.8ms | Valid: loss=1.214, acc= 59.6% | *\n",
            "Epoch   3 | Train: loss=0.934, acc= 66.0% | time=1905.8ms | Valid: loss=1.141, acc= 60.0% | *\n",
            "Epoch   4 | Train: loss=0.927, acc= 67.3% | time=1913.5ms | Valid: loss=1.215, acc= 58.8% |\n",
            "Epoch   5 | Train: loss=0.878, acc= 68.7% | time=1907.5ms | Valid: loss=1.120, acc= 59.2% | *\n",
            "Epoch   6 | Train: loss=0.861, acc= 69.7% | time=1907.9ms | Valid: loss=1.145, acc= 60.8% |\n",
            "Epoch   7 | Train: loss=0.841, acc= 70.3% | time=1917.4ms | Valid: loss=1.138, acc= 61.2% |\n",
            "Epoch   8 | Train: loss=0.795, acc= 72.6% | time=1909.7ms | Valid: loss=1.094, acc= 61.2% | *\n",
            "Epoch   9 | Train: loss=0.782, acc= 72.5% | time=1915.0ms | Valid: loss=1.099, acc= 62.0% |\n",
            "Epoch  10 | Train: loss=0.743, acc= 73.9% | time=1914.0ms | Valid: loss=1.069, acc= 61.6% | *\n",
            "Epoch  11 | Train: loss=0.763, acc= 72.9% | time=1915.2ms | Valid: loss=1.120, acc= 62.8% |\n",
            "Epoch  12 | Train: loss=0.725, acc= 74.0% | time=1912.8ms | Valid: loss=1.078, acc= 62.0% |\n",
            "Epoch  13 | Train: loss=0.762, acc= 73.5% | time=1906.6ms | Valid: loss=1.173, acc= 62.8% |\n",
            "Epoch  14 | Train: loss=0.682, acc= 75.9% | time=1913.9ms | Valid: loss=1.117, acc= 63.2% |\n",
            "Epoch  15 | Train: loss=0.707, acc= 75.2% | time=1917.7ms | Valid: loss=1.078, acc= 64.4% |\n",
            "Epoch  16 | Train: loss=0.681, acc= 75.9% | time=1911.5ms | Valid: loss=1.087, acc= 64.4% | lr=5.0e-03\n",
            "Epoch  17 | Train: loss=0.676, acc= 76.1% | time=1913.4ms | Valid: loss=1.061, acc= 66.4% | *\n",
            "Epoch  18 | Train: loss=0.663, acc= 76.5% | time=1911.2ms | Valid: loss=1.023, acc= 66.8% | *\n",
            "Epoch  19 | Train: loss=0.662, acc= 77.2% | time=1905.5ms | Valid: loss=1.058, acc= 65.2% |\n",
            "Epoch  20 | Train: loss=0.664, acc= 76.4% | time=1906.9ms | Valid: loss=1.081, acc= 62.8% |\n",
            "Epoch  21 | Train: loss=0.677, acc= 76.3% | time=1917.4ms | Valid: loss=1.083, acc= 65.2% |\n",
            "Epoch  22 | Train: loss=0.653, acc= 76.5% | time=1915.3ms | Valid: loss=1.098, acc= 64.0% |\n",
            "Epoch  23 | Train: loss=0.626, acc= 77.8% | time=1912.0ms | Valid: loss=1.056, acc= 64.8% |\n",
            "Epoch  24 | Train: loss=0.618, acc= 78.4% | time=1915.3ms | Valid: loss=1.073, acc= 65.2% | lr=2.5e-03\n",
            "Epoch  25 | Train: loss=0.624, acc= 77.9% | time=1915.2ms | Valid: loss=1.085, acc= 62.8% |\n",
            "Epoch  26 | Train: loss=0.627, acc= 78.2% | time=1921.7ms | Valid: loss=1.067, acc= 64.8% |\n",
            "Epoch  27 | Train: loss=0.617, acc= 78.4% | time=1912.9ms | Valid: loss=1.074, acc= 64.4% |\n",
            "Epoch  28 | Train: loss=0.632, acc= 77.5% | time=1912.3ms | Valid: loss=1.058, acc= 64.0% |\n",
            "Epoch  29 | Train: loss=0.631, acc= 78.1% | time=1914.9ms | Valid: loss=1.048, acc= 64.8% |\n",
            "Epoch  30 | Train: loss=0.612, acc= 78.6% | time=1909.2ms | Valid: loss=1.061, acc= 66.4% | lr=1.3e-03\n",
            "Epoch  31 | Train: loss=0.616, acc= 78.2% | time=1914.2ms | Valid: loss=1.079, acc= 64.0% |\n",
            "Epoch  32 | Train: loss=0.624, acc= 77.8% | time=1908.9ms | Valid: loss=1.098, acc= 64.0% |\n",
            "Epoch  33 | Train: loss=0.621, acc= 78.4% | time=1904.3ms | Valid: loss=1.053, acc= 66.0% |\n",
            "Epoch  34 | Train: loss=0.615, acc= 78.5% | time=1910.4ms | Valid: loss=1.076, acc= 66.0% |\n",
            "Epoch  35 | Train: loss=0.613, acc= 78.5% | time=1913.2ms | Valid: loss=1.059, acc= 66.4% |\n",
            "Epoch  36 | Train: loss=0.608, acc= 78.6% | time=1910.7ms | Valid: loss=1.072, acc= 65.6% | lr=6.3e-04\n",
            "Epoch  37 | Train: loss=0.608, acc= 78.6% | time=1903.5ms | Valid: loss=1.029, acc= 64.4% |\n",
            "Epoch  38 | Train: loss=0.606, acc= 78.8% | time=1911.5ms | Valid: loss=1.067, acc= 64.8% |\n",
            "Epoch  39 | Train: loss=0.603, acc= 79.0% | time=1918.9ms | Valid: loss=1.052, acc= 66.8% |\n",
            "Epoch  40 | Train: loss=0.609, acc= 78.6% | time=1914.4ms | Valid: loss=1.055, acc= 66.0% |\n",
            "Epoch  41 | Train: loss=0.611, acc= 78.8% | time=1912.1ms | Valid: loss=1.056, acc= 65.2% |\n",
            "Epoch  42 | Train: loss=0.599, acc= 79.3% | time=1913.6ms | Valid: loss=1.048, acc= 67.2% | lr=3.1e-04\n",
            "Epoch  43 | Train: loss=0.601, acc= 78.6% | time=1917.3ms | Valid: loss=1.021, acc= 66.8% | *\n",
            "Epoch  44 | Train: loss=0.605, acc= 78.9% | time=1910.6ms | Valid: loss=1.035, acc= 66.8% |\n",
            "Epoch  45 | Train: loss=0.597, acc= 78.9% | time=1909.3ms | Valid: loss=1.059, acc= 65.6% |\n",
            "Epoch  46 | Train: loss=0.612, acc= 78.5% | time=1907.6ms | Valid: loss=1.038, acc= 65.2% |\n",
            "Epoch  47 | Train: loss=0.606, acc= 78.9% | time=1907.7ms | Valid: loss=1.060, acc= 66.8% |\n",
            "Epoch  48 | Train: loss=0.597, acc= 78.9% | time=1917.2ms | Valid: loss=1.064, acc= 64.0% |\n",
            "Epoch  49 | Train: loss=0.601, acc= 78.7% | time=1909.5ms | Valid: loss=1.036, acc= 64.8% | lr=1.6e-04\n",
            "Epoch  50 | Train: loss=0.604, acc= 78.7% | time=1911.4ms | Valid: loss=1.044, acc= 67.6% |\n",
            "Epoch  51 | Train: loss=0.602, acc= 79.2% | time=1909.2ms | Valid: loss=1.061, acc= 66.8% |\n",
            "Epoch  52 | Train: loss=0.610, acc= 78.3% | time=1916.6ms | Valid: loss=1.034, acc= 66.0% |\n",
            "Epoch  53 | Train: loss=0.599, acc= 79.3% | time=1913.9ms | Valid: loss=1.050, acc= 66.4% |\n",
            "Epoch  54 | Train: loss=0.599, acc= 78.6% | time=1910.8ms | Valid: loss=1.053, acc= 66.8% |\n",
            "Epoch  55 | Train: loss=0.607, acc= 79.2% | time=1912.8ms | Valid: loss=1.044, acc= 66.8% | lr=7.8e-05\n",
            "Epoch  56 | Train: loss=0.608, acc= 78.8% | time=1907.6ms | Valid: loss=1.045, acc= 64.4% |\n",
            "Epoch  57 | Train: loss=0.598, acc= 78.4% | time=1912.9ms | Valid: loss=1.017, acc= 64.8% | *\n",
            "Epoch  58 | Train: loss=0.599, acc= 79.0% | time=1913.0ms | Valid: loss=1.036, acc= 67.2% |\n",
            "Epoch  59 | Train: loss=0.605, acc= 78.3% | time=1908.6ms | Valid: loss=1.064, acc= 64.8% |\n",
            "Epoch  60 | Train: loss=0.605, acc= 78.8% | time=1912.1ms | Valid: loss=1.044, acc= 65.6% |\n",
            "Epoch  61 | Train: loss=0.603, acc= 78.7% | time=1914.4ms | Valid: loss=1.081, acc= 66.0% |\n",
            "Epoch  62 | Train: loss=0.603, acc= 78.8% | time=1911.4ms | Valid: loss=1.070, acc= 63.6% |\n",
            "Epoch  63 | Train: loss=0.605, acc= 78.5% | time=1910.0ms | Valid: loss=1.030, acc= 67.2% | lr=3.9e-05\n",
            "Epoch  64 | Train: loss=0.599, acc= 78.7% | time=1914.3ms | Valid: loss=1.058, acc= 65.2% |\n",
            "Epoch  65 | Train: loss=0.610, acc= 78.9% | time=1916.4ms | Valid: loss=1.081, acc= 65.2% |\n",
            "Epoch  66 | Train: loss=0.600, acc= 79.0% | time=1911.4ms | Valid: loss=1.068, acc= 66.0% |\n",
            "Epoch  67 | Train: loss=0.602, acc= 78.7% | time=1903.5ms | Valid: loss=1.079, acc= 64.0% |\n",
            "Epoch  68 | Train: loss=0.599, acc= 78.8% | time=1903.0ms | Valid: loss=1.035, acc= 67.6% |\n",
            "Epoch  69 | Train: loss=0.603, acc= 78.9% | time=1904.5ms | Valid: loss=1.072, acc= 65.2% | lr=2.0e-05\n",
            "Epoch  70 | Train: loss=0.601, acc= 78.7% | time=1914.1ms | Valid: loss=1.009, acc= 66.4% | *\n",
            "Epoch  71 | Train: loss=0.607, acc= 78.4% | time=1914.4ms | Valid: loss=1.032, acc= 66.0% |\n",
            "Epoch  72 | Train: loss=0.608, acc= 78.6% | time=1910.8ms | Valid: loss=1.031, acc= 67.6% |\n",
            "Epoch  73 | Train: loss=0.610, acc= 78.5% | time=1912.3ms | Valid: loss=1.021, acc= 66.8% |\n",
            "Epoch  74 | Train: loss=0.600, acc= 78.9% | time=1908.9ms | Valid: loss=1.040, acc= 65.6% |\n",
            "Epoch  75 | Train: loss=0.598, acc= 78.9% | time=1915.4ms | Valid: loss=1.113, acc= 62.8% |\n",
            "Epoch  76 | Train: loss=0.606, acc= 78.2% | time=1918.2ms | Valid: loss=1.051, acc= 66.0% | lr=9.8e-06\n",
            "Test: loss=0.881 , acc= 70.5%\n",
            "------------------------------\n",
            "Representation Matrix\n",
            "------------------------------\n",
            "Layer 1 : (48, 20184)\n",
            "Layer 2 : (576, 14400)\n",
            "Layer 3 : (512, 2500)\n",
            "Layer 4 : (1024, 125)\n",
            "Layer 5 : (2048, 125)\n",
            "------------------------------\n",
            "Threshold:  [0.988 0.988 0.988 0.988 0.988]\n",
            "Skip Updating GPM for layer: 1\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 13/48\n",
            "Layer 2 : 269/576\n",
            "Layer 3 : 391/512\n",
            "Layer 4 : 519/1024\n",
            "Layer 5 : 684/2048\n",
            "----------------------------------------\n",
            "Accuracies =\n",
            "\t 75.6%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 76.4%  68.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 75.2%  66.6%  72.4%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 75.0%  66.3%  72.0%  71.4%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 74.6%  67.2%  71.8%  71.2%  74.4%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 76.0%  65.1%  70.7%  70.1%  74.6%  72.1%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 74.4%  67.3%  71.9%  70.7%  73.8%  71.1%  69.6%   0.0%   0.0%   0.0% \n",
            "****************************************************************************************************\n",
            "Task  7 (cifar100-7)\n",
            "****************************************************************************************************\n",
            "----------------------------------------\n",
            "Task ID :7 | Learning Rate : 0.01\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([48, 48])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([576, 576])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([512, 512])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([1024, 1024])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([2048, 2048])\n",
            "----------------------------------------\n",
            "Epoch   1 | Train: loss=1.159, acc= 60.1% | time=1946.0ms | Valid: loss=1.247, acc= 57.2% | *\n",
            "Epoch   2 | Train: loss=1.050, acc= 63.6% | time=1904.4ms | Valid: loss=1.163, acc= 56.8% | *\n",
            "Epoch   3 | Train: loss=1.005, acc= 65.1% | time=1914.8ms | Valid: loss=1.144, acc= 61.6% | *\n",
            "Epoch   4 | Train: loss=1.001, acc= 65.7% | time=1919.0ms | Valid: loss=1.131, acc= 63.2% | *\n",
            "Epoch   5 | Train: loss=0.945, acc= 67.5% | time=1920.3ms | Valid: loss=1.109, acc= 63.2% | *\n",
            "Epoch   6 | Train: loss=0.933, acc= 68.4% | time=1908.9ms | Valid: loss=1.111, acc= 61.6% |\n",
            "Epoch   7 | Train: loss=0.890, acc= 69.9% | time=1911.3ms | Valid: loss=1.050, acc= 62.4% | *\n",
            "Epoch   8 | Train: loss=0.893, acc= 70.0% | time=1921.5ms | Valid: loss=1.128, acc= 64.0% |\n",
            "Epoch   9 | Train: loss=0.865, acc= 70.5% | time=1919.9ms | Valid: loss=1.106, acc= 66.4% |\n",
            "Epoch  10 | Train: loss=0.881, acc= 69.9% | time=1920.4ms | Valid: loss=1.125, acc= 64.0% |\n",
            "Epoch  11 | Train: loss=0.838, acc= 71.5% | time=1919.7ms | Valid: loss=1.054, acc= 65.2% |\n",
            "Epoch  12 | Train: loss=0.839, acc= 71.0% | time=1907.4ms | Valid: loss=1.160, acc= 65.2% |\n",
            "Epoch  13 | Train: loss=0.807, acc= 73.4% | time=1911.9ms | Valid: loss=1.073, acc= 64.0% | lr=5.0e-03\n",
            "Epoch  14 | Train: loss=0.815, acc= 72.4% | time=1909.3ms | Valid: loss=1.069, acc= 66.4% |\n",
            "Epoch  15 | Train: loss=0.794, acc= 72.7% | time=1915.4ms | Valid: loss=1.070, acc= 64.8% |\n",
            "Epoch  16 | Train: loss=0.774, acc= 73.4% | time=1915.3ms | Valid: loss=1.040, acc= 64.4% | *\n",
            "Epoch  17 | Train: loss=0.776, acc= 73.5% | time=1913.5ms | Valid: loss=1.057, acc= 61.6% |\n",
            "Epoch  18 | Train: loss=0.773, acc= 73.8% | time=1914.0ms | Valid: loss=1.070, acc= 66.4% |\n",
            "Epoch  19 | Train: loss=0.768, acc= 73.8% | time=1917.7ms | Valid: loss=1.052, acc= 66.0% |\n",
            "Epoch  20 | Train: loss=0.766, acc= 73.8% | time=1913.8ms | Valid: loss=1.093, acc= 64.4% |\n",
            "Epoch  21 | Train: loss=0.750, acc= 74.2% | time=1921.3ms | Valid: loss=1.013, acc= 65.2% | *\n",
            "Epoch  22 | Train: loss=0.759, acc= 73.9% | time=1911.9ms | Valid: loss=1.106, acc= 64.8% |\n",
            "Epoch  23 | Train: loss=0.755, acc= 74.3% | time=1916.8ms | Valid: loss=1.065, acc= 65.2% |\n",
            "Epoch  24 | Train: loss=0.733, acc= 75.0% | time=1917.7ms | Valid: loss=1.035, acc= 64.4% |\n",
            "Epoch  25 | Train: loss=0.741, acc= 74.5% | time=1923.5ms | Valid: loss=1.067, acc= 64.8% |\n",
            "Epoch  26 | Train: loss=0.716, acc= 75.5% | time=1914.8ms | Valid: loss=1.049, acc= 66.8% |\n",
            "Epoch  27 | Train: loss=0.721, acc= 75.6% | time=1918.9ms | Valid: loss=1.043, acc= 67.6% | lr=2.5e-03\n",
            "Epoch  28 | Train: loss=0.718, acc= 75.2% | time=1920.4ms | Valid: loss=1.043, acc= 64.0% |\n",
            "Epoch  29 | Train: loss=0.708, acc= 75.7% | time=1915.0ms | Valid: loss=1.030, acc= 66.0% |\n",
            "Epoch  30 | Train: loss=0.708, acc= 75.9% | time=1923.8ms | Valid: loss=1.041, acc= 66.4% |\n",
            "Epoch  31 | Train: loss=0.707, acc= 75.6% | time=1918.1ms | Valid: loss=1.040, acc= 67.6% |\n",
            "Epoch  32 | Train: loss=0.699, acc= 76.1% | time=1912.0ms | Valid: loss=1.011, acc= 68.0% | *\n",
            "Epoch  33 | Train: loss=0.704, acc= 75.8% | time=1912.4ms | Valid: loss=1.043, acc= 65.2% |\n",
            "Epoch  34 | Train: loss=0.708, acc= 76.0% | time=1920.3ms | Valid: loss=1.064, acc= 66.0% |\n",
            "Epoch  35 | Train: loss=0.703, acc= 75.7% | time=1919.4ms | Valid: loss=1.039, acc= 64.8% |\n",
            "Epoch  36 | Train: loss=0.695, acc= 76.3% | time=1918.1ms | Valid: loss=1.022, acc= 64.8% |\n",
            "Epoch  37 | Train: loss=0.691, acc= 76.2% | time=1913.1ms | Valid: loss=1.048, acc= 67.2% |\n",
            "Epoch  38 | Train: loss=0.681, acc= 76.3% | time=1919.7ms | Valid: loss=1.030, acc= 67.6% | lr=1.3e-03\n",
            "Epoch  39 | Train: loss=0.692, acc= 76.2% | time=1919.2ms | Valid: loss=1.060, acc= 66.4% |\n",
            "Epoch  40 | Train: loss=0.689, acc= 75.7% | time=1907.8ms | Valid: loss=1.039, acc= 65.6% |\n",
            "Epoch  41 | Train: loss=0.685, acc= 76.3% | time=1914.6ms | Valid: loss=1.044, acc= 65.6% |\n",
            "Epoch  42 | Train: loss=0.679, acc= 76.7% | time=1907.5ms | Valid: loss=0.981, acc= 68.4% | *\n",
            "Epoch  43 | Train: loss=0.686, acc= 76.9% | time=1923.7ms | Valid: loss=1.035, acc= 64.4% |\n",
            "Epoch  44 | Train: loss=0.685, acc= 76.6% | time=1915.8ms | Valid: loss=1.030, acc= 66.4% |\n",
            "Epoch  45 | Train: loss=0.676, acc= 76.9% | time=1916.2ms | Valid: loss=1.017, acc= 66.4% |\n",
            "Epoch  46 | Train: loss=0.673, acc= 76.6% | time=1917.8ms | Valid: loss=1.043, acc= 64.8% |\n",
            "Epoch  47 | Train: loss=0.688, acc= 76.4% | time=1915.5ms | Valid: loss=1.055, acc= 64.8% |\n",
            "Epoch  48 | Train: loss=0.678, acc= 76.3% | time=1915.7ms | Valid: loss=1.056, acc= 66.0% | lr=6.3e-04\n",
            "Epoch  49 | Train: loss=0.688, acc= 76.3% | time=1911.5ms | Valid: loss=1.035, acc= 66.4% |\n",
            "Epoch  50 | Train: loss=0.679, acc= 76.6% | time=1913.0ms | Valid: loss=1.033, acc= 65.2% |\n",
            "Epoch  51 | Train: loss=0.684, acc= 76.5% | time=1926.0ms | Valid: loss=1.030, acc= 64.0% |\n",
            "Epoch  52 | Train: loss=0.683, acc= 76.8% | time=1912.9ms | Valid: loss=1.064, acc= 66.8% |\n",
            "Epoch  53 | Train: loss=0.681, acc= 76.1% | time=1913.9ms | Valid: loss=1.032, acc= 64.4% |\n",
            "Epoch  54 | Train: loss=0.682, acc= 76.9% | time=1911.9ms | Valid: loss=1.068, acc= 64.4% | lr=3.1e-04\n",
            "Epoch  55 | Train: loss=0.681, acc= 76.5% | time=1925.7ms | Valid: loss=1.034, acc= 65.2% |\n",
            "Epoch  56 | Train: loss=0.677, acc= 76.4% | time=1915.2ms | Valid: loss=1.021, acc= 65.2% |\n",
            "Epoch  57 | Train: loss=0.673, acc= 76.2% | time=1912.8ms | Valid: loss=1.007, acc= 66.4% |\n",
            "Epoch  58 | Train: loss=0.677, acc= 76.3% | time=1914.9ms | Valid: loss=1.022, acc= 68.4% |\n",
            "Epoch  59 | Train: loss=0.676, acc= 76.8% | time=1917.6ms | Valid: loss=1.034, acc= 65.6% |\n",
            "Epoch  60 | Train: loss=0.675, acc= 76.7% | time=1911.1ms | Valid: loss=1.051, acc= 65.2% | lr=1.6e-04\n",
            "Epoch  61 | Train: loss=0.673, acc= 77.2% | time=1915.1ms | Valid: loss=1.018, acc= 67.6% |\n",
            "Epoch  62 | Train: loss=0.670, acc= 76.8% | time=1913.9ms | Valid: loss=1.046, acc= 65.6% |\n",
            "Epoch  63 | Train: loss=0.672, acc= 76.7% | time=1915.5ms | Valid: loss=1.009, acc= 66.4% |\n",
            "Epoch  64 | Train: loss=0.672, acc= 77.1% | time=1915.5ms | Valid: loss=1.016, acc= 67.2% |\n",
            "Epoch  65 | Train: loss=0.675, acc= 76.6% | time=1906.7ms | Valid: loss=1.019, acc= 68.0% |\n",
            "Epoch  66 | Train: loss=0.678, acc= 76.7% | time=1908.6ms | Valid: loss=1.024, acc= 66.4% | lr=7.8e-05\n",
            "Epoch  67 | Train: loss=0.667, acc= 76.5% | time=1918.1ms | Valid: loss=1.017, acc= 66.4% |\n",
            "Epoch  68 | Train: loss=0.665, acc= 76.7% | time=1919.7ms | Valid: loss=1.023, acc= 66.4% |\n",
            "Epoch  69 | Train: loss=0.676, acc= 76.7% | time=1919.7ms | Valid: loss=1.026, acc= 64.4% |\n",
            "Epoch  70 | Train: loss=0.678, acc= 76.6% | time=1917.4ms | Valid: loss=1.055, acc= 65.6% |\n",
            "Epoch  71 | Train: loss=0.671, acc= 77.0% | time=1908.6ms | Valid: loss=1.032, acc= 67.2% |\n",
            "Epoch  72 | Train: loss=0.665, acc= 77.3% | time=1915.2ms | Valid: loss=1.038, acc= 66.4% | lr=3.9e-05\n",
            "Epoch  73 | Train: loss=0.665, acc= 77.2% | time=1920.1ms | Valid: loss=1.025, acc= 66.0% |\n",
            "Epoch  74 | Train: loss=0.681, acc= 76.6% | time=1917.0ms | Valid: loss=1.054, acc= 66.0% |\n",
            "Epoch  75 | Train: loss=0.684, acc= 76.6% | time=1919.0ms | Valid: loss=1.009, acc= 64.8% |\n",
            "Epoch  76 | Train: loss=0.672, acc= 77.2% | time=1913.6ms | Valid: loss=1.020, acc= 64.0% |\n",
            "Epoch  77 | Train: loss=0.673, acc= 76.5% | time=1916.6ms | Valid: loss=1.030, acc= 65.6% |\n",
            "Epoch  78 | Train: loss=0.671, acc= 77.1% | time=1915.3ms | Valid: loss=1.013, acc= 67.6% | lr=2.0e-05\n",
            "Epoch  79 | Train: loss=0.670, acc= 76.9% | time=1912.7ms | Valid: loss=1.032, acc= 68.4% |\n",
            "Epoch  80 | Train: loss=0.682, acc= 76.5% | time=1911.7ms | Valid: loss=1.076, acc= 64.4% |\n",
            "Epoch  81 | Train: loss=0.671, acc= 77.1% | time=1921.3ms | Valid: loss=1.026, acc= 65.6% |\n",
            "Epoch  82 | Train: loss=0.675, acc= 76.8% | time=1913.6ms | Valid: loss=1.037, acc= 67.6% |\n",
            "Epoch  83 | Train: loss=0.674, acc= 77.0% | time=1914.8ms | Valid: loss=1.055, acc= 64.4% |\n",
            "Epoch  84 | Train: loss=0.668, acc= 77.1% | time=1923.1ms | Valid: loss=1.080, acc= 63.2% | lr=9.8e-06\n",
            "Test: loss=0.927 , acc= 69.7%\n",
            "------------------------------\n",
            "Representation Matrix\n",
            "------------------------------\n",
            "Layer 1 : (48, 20184)\n",
            "Layer 2 : (576, 14400)\n",
            "Layer 3 : (512, 2500)\n",
            "Layer 4 : (1024, 125)\n",
            "Layer 5 : (2048, 125)\n",
            "------------------------------\n",
            "Threshold:  [0.991 0.991 0.991 0.991 0.991]\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 14/48\n",
            "Layer 2 : 320/576\n",
            "Layer 3 : 420/512\n",
            "Layer 4 : 592/1024\n",
            "Layer 5 : 785/2048\n",
            "----------------------------------------\n",
            "Accuracies =\n",
            "\t 75.6%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 76.4%  68.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 75.2%  66.6%  72.4%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 75.0%  66.3%  72.0%  71.4%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 74.6%  67.2%  71.8%  71.2%  74.4%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 76.0%  65.1%  70.7%  70.1%  74.6%  72.1%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 74.4%  67.3%  71.9%  70.7%  73.8%  71.1%  69.6%   0.0%   0.0%   0.0% \n",
            "\t 75.5%  66.1%  72.1%  72.2%  73.4%  71.8%  69.9%  70.8%   0.0%   0.0% \n",
            "****************************************************************************************************\n",
            "Task  8 (cifar100-8)\n",
            "****************************************************************************************************\n",
            "----------------------------------------\n",
            "Task ID :8 | Learning Rate : 0.01\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([48, 48])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([576, 576])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([512, 512])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([1024, 1024])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([2048, 2048])\n",
            "----------------------------------------\n",
            "Epoch   1 | Train: loss=1.162, acc= 60.3% | time=1931.8ms | Valid: loss=1.294, acc= 52.8% | *\n",
            "Epoch   2 | Train: loss=1.032, acc= 64.7% | time=1913.4ms | Valid: loss=1.177, acc= 57.6% | *\n",
            "Epoch   3 | Train: loss=0.970, acc= 66.5% | time=1914.1ms | Valid: loss=1.162, acc= 59.6% | *\n",
            "Epoch   4 | Train: loss=0.967, acc= 66.6% | time=1920.6ms | Valid: loss=1.146, acc= 57.6% | *\n",
            "Epoch   5 | Train: loss=0.896, acc= 69.3% | time=1928.9ms | Valid: loss=1.151, acc= 61.2% |\n",
            "Epoch   6 | Train: loss=0.888, acc= 69.5% | time=1911.4ms | Valid: loss=1.160, acc= 63.6% |\n",
            "Epoch   7 | Train: loss=0.862, acc= 70.6% | time=1922.6ms | Valid: loss=1.122, acc= 64.0% | *\n",
            "Epoch   8 | Train: loss=0.869, acc= 70.6% | time=1923.5ms | Valid: loss=1.155, acc= 60.4% |\n",
            "Epoch   9 | Train: loss=0.835, acc= 72.4% | time=1924.9ms | Valid: loss=1.102, acc= 64.0% | *\n",
            "Epoch  10 | Train: loss=0.798, acc= 73.5% | time=1922.1ms | Valid: loss=1.063, acc= 66.4% | *\n",
            "Epoch  11 | Train: loss=0.789, acc= 73.2% | time=1921.4ms | Valid: loss=1.119, acc= 65.2% |\n",
            "Epoch  12 | Train: loss=0.765, acc= 75.0% | time=1923.2ms | Valid: loss=1.083, acc= 65.2% |\n",
            "Epoch  13 | Train: loss=0.781, acc= 74.0% | time=1917.5ms | Valid: loss=1.107, acc= 63.6% |\n",
            "Epoch  14 | Train: loss=0.768, acc= 74.4% | time=1936.9ms | Valid: loss=1.102, acc= 66.0% |\n",
            "Epoch  15 | Train: loss=0.734, acc= 75.3% | time=1929.5ms | Valid: loss=1.118, acc= 65.6% |\n",
            "Epoch  16 | Train: loss=0.720, acc= 75.6% | time=1926.9ms | Valid: loss=1.069, acc= 66.8% | lr=5.0e-03\n",
            "Epoch  17 | Train: loss=0.713, acc= 75.5% | time=1921.8ms | Valid: loss=1.085, acc= 66.0% |\n",
            "Epoch  18 | Train: loss=0.720, acc= 76.0% | time=1913.1ms | Valid: loss=1.084, acc= 68.4% |\n",
            "Epoch  19 | Train: loss=0.708, acc= 75.8% | time=1926.0ms | Valid: loss=1.078, acc= 66.0% |\n",
            "Epoch  20 | Train: loss=0.693, acc= 76.5% | time=1922.6ms | Valid: loss=1.071, acc= 67.2% |\n",
            "Epoch  21 | Train: loss=0.676, acc= 77.2% | time=1919.1ms | Valid: loss=1.028, acc= 66.4% | *\n",
            "Epoch  22 | Train: loss=0.681, acc= 77.0% | time=1922.1ms | Valid: loss=1.064, acc= 65.6% |\n",
            "Epoch  23 | Train: loss=0.680, acc= 77.1% | time=1911.6ms | Valid: loss=1.036, acc= 66.8% |\n",
            "Epoch  24 | Train: loss=0.661, acc= 77.7% | time=1922.1ms | Valid: loss=1.016, acc= 68.8% | *\n",
            "Epoch  25 | Train: loss=0.680, acc= 76.9% | time=1914.8ms | Valid: loss=1.014, acc= 70.4% | *\n",
            "Epoch  26 | Train: loss=0.673, acc= 77.3% | time=1914.7ms | Valid: loss=1.065, acc= 68.0% |\n",
            "Epoch  27 | Train: loss=0.665, acc= 77.8% | time=1917.6ms | Valid: loss=1.081, acc= 66.0% |\n",
            "Epoch  28 | Train: loss=0.666, acc= 77.9% | time=1924.6ms | Valid: loss=1.071, acc= 66.8% |\n",
            "Epoch  29 | Train: loss=0.654, acc= 77.9% | time=1921.0ms | Valid: loss=1.075, acc= 68.0% |\n",
            "Epoch  30 | Train: loss=0.642, acc= 78.4% | time=1918.9ms | Valid: loss=1.033, acc= 69.6% |\n",
            "Epoch  31 | Train: loss=0.632, acc= 78.6% | time=1919.7ms | Valid: loss=1.054, acc= 67.2% | lr=2.5e-03\n",
            "Epoch  32 | Train: loss=0.642, acc= 78.4% | time=1922.7ms | Valid: loss=1.033, acc= 67.6% |\n",
            "Epoch  33 | Train: loss=0.628, acc= 78.7% | time=1922.8ms | Valid: loss=1.052, acc= 67.2% |\n",
            "Epoch  34 | Train: loss=0.636, acc= 78.5% | time=1918.1ms | Valid: loss=1.012, acc= 67.2% | *\n",
            "Epoch  35 | Train: loss=0.634, acc= 78.3% | time=1921.8ms | Valid: loss=1.097, acc= 68.4% |\n",
            "Epoch  36 | Train: loss=0.633, acc= 79.0% | time=1925.7ms | Valid: loss=1.081, acc= 68.0% |\n",
            "Epoch  37 | Train: loss=0.619, acc= 79.1% | time=1920.5ms | Valid: loss=1.053, acc= 68.8% |\n",
            "Epoch  38 | Train: loss=0.622, acc= 79.2% | time=1919.8ms | Valid: loss=1.046, acc= 68.0% |\n",
            "Epoch  39 | Train: loss=0.626, acc= 79.1% | time=1919.2ms | Valid: loss=1.037, acc= 68.0% |\n",
            "Epoch  40 | Train: loss=0.613, acc= 79.4% | time=1922.2ms | Valid: loss=1.055, acc= 67.2% | lr=1.3e-03\n",
            "Epoch  41 | Train: loss=0.611, acc= 79.1% | time=1924.9ms | Valid: loss=1.040, acc= 67.6% |\n",
            "Epoch  42 | Train: loss=0.610, acc= 79.5% | time=1914.4ms | Valid: loss=1.061, acc= 66.4% |\n",
            "Epoch  43 | Train: loss=0.617, acc= 79.2% | time=1917.9ms | Valid: loss=1.004, acc= 69.2% | *\n",
            "Epoch  44 | Train: loss=0.604, acc= 79.7% | time=1930.8ms | Valid: loss=1.050, acc= 66.4% |\n",
            "Epoch  45 | Train: loss=0.617, acc= 79.6% | time=1923.8ms | Valid: loss=1.043, acc= 67.2% |\n",
            "Epoch  46 | Train: loss=0.619, acc= 79.3% | time=1918.7ms | Valid: loss=1.044, acc= 67.2% |\n",
            "Epoch  47 | Train: loss=0.618, acc= 79.1% | time=1922.4ms | Valid: loss=1.029, acc= 68.4% |\n",
            "Epoch  48 | Train: loss=0.609, acc= 79.6% | time=1920.3ms | Valid: loss=1.049, acc= 67.2% |\n",
            "Epoch  49 | Train: loss=0.612, acc= 79.6% | time=1918.6ms | Valid: loss=1.056, acc= 67.6% | lr=6.3e-04\n",
            "Epoch  50 | Train: loss=0.608, acc= 79.6% | time=1925.9ms | Valid: loss=1.074, acc= 67.6% |\n",
            "Epoch  51 | Train: loss=0.608, acc= 79.2% | time=1917.4ms | Valid: loss=1.039, acc= 68.0% |\n",
            "Epoch  52 | Train: loss=0.610, acc= 79.5% | time=1923.5ms | Valid: loss=1.081, acc= 66.4% |\n",
            "Epoch  53 | Train: loss=0.621, acc= 79.1% | time=1918.6ms | Valid: loss=1.052, acc= 68.0% |\n",
            "Epoch  54 | Train: loss=0.601, acc= 80.1% | time=1918.3ms | Valid: loss=1.057, acc= 69.6% |\n",
            "Epoch  55 | Train: loss=0.612, acc= 79.7% | time=1924.5ms | Valid: loss=1.028, acc= 68.4% | lr=3.1e-04\n",
            "Epoch  56 | Train: loss=0.604, acc= 79.7% | time=1924.2ms | Valid: loss=1.038, acc= 68.8% |\n",
            "Epoch  57 | Train: loss=0.605, acc= 80.0% | time=1919.6ms | Valid: loss=1.080, acc= 66.8% |\n",
            "Epoch  58 | Train: loss=0.603, acc= 80.2% | time=1923.3ms | Valid: loss=1.053, acc= 68.4% |\n",
            "Epoch  59 | Train: loss=0.615, acc= 79.4% | time=1925.5ms | Valid: loss=1.033, acc= 67.2% |\n",
            "Epoch  60 | Train: loss=0.602, acc= 79.8% | time=1910.1ms | Valid: loss=1.018, acc= 67.2% |\n",
            "Epoch  61 | Train: loss=0.600, acc= 80.0% | time=1916.3ms | Valid: loss=1.030, acc= 67.2% | lr=1.6e-04\n",
            "Epoch  62 | Train: loss=0.598, acc= 80.0% | time=1920.6ms | Valid: loss=1.028, acc= 67.6% |\n",
            "Epoch  63 | Train: loss=0.604, acc= 79.3% | time=1914.6ms | Valid: loss=1.042, acc= 69.6% |\n",
            "Epoch  64 | Train: loss=0.605, acc= 79.4% | time=1923.4ms | Valid: loss=1.055, acc= 68.4% |\n",
            "Epoch  65 | Train: loss=0.603, acc= 79.5% | time=1928.0ms | Valid: loss=1.025, acc= 68.8% |\n",
            "Epoch  66 | Train: loss=0.599, acc= 80.3% | time=1918.8ms | Valid: loss=1.003, acc= 68.4% | *\n",
            "Epoch  67 | Train: loss=0.600, acc= 79.7% | time=1924.9ms | Valid: loss=0.999, acc= 69.6% | *\n",
            "Epoch  68 | Train: loss=0.599, acc= 79.6% | time=1921.5ms | Valid: loss=1.031, acc= 68.0% |\n",
            "Epoch  69 | Train: loss=0.610, acc= 79.7% | time=1922.4ms | Valid: loss=1.062, acc= 67.6% |\n",
            "Epoch  70 | Train: loss=0.606, acc= 79.6% | time=1920.6ms | Valid: loss=1.028, acc= 67.2% |\n",
            "Epoch  71 | Train: loss=0.602, acc= 79.3% | time=1921.9ms | Valid: loss=1.031, acc= 70.4% |\n",
            "Epoch  72 | Train: loss=0.601, acc= 79.6% | time=1915.4ms | Valid: loss=1.053, acc= 68.4% |\n",
            "Epoch  73 | Train: loss=0.595, acc= 80.0% | time=1920.4ms | Valid: loss=1.054, acc= 68.4% | lr=7.8e-05\n",
            "Epoch  74 | Train: loss=0.603, acc= 79.7% | time=1919.0ms | Valid: loss=1.068, acc= 68.4% |\n",
            "Epoch  75 | Train: loss=0.611, acc= 79.4% | time=1916.6ms | Valid: loss=1.072, acc= 68.0% |\n",
            "Epoch  76 | Train: loss=0.593, acc= 80.2% | time=1915.1ms | Valid: loss=1.089, acc= 68.8% |\n",
            "Epoch  77 | Train: loss=0.600, acc= 79.8% | time=1918.8ms | Valid: loss=1.044, acc= 67.6% |\n",
            "Epoch  78 | Train: loss=0.603, acc= 79.3% | time=1914.0ms | Valid: loss=1.032, acc= 67.2% |\n",
            "Epoch  79 | Train: loss=0.599, acc= 79.7% | time=1920.1ms | Valid: loss=0.994, acc= 69.6% | *\n",
            "Epoch  80 | Train: loss=0.597, acc= 79.9% | time=1930.4ms | Valid: loss=1.047, acc= 67.6% |\n",
            "Epoch  81 | Train: loss=0.601, acc= 79.8% | time=1913.6ms | Valid: loss=1.045, acc= 67.2% |\n",
            "Epoch  82 | Train: loss=0.599, acc= 79.8% | time=1921.8ms | Valid: loss=1.049, acc= 67.2% |\n",
            "Epoch  83 | Train: loss=0.610, acc= 79.7% | time=1918.8ms | Valid: loss=1.063, acc= 68.8% |\n",
            "Epoch  84 | Train: loss=0.599, acc= 79.8% | time=1915.8ms | Valid: loss=1.050, acc= 67.2% |\n",
            "Epoch  85 | Train: loss=0.607, acc= 79.7% | time=1918.4ms | Valid: loss=1.014, acc= 68.4% | lr=3.9e-05\n",
            "Epoch  86 | Train: loss=0.595, acc= 80.3% | time=1914.2ms | Valid: loss=1.044, acc= 67.6% |\n",
            "Epoch  87 | Train: loss=0.600, acc= 79.7% | time=1925.9ms | Valid: loss=1.039, acc= 68.8% |\n",
            "Epoch  88 | Train: loss=0.596, acc= 80.2% | time=1924.4ms | Valid: loss=1.035, acc= 68.4% |\n",
            "Epoch  89 | Train: loss=0.604, acc= 79.4% | time=1926.6ms | Valid: loss=1.078, acc= 66.4% |\n",
            "Epoch  90 | Train: loss=0.598, acc= 79.4% | time=1919.1ms | Valid: loss=1.022, acc= 67.6% |\n",
            "Epoch  91 | Train: loss=0.600, acc= 80.0% | time=1922.7ms | Valid: loss=1.036, acc= 69.2% | lr=2.0e-05\n",
            "Epoch  92 | Train: loss=0.593, acc= 79.7% | time=1922.7ms | Valid: loss=1.058, acc= 68.0% |\n",
            "Epoch  93 | Train: loss=0.598, acc= 79.7% | time=1917.2ms | Valid: loss=1.048, acc= 67.2% |\n",
            "Epoch  94 | Train: loss=0.601, acc= 79.6% | time=1913.6ms | Valid: loss=1.118, acc= 68.4% |\n",
            "Epoch  95 | Train: loss=0.606, acc= 79.5% | time=1920.6ms | Valid: loss=1.062, acc= 68.0% |\n",
            "Epoch  96 | Train: loss=0.605, acc= 79.7% | time=1917.8ms | Valid: loss=1.050, acc= 68.0% |\n",
            "Epoch  97 | Train: loss=0.604, acc= 79.9% | time=1919.2ms | Valid: loss=1.025, acc= 68.8% | lr=9.8e-06\n",
            "Test: loss=0.852 , acc= 71.3%\n",
            "------------------------------\n",
            "Representation Matrix\n",
            "------------------------------\n",
            "Layer 1 : (48, 20184)\n",
            "Layer 2 : (576, 14400)\n",
            "Layer 3 : (512, 2500)\n",
            "Layer 4 : (1024, 125)\n",
            "Layer 5 : (2048, 125)\n",
            "------------------------------\n",
            "Threshold:  [0.994 0.994 0.994 0.994 0.994]\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 21/48\n",
            "Layer 2 : 380/576\n",
            "Layer 3 : 450/512\n",
            "Layer 4 : 675/1024\n",
            "Layer 5 : 895/2048\n",
            "----------------------------------------\n",
            "Accuracies =\n",
            "\t 75.6%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 76.4%  68.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 75.2%  66.6%  72.4%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 75.0%  66.3%  72.0%  71.4%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 74.6%  67.2%  71.8%  71.2%  74.4%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 76.0%  65.1%  70.7%  70.1%  74.6%  72.1%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 74.4%  67.3%  71.9%  70.7%  73.8%  71.1%  69.6%   0.0%   0.0%   0.0% \n",
            "\t 75.5%  66.1%  72.1%  72.2%  73.4%  71.8%  69.9%  70.8%   0.0%   0.0% \n",
            "\t 74.7%  66.9%  72.5%  71.8%  74.7%  73.0%  69.2%  70.6%  71.6%   0.0% \n",
            "****************************************************************************************************\n",
            "Task  9 (cifar100-9)\n",
            "****************************************************************************************************\n",
            "----------------------------------------\n",
            "Task ID :9 | Learning Rate : 0.01\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([48, 48])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([576, 576])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([512, 512])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([1024, 1024])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([2048, 2048])\n",
            "----------------------------------------\n",
            "Epoch   1 | Train: loss=1.029, acc= 65.5% | time=1940.4ms | Valid: loss=1.032, acc= 63.2% | *\n",
            "Epoch   2 | Train: loss=0.901, acc= 69.7% | time=1918.5ms | Valid: loss=0.962, acc= 68.0% | *\n",
            "Epoch   3 | Train: loss=0.865, acc= 71.4% | time=1922.1ms | Valid: loss=0.914, acc= 68.8% | *\n",
            "Epoch   4 | Train: loss=0.846, acc= 71.5% | time=1923.6ms | Valid: loss=0.928, acc= 66.8% |\n",
            "Epoch   5 | Train: loss=0.796, acc= 73.3% | time=1926.0ms | Valid: loss=0.845, acc= 71.2% | *\n",
            "Epoch   6 | Train: loss=0.784, acc= 73.2% | time=1929.9ms | Valid: loss=0.863, acc= 70.0% |\n",
            "Epoch   7 | Train: loss=0.749, acc= 74.4% | time=1930.0ms | Valid: loss=0.849, acc= 72.4% |\n",
            "Epoch   8 | Train: loss=0.756, acc= 75.2% | time=1919.7ms | Valid: loss=0.906, acc= 68.4% |\n",
            "Epoch   9 | Train: loss=0.725, acc= 75.6% | time=1927.6ms | Valid: loss=0.856, acc= 72.8% |\n",
            "Epoch  10 | Train: loss=0.740, acc= 75.1% | time=1925.2ms | Valid: loss=0.873, acc= 71.6% |\n",
            "Epoch  11 | Train: loss=0.711, acc= 76.3% | time=1921.4ms | Valid: loss=0.873, acc= 72.8% | lr=5.0e-03\n",
            "Epoch  12 | Train: loss=0.702, acc= 76.9% | time=1930.8ms | Valid: loss=0.817, acc= 73.2% | *\n",
            "Epoch  13 | Train: loss=0.682, acc= 76.9% | time=1924.5ms | Valid: loss=0.825, acc= 74.0% |\n",
            "Epoch  14 | Train: loss=0.668, acc= 77.7% | time=1924.0ms | Valid: loss=0.849, acc= 73.2% |\n",
            "Epoch  15 | Train: loss=0.661, acc= 77.6% | time=1917.6ms | Valid: loss=0.787, acc= 76.8% | *\n",
            "Epoch  16 | Train: loss=0.683, acc= 76.5% | time=1926.7ms | Valid: loss=0.900, acc= 72.4% |\n",
            "Epoch  17 | Train: loss=0.655, acc= 77.6% | time=1930.9ms | Valid: loss=0.839, acc= 70.8% |\n",
            "Epoch  18 | Train: loss=0.680, acc= 77.3% | time=1916.7ms | Valid: loss=0.902, acc= 70.4% |\n",
            "Epoch  19 | Train: loss=0.661, acc= 77.5% | time=1929.2ms | Valid: loss=0.840, acc= 73.6% |\n",
            "Epoch  20 | Train: loss=0.657, acc= 77.3% | time=1915.6ms | Valid: loss=0.858, acc= 72.4% |\n",
            "Epoch  21 | Train: loss=0.641, acc= 78.6% | time=1925.2ms | Valid: loss=0.824, acc= 74.4% | lr=2.5e-03\n",
            "Epoch  22 | Train: loss=0.648, acc= 77.8% | time=1927.6ms | Valid: loss=0.846, acc= 74.0% |\n",
            "Epoch  23 | Train: loss=0.646, acc= 78.1% | time=1924.8ms | Valid: loss=0.834, acc= 73.2% |\n",
            "Epoch  24 | Train: loss=0.641, acc= 78.7% | time=1930.7ms | Valid: loss=0.837, acc= 74.4% |\n",
            "Epoch  25 | Train: loss=0.634, acc= 78.4% | time=1919.1ms | Valid: loss=0.800, acc= 76.4% |\n",
            "Epoch  26 | Train: loss=0.629, acc= 78.6% | time=1925.8ms | Valid: loss=0.830, acc= 71.6% |\n",
            "Epoch  27 | Train: loss=0.632, acc= 78.1% | time=1924.5ms | Valid: loss=0.838, acc= 74.4% | lr=1.3e-03\n",
            "Epoch  28 | Train: loss=0.626, acc= 78.9% | time=1926.2ms | Valid: loss=0.807, acc= 74.4% |\n",
            "Epoch  29 | Train: loss=0.622, acc= 79.1% | time=1931.7ms | Valid: loss=0.818, acc= 74.0% |\n",
            "Epoch  30 | Train: loss=0.627, acc= 78.7% | time=1921.6ms | Valid: loss=0.839, acc= 73.6% |\n",
            "Epoch  31 | Train: loss=0.630, acc= 78.5% | time=1927.3ms | Valid: loss=0.854, acc= 73.6% |\n",
            "Epoch  32 | Train: loss=0.626, acc= 79.0% | time=1926.3ms | Valid: loss=0.839, acc= 73.2% |\n",
            "Epoch  33 | Train: loss=0.624, acc= 78.7% | time=1918.8ms | Valid: loss=0.825, acc= 74.0% | lr=6.3e-04\n",
            "Epoch  34 | Train: loss=0.631, acc= 78.3% | time=1925.1ms | Valid: loss=0.821, acc= 74.4% |\n",
            "Epoch  35 | Train: loss=0.629, acc= 78.3% | time=1919.7ms | Valid: loss=0.815, acc= 73.2% |\n",
            "Epoch  36 | Train: loss=0.623, acc= 78.8% | time=1923.7ms | Valid: loss=0.831, acc= 72.8% |\n",
            "Epoch  37 | Train: loss=0.624, acc= 78.5% | time=1927.2ms | Valid: loss=0.814, acc= 72.8% |\n",
            "Epoch  38 | Train: loss=0.630, acc= 78.5% | time=1927.8ms | Valid: loss=0.857, acc= 72.4% |\n",
            "Epoch  39 | Train: loss=0.618, acc= 79.0% | time=1928.4ms | Valid: loss=0.783, acc= 76.4% | *\n",
            "Epoch  40 | Train: loss=0.617, acc= 79.3% | time=1923.0ms | Valid: loss=0.853, acc= 74.8% |\n",
            "Epoch  41 | Train: loss=0.621, acc= 79.0% | time=1918.2ms | Valid: loss=0.827, acc= 72.8% |\n",
            "Epoch  42 | Train: loss=0.616, acc= 79.1% | time=1928.6ms | Valid: loss=0.790, acc= 76.8% |\n",
            "Epoch  43 | Train: loss=0.622, acc= 78.5% | time=1926.4ms | Valid: loss=0.805, acc= 73.2% |\n",
            "Epoch  44 | Train: loss=0.604, acc= 79.7% | time=1926.0ms | Valid: loss=0.810, acc= 74.4% |\n",
            "Epoch  45 | Train: loss=0.620, acc= 78.7% | time=1923.4ms | Valid: loss=0.785, acc= 75.6% | lr=3.1e-04\n",
            "Epoch  46 | Train: loss=0.616, acc= 79.2% | time=1924.3ms | Valid: loss=0.833, acc= 74.4% |\n",
            "Epoch  47 | Train: loss=0.620, acc= 78.8% | time=1920.7ms | Valid: loss=0.814, acc= 74.8% |\n",
            "Epoch  48 | Train: loss=0.625, acc= 78.7% | time=1922.2ms | Valid: loss=0.800, acc= 75.2% |\n",
            "Epoch  49 | Train: loss=0.613, acc= 78.9% | time=1922.5ms | Valid: loss=0.785, acc= 76.4% |\n",
            "Epoch  50 | Train: loss=0.614, acc= 79.5% | time=1927.0ms | Valid: loss=0.856, acc= 72.4% |\n",
            "Epoch  51 | Train: loss=0.624, acc= 79.0% | time=1925.6ms | Valid: loss=0.831, acc= 73.6% | lr=1.6e-04\n",
            "Epoch  52 | Train: loss=0.610, acc= 79.6% | time=1927.1ms | Valid: loss=0.831, acc= 74.0% |\n",
            "Epoch  53 | Train: loss=0.622, acc= 79.2% | time=1930.7ms | Valid: loss=0.843, acc= 73.2% |\n",
            "Epoch  54 | Train: loss=0.617, acc= 79.1% | time=1920.0ms | Valid: loss=0.820, acc= 74.8% |\n",
            "Epoch  55 | Train: loss=0.611, acc= 79.4% | time=1933.6ms | Valid: loss=0.828, acc= 72.0% |\n",
            "Epoch  56 | Train: loss=0.619, acc= 79.1% | time=1919.1ms | Valid: loss=0.841, acc= 74.4% |\n",
            "Epoch  57 | Train: loss=0.613, acc= 79.2% | time=1926.0ms | Valid: loss=0.820, acc= 74.0% | lr=7.8e-05\n",
            "Epoch  58 | Train: loss=0.608, acc= 79.5% | time=1922.7ms | Valid: loss=0.817, acc= 75.2% |\n",
            "Epoch  59 | Train: loss=0.612, acc= 79.1% | time=1912.4ms | Valid: loss=0.823, acc= 73.6% |\n",
            "Epoch  60 | Train: loss=0.615, acc= 78.9% | time=1920.4ms | Valid: loss=0.841, acc= 72.4% |\n",
            "Epoch  61 | Train: loss=0.620, acc= 78.8% | time=1921.8ms | Valid: loss=0.813, acc= 75.6% |\n",
            "Epoch  62 | Train: loss=0.619, acc= 79.0% | time=1924.6ms | Valid: loss=0.811, acc= 74.4% |\n",
            "Epoch  63 | Train: loss=0.621, acc= 78.9% | time=1923.9ms | Valid: loss=0.819, acc= 74.4% | lr=3.9e-05\n",
            "Epoch  64 | Train: loss=0.606, acc= 79.2% | time=1926.8ms | Valid: loss=0.806, acc= 75.6% |\n",
            "Epoch  65 | Train: loss=0.606, acc= 79.2% | time=1920.4ms | Valid: loss=0.839, acc= 73.2% |\n",
            "Epoch  66 | Train: loss=0.618, acc= 78.7% | time=1923.1ms | Valid: loss=0.836, acc= 75.2% |\n",
            "Epoch  67 | Train: loss=0.616, acc= 78.7% | time=1922.4ms | Valid: loss=0.819, acc= 75.6% |\n",
            "Epoch  68 | Train: loss=0.608, acc= 78.6% | time=1921.6ms | Valid: loss=0.823, acc= 73.6% |\n",
            "Epoch  69 | Train: loss=0.610, acc= 79.5% | time=1920.4ms | Valid: loss=0.847, acc= 74.4% | lr=2.0e-05\n",
            "Epoch  70 | Train: loss=0.610, acc= 79.6% | time=1927.0ms | Valid: loss=0.826, acc= 72.4% |\n",
            "Epoch  71 | Train: loss=0.611, acc= 79.1% | time=1916.1ms | Valid: loss=0.827, acc= 75.2% |\n",
            "Epoch  72 | Train: loss=0.614, acc= 79.5% | time=1919.0ms | Valid: loss=0.844, acc= 75.2% |\n",
            "Epoch  73 | Train: loss=0.615, acc= 78.9% | time=1920.4ms | Valid: loss=0.841, acc= 73.2% |\n",
            "Epoch  74 | Train: loss=0.621, acc= 78.9% | time=1918.2ms | Valid: loss=0.845, acc= 73.2% |\n",
            "Epoch  75 | Train: loss=0.615, acc= 79.5% | time=1924.8ms | Valid: loss=0.806, acc= 75.6% | lr=9.8e-06\n",
            "Test: loss=0.823 , acc= 72.9%\n",
            "------------------------------\n",
            "Representation Matrix\n",
            "------------------------------\n",
            "Layer 1 : (48, 20184)\n",
            "Layer 2 : (576, 14400)\n",
            "Layer 3 : (512, 2500)\n",
            "Layer 4 : (1024, 125)\n",
            "Layer 5 : (2048, 125)\n",
            "------------------------------\n",
            "Threshold:  [0.997 0.997 0.997 0.997 0.997]\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 22/48\n",
            "Layer 2 : 422/576\n",
            "Layer 3 : 475/512\n",
            "Layer 4 : 762/1024\n",
            "Layer 5 : 1008/2048\n",
            "----------------------------------------\n",
            "Accuracies =\n",
            "\t 75.6%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 76.4%  68.8%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 75.2%  66.6%  72.4%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 75.0%  66.3%  72.0%  71.4%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 74.6%  67.2%  71.8%  71.2%  74.4%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 76.0%  65.1%  70.7%  70.1%  74.6%  72.1%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 74.4%  67.3%  71.9%  70.7%  73.8%  71.1%  69.6%   0.0%   0.0%   0.0% \n",
            "\t 75.5%  66.1%  72.1%  72.2%  73.4%  71.8%  69.9%  70.8%   0.0%   0.0% \n",
            "\t 74.7%  66.9%  72.5%  71.8%  74.7%  73.0%  69.2%  70.6%  71.6%   0.0% \n",
            "\t 74.7%  65.7%  72.5%  72.2%  75.5%  71.9%  70.8%  70.7%  71.6%  73.6% \n",
            "--------------------------------------------------\n",
            "Task Order : [0 1 2 3 4 5 6 7 8 9]\n",
            "Final Avg Accuracy: 71.92%\n",
            "Backward transfer: -0.12%\n",
            "[Elapsed time = 2190701.4 ms]\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sQ_SC89fh9dj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}