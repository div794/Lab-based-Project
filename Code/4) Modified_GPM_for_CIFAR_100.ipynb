{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modified GPM for CIFAR_100.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ab3cce1340f741d68a2da72c34ffe80b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29b00f4a8c3147ae8ba51aac39ec18ce",
              "IPY_MODEL_cf770af8611b4e1488778a13cd7985a3",
              "IPY_MODEL_8120e9bbf84b4dfc82ef5ffa9be88b05"
            ],
            "layout": "IPY_MODEL_935343f46f3d4fb798ea531b8ad040b8"
          }
        },
        "29b00f4a8c3147ae8ba51aac39ec18ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3a53a95e4ea4f27a3db95832c81a67d",
            "placeholder": "​",
            "style": "IPY_MODEL_d5abaa6610c249fe9fc97e68da52a4df",
            "value": ""
          }
        },
        "cf770af8611b4e1488778a13cd7985a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9bafdcaf4444d08b167194c418b140f",
            "max": 169001437,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_663b7f0e50844fb2a9f9811cdc24303e",
            "value": 169001437
          }
        },
        "8120e9bbf84b4dfc82ef5ffa9be88b05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b6bfd6da7d64ada9675e19335f7f41b",
            "placeholder": "​",
            "style": "IPY_MODEL_10177a8f737f49cfa471ac8da5992169",
            "value": " 169001984/? [00:03&lt;00:00, 58080788.47it/s]"
          }
        },
        "935343f46f3d4fb798ea531b8ad040b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3a53a95e4ea4f27a3db95832c81a67d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5abaa6610c249fe9fc97e68da52a4df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9bafdcaf4444d08b167194c418b140f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "663b7f0e50844fb2a9f9811cdc24303e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b6bfd6da7d64ada9675e19335f7f41b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10177a8f737f49cfa471ac8da5992169": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! nvidia-smi"
      ],
      "metadata": {
        "id": "7J8v4p-Pj-ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a84fc3a1-9a7c-4826-b293-bd940e74a8dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 12 05:49:20 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bBuLoWAo0i0"
      },
      "outputs": [],
      "source": [
        "import os,sys\n",
        "import os.path\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import random\n",
        "import pdb\n",
        "import argparse,time\n",
        "import math\n",
        "from copy import deepcopy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cf100_dir = '/content/drive/MyDrive/CSN-300 Lab based project/Gradient Projection Memory for continual learning/data'\n",
        "file_dir = '/content/drive/MyDrive/CSN-300 Lab based project/Gradient Projection Memory for continual learning/data/binary_cifar100'"
      ],
      "metadata": {
        "id": "Oq3gRxn8ZYzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get(seed=0,pc_valid=0.10):\n",
        "    data={}\n",
        "    taskcla=[]\n",
        "    size=[3,32,32]\n",
        "\n",
        "    if not os.path.isdir(file_dir):\n",
        "        os.makedirs(file_dir)\n",
        "\n",
        "        mean=[x/255 for x in [125.3,123.0,113.9]]\n",
        "        std=[x/255 for x in [63.0,62.1,66.7]]\n",
        "\n",
        "        # CIFAR100\n",
        "        dat={}\n",
        "        dat['train']=datasets.CIFAR100(cf100_dir,train=True,download=True,transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean,std)]))\n",
        "        dat['test']=datasets.CIFAR100(cf100_dir,train=False,download=True,transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean,std)]))\n",
        "        # dat['train'] = datasets.CIFAR100(cf100_dir,train=True,download=False,transform=transforms.Compose([transforms.ToTensor()]))\n",
        "        # dat['test']  = datasets.CIFAR100(cf100_dir,train=False,download=False,transform=transforms.Compose([transforms.ToTensor()]))\n",
        "        for n in range(10):\n",
        "            data[n]={}\n",
        "            data[n]['name']='cifar100'\n",
        "            data[n]['ncla']=10\n",
        "            data[n]['train']={'x': [],'y': []}\n",
        "            data[n]['test']={'x': [],'y': []}\n",
        "            data[n]['replay']={'x': [],'y': []}\n",
        "        for s in ['train','test']:\n",
        "            loader=torch.utils.data.DataLoader(dat[s],batch_size=1,shuffle=False)\n",
        "            for image,target in loader:\n",
        "                n=target.numpy()[0]\n",
        "                nn=(n//10)\n",
        "                data[nn][s]['x'].append(image) # 255 \n",
        "                data[nn][s]['y'].append(n%10)\n",
        "\n",
        "\n",
        "        # replay\n",
        "        loader=torch.utils.data.DataLoader(dat['train'],batch_size=1,shuffle=True)\n",
        "        counter=0;\n",
        "        visited=[0]*100\n",
        "        for image,target in loader:\n",
        "          n=target.numpy()[0]\n",
        "          nn=(n//10)\n",
        "          if(visited[n]<2):\n",
        "            data[nn]['replay']['x'].append(image) # 255 \n",
        "            data[nn]['replay']['y'].append(n%10)\n",
        "            visited[n]+=1;\n",
        "            counter+=1;\n",
        "          if(counter==200):\n",
        "            break\n",
        "          \n",
        "\n",
        "        # \"Unify\" and save\n",
        "        for t in data.keys():\n",
        "            for s in ['train','test', 'replay']:\n",
        "                data[t][s]['x']=torch.stack(data[t][s]['x']).view(-1,size[0],size[1],size[2])\n",
        "                data[t][s]['y']=torch.LongTensor(np.array(data[t][s]['y'],dtype=int)).view(-1)\n",
        "                torch.save(data[t][s]['x'], os.path.join(os.path.expanduser(file_dir),'data'+str(t)+s+'x.bin'))\n",
        "                torch.save(data[t][s]['y'], os.path.join(os.path.expanduser(file_dir),'data'+str(t)+s+'y.bin'))\n",
        "\n",
        "    # Load binary files\n",
        "    data={}\n",
        "    # ids=list(shuffle(np.arange(5),random_state=seed))\n",
        "    ids=list(np.arange(10))\n",
        "    print('Task order =',ids)\n",
        "    for i in range(10):\n",
        "        data[i] = dict.fromkeys(['name','ncla','train','test', 'replay'])\n",
        "        for s in ['train','test', 'replay']:\n",
        "            data[i][s]={'x':[],'y':[]}\n",
        "            data[i][s]['x']=torch.load(os.path.join(os.path.expanduser(file_dir),'data'+str(ids[i])+s+'x.bin'))\n",
        "            data[i][s]['y']=torch.load(os.path.join(os.path.expanduser(file_dir),'data'+str(ids[i])+s+'y.bin'))\n",
        "        data[i]['ncla']=len(np.unique(data[i]['train']['y'].numpy()))\n",
        "        if data[i]['ncla']==2:\n",
        "            data[i]['name']='cifar10-'+str(ids[i])\n",
        "        else:\n",
        "            data[i]['name']='cifar100-'+str(ids[i])\n",
        "\n",
        "    # Validation\n",
        "    for t in data.keys():\n",
        "        r=np.arange(data[t]['train']['x'].size(0))\n",
        "        r=np.array(shuffle(r,random_state=seed),dtype=int)\n",
        "        nvalid=int(pc_valid*len(r))\n",
        "        ivalid=torch.LongTensor(r[:nvalid])\n",
        "        itrain=torch.LongTensor(r[nvalid:])\n",
        "        data[t]['valid']={}\n",
        "        data[t]['valid']['x']=data[t]['train']['x'][ivalid].clone()\n",
        "        data[t]['valid']['y']=data[t]['train']['y'][ivalid].clone()\n",
        "        data[t]['train']['x']=data[t]['train']['x'][itrain].clone()\n",
        "        data[t]['train']['y']=data[t]['train']['y'][itrain].clone()\n",
        "\n",
        "    # Others\n",
        "    n=0\n",
        "    for t in data.keys():\n",
        "        taskcla.append((t,data[t]['ncla']))\n",
        "        n+=data[t]['ncla']\n",
        "    data['ncla']=n\n",
        "\n",
        "    return data,taskcla,size"
      ],
      "metadata": {
        "id": "qYc3T2fCXHcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_conv_output_size(Lin,kernel_size,stride=1,padding=0,dilation=1):\n",
        "    return int(np.floor((Lin+2*padding-dilation*(kernel_size-1)-1)/float(stride)+1))"
      ],
      "metadata": {
        "id": "RayVK9brXXXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self,taskcla):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.act=OrderedDict()\n",
        "        self.map =[]\n",
        "        self.ksize=[]\n",
        "        self.in_channel =[]\n",
        "        self.map.append(32)\n",
        "        self.conv1 = nn.Conv2d(3, 64, 4, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64, track_running_stats=False)\n",
        "        s=compute_conv_output_size(32,4)\n",
        "        s=s//2\n",
        "        self.ksize.append(4)\n",
        "        self.in_channel.append(3)\n",
        "        self.map.append(s)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(128, track_running_stats=False)\n",
        "        s=compute_conv_output_size(s,3)\n",
        "        s=s//2\n",
        "        self.ksize.append(3)\n",
        "        self.in_channel.append(64)\n",
        "        self.map.append(s)\n",
        "        self.conv3 = nn.Conv2d(128, 256, 2, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(256, track_running_stats=False)\n",
        "        s=compute_conv_output_size(s,2)\n",
        "        s=s//2\n",
        "        self.smid=s\n",
        "        self.ksize.append(2)\n",
        "        self.in_channel.append(128)\n",
        "        self.map.append(256*self.smid*self.smid)\n",
        "        self.maxpool=torch.nn.MaxPool2d(2)\n",
        "        self.relu=torch.nn.ReLU()\n",
        "        self.drop1=torch.nn.Dropout(0.2)\n",
        "        self.drop2=torch.nn.Dropout(0.5)\n",
        "\n",
        "        self.fc1 = nn.Linear(256*self.smid*self.smid,2048, bias=False)\n",
        "        self.bn4 = nn.BatchNorm1d(2048, track_running_stats=False)\n",
        "        self.fc2 = nn.Linear(2048,2048, bias=False)\n",
        "        self.bn5 = nn.BatchNorm1d(2048, track_running_stats=False)\n",
        "        self.map.extend([2048])\n",
        "        \n",
        "        self.taskcla = taskcla\n",
        "        self.fc3=torch.nn.ModuleList()\n",
        "        for t,n in self.taskcla:\n",
        "            self.fc3.append(torch.nn.Linear(2048,n,bias=False))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        bsz = deepcopy(x.size(0))\n",
        "        self.act['conv1']=x\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool(self.drop1(self.relu(self.bn1(x))))\n",
        "\n",
        "        self.act['conv2']=x\n",
        "        x = self.conv2(x)\n",
        "        x = self.maxpool(self.drop1(self.relu(self.bn2(x))))\n",
        "\n",
        "        self.act['conv3']=x\n",
        "        x = self.conv3(x)\n",
        "        x = self.maxpool(self.drop2(self.relu(self.bn3(x))))\n",
        "\n",
        "        x=x.view(bsz,-1)\n",
        "        self.act['fc1']=x\n",
        "        x = self.fc1(x)\n",
        "        x = self.drop2(self.relu(self.bn4(x)))\n",
        "\n",
        "        self.act['fc2']=x        \n",
        "        x = self.fc2(x)\n",
        "        x = self.drop2(self.relu(self.bn5(x)))\n",
        "        y=[]\n",
        "        for t,i in self.taskcla:\n",
        "            y.append(self.fc3[t](x))\n",
        "            \n",
        "        return y"
      ],
      "metadata": {
        "id": "Gw5MR7RLXY1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(model):\n",
        "    return deepcopy(model.state_dict())"
      ],
      "metadata": {
        "id": "_NpFNrwIXroX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_model_(model,state_dict):\n",
        "    model.load_state_dict(deepcopy(state_dict))\n",
        "    return"
      ],
      "metadata": {
        "id": "QJTTKYeWXvSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_learning_rate(optimizer, epoch, args):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        if (epoch ==1):\n",
        "            param_group['lr']=args.lr\n",
        "        else:\n",
        "            param_group['lr'] /= args.lr_factor"
      ],
      "metadata": {
        "id": "7FZGogWKXwr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(args, model, device, x,y, optimizer,criterion, task_id):\n",
        "    model.train()\n",
        "    r=np.arange(x.size(0))\n",
        "    np.random.shuffle(r)\n",
        "    r=torch.LongTensor(r).to(device)\n",
        "    # Loop batches\n",
        "    for i in range(0,len(r),args.batch_size_train):\n",
        "        if i+args.batch_size_train<=len(r): b=r[i:i+args.batch_size_train]\n",
        "        else: b=r[i:]\n",
        "        data = x[b]\n",
        "        data, target = data.to(device), y[b].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output[task_id], target)        \n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "gBFRqVgEX5Be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_projected(args,model,device,x,y,optimizer,criterion,feature_mat,task_id):\n",
        "    model.train()\n",
        "    r=np.arange(x.size(0))\n",
        "    np.random.shuffle(r)\n",
        "    r=torch.LongTensor(r).to(device)\n",
        "    # Loop batches\n",
        "    for i in range(0,len(r),args.batch_size_train):\n",
        "        if i+args.batch_size_train<=len(r): b=r[i:i+args.batch_size_train]\n",
        "        else: b=r[i:]\n",
        "        data = x[b]\n",
        "        data, target = data.to(device), y[b].to(device)\n",
        "        optimizer.zero_grad()        \n",
        "        output = model(data)\n",
        "        loss = criterion(output[task_id], target)         \n",
        "        loss.backward()\n",
        "        # Gradient Projections \n",
        "        kk = 0 \n",
        "        for k, (m,params) in enumerate(model.named_parameters()):\n",
        "            if k<15 and len(params.size())!=1:\n",
        "                sz =  params.grad.data.size(0)\n",
        "                params.grad.data = params.grad.data - torch.mm(params.grad.data.view(sz,-1),\\\n",
        "                                                        feature_mat[kk]).view(params.size())\n",
        "                kk +=1\n",
        "            elif (k<15 and len(params.size())==1) and task_id !=0 :\n",
        "                params.grad.data.fill_(0)\n",
        "\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "jybgW9mNX7n2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_projected_on_replay(model,device,x,y,optimizer,criterion,feature_mat):\n",
        "    model.train()\n",
        "    r=np.arange(x.size(0))\n",
        "    # np.random.shuffle(r)\n",
        "    r=torch.LongTensor(r).to(device)\n",
        "    batch_size=10\n",
        "    flag = True\n",
        "    # Loop batches\n",
        "    task_id=0\n",
        "    for i in range(0,len(r),batch_size):\n",
        "        if i+batch_size<=len(r): b=r[i:i+batch_size]\n",
        "        else: b=r[i:]\n",
        "        data = x[b]\n",
        "        data, target = data.to(device), y[b].to(device)\n",
        "        optimizer.zero_grad()        \n",
        "        output = model(data)\n",
        "        loss = criterion(output[task_id], target)         \n",
        "        loss.backward()\n",
        "        # Gradient Projections \n",
        "        kk = 0 \n",
        "        for k, (m,params) in enumerate(model.named_parameters()):\n",
        "            if k<15 and len(params.size())!=1:\n",
        "                sz =  params.grad.data.size(0)\n",
        "                params.grad.data = params.grad.data - torch.mm(params.grad.data.view(sz,-1),\\\n",
        "                                                        feature_mat[kk]).view(params.size())\n",
        "                kk +=1\n",
        "            elif (k<15 and len(params.size())==1) and task_id !=0 :\n",
        "                params.grad.data.fill_(0)\n",
        "\n",
        "        optimizer.step()\n",
        "        if(flag):\n",
        "          flag = False\n",
        "        else:\n",
        "          flag = True\n",
        "          task_id = task_id + 1"
      ],
      "metadata": {
        "id": "5tFqHsnGwaYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(args, model, device, x, y, criterion, task_id):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_num = 0 \n",
        "    correct = 0\n",
        "    r=np.arange(x.size(0))\n",
        "    np.random.shuffle(r)\n",
        "    r=torch.LongTensor(r).to(device)\n",
        "    with torch.no_grad():\n",
        "        # Loop batches\n",
        "        for i in range(0,len(r),args.batch_size_test):\n",
        "            if i+args.batch_size_test<=len(r): b=r[i:i+args.batch_size_test]\n",
        "            else: b=r[i:]\n",
        "            data = x[b]\n",
        "            data, target = data.to(device), y[b].to(device)\n",
        "            output = model(data)\n",
        "            loss = criterion(output[task_id], target)\n",
        "            pred = output[task_id].argmax(dim=1, keepdim=True) \n",
        "            \n",
        "            correct    += pred.eq(target.view_as(pred)).sum().item()\n",
        "            total_loss += loss.data.cpu().numpy().item()*len(b)\n",
        "            total_num  += len(b)\n",
        "\n",
        "    acc = 100. * correct / total_num\n",
        "    final_loss = total_loss / total_num\n",
        "    return final_loss, acc"
      ],
      "metadata": {
        "id": "Bf9uamTFX-9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_representation_matrix (net, device, x, y=None): \n",
        "    # Collect activations by forward pass\n",
        "    r=np.arange(x.size(0))\n",
        "    np.random.shuffle(r)\n",
        "    r=torch.LongTensor(r).to(device)\n",
        "    b=r[0:125] # Take 125 random samples \n",
        "    example_data = x[b]\n",
        "    example_data = example_data.to(device)\n",
        "    example_out  = net(example_data)\n",
        "    \n",
        "    batch_list=[2*12,100,100,125,125] \n",
        "    mat_list=[]\n",
        "    act_key=list(net.act.keys())\n",
        "    for i in range(len(net.map)):\n",
        "        bsz=batch_list[i]\n",
        "        k=0\n",
        "        if i<3:\n",
        "            ksz= net.ksize[i]\n",
        "            s=compute_conv_output_size(net.map[i],net.ksize[i])\n",
        "            mat = np.zeros((net.ksize[i]*net.ksize[i]*net.in_channel[i],s*s*bsz))\n",
        "            act = net.act[act_key[i]].detach().cpu().numpy()\n",
        "            for kk in range(bsz):\n",
        "                for ii in range(s):\n",
        "                    for jj in range(s):\n",
        "                        mat[:,k]=act[kk,:,ii:ksz+ii,jj:ksz+jj].reshape(-1) \n",
        "                        k +=1\n",
        "            mat_list.append(mat)\n",
        "        else:\n",
        "            act = net.act[act_key[i]].detach().cpu().numpy()\n",
        "            activation = act[0:bsz].transpose()\n",
        "            mat_list.append(activation)\n",
        "\n",
        "    print('-'*30)\n",
        "    print('Representation Matrix')\n",
        "    print('-'*30)\n",
        "    for i in range(len(mat_list)):\n",
        "        print ('Layer {} : {}'.format(i+1,mat_list[i].shape))\n",
        "    print('-'*30)\n",
        "    return mat_list"
      ],
      "metadata": {
        "id": "B7Eocwy2YBlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_GPM (model, mat_list, threshold, feature_list=[],):\n",
        "    print ('Threshold: ', threshold) \n",
        "    if not feature_list:\n",
        "        # After First Task \n",
        "        for i in range(len(mat_list)):\n",
        "            activation = mat_list[i]\n",
        "            U,S,Vh = np.linalg.svd(activation, full_matrices=False)\n",
        "            # criteria (Eq-5)\n",
        "            sval_total = (S**2).sum()\n",
        "            sval_ratio = (S**2)/sval_total\n",
        "            r = np.sum(np.cumsum(sval_ratio)<threshold[i]) #+1  \n",
        "            feature_list.append(U[:,0:r])\n",
        "    else:\n",
        "        for i in range(len(mat_list)):\n",
        "            activation = mat_list[i]\n",
        "            U1,S1,Vh1=np.linalg.svd(activation, full_matrices=False)\n",
        "            sval_total = (S1**2).sum()\n",
        "            # Projected Representation (Eq-8)\n",
        "            act_hat = activation - np.dot(np.dot(feature_list[i],feature_list[i].transpose()),activation)\n",
        "            U,S,Vh = np.linalg.svd(act_hat, full_matrices=False)\n",
        "            # criteria (Eq-9)\n",
        "            sval_hat = (S**2).sum()\n",
        "            sval_ratio = (S**2)/sval_total               \n",
        "            accumulated_sval = (sval_total-sval_hat)/sval_total\n",
        "            \n",
        "            r = 0\n",
        "            for ii in range (sval_ratio.shape[0]):\n",
        "                if accumulated_sval < threshold[i]:\n",
        "                    accumulated_sval += sval_ratio[ii]\n",
        "                    r += 1\n",
        "                else:\n",
        "                    break\n",
        "            if r == 0:\n",
        "                print ('Skip Updating GPM for layer: {}'.format(i+1)) \n",
        "                continue\n",
        "            # update GPM\n",
        "            Ui=np.hstack((feature_list[i],U[:,0:r]))  \n",
        "            if Ui.shape[1] > Ui.shape[0] :\n",
        "                feature_list[i]=Ui[:,0:Ui.shape[0]]\n",
        "            else:\n",
        "                feature_list[i]=Ui\n",
        "    \n",
        "    print('-'*40)\n",
        "    print('Gradient Constraints Summary')\n",
        "    print('-'*40)\n",
        "    for i in range(len(feature_list)):\n",
        "        print ('Layer {} : {}/{}'.format(i+1,feature_list[i].shape[1], feature_list[i].shape[0]))\n",
        "    print('-'*40)\n",
        "    return feature_list "
      ],
      "metadata": {
        "id": "EpmlmdfBYIH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(args):\n",
        "    tstart=time.time()\n",
        "    ## Device Setting \n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    torch.manual_seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    ## Load CIFAR100 DATASET\n",
        "    data,taskcla,inputsize=get(seed=args.seed, pc_valid=args.pc_valid)\n",
        "\n",
        "    acc_matrix=np.zeros((10,10))\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    task_id = 0\n",
        "    task_list = []\n",
        "\n",
        "    #our approach\n",
        "    print(data.keys())\n",
        "    # print(data[0]['replay'])\n",
        "    x_replay = data[0]['replay']['x']\n",
        "    y_replay = data[0]['replay']['y']\n",
        "    #################\n",
        "\n",
        "\n",
        "    for k,ncla in taskcla:\n",
        "        # specify threshold hyperparameter\n",
        "        threshold = np.array([0.97] * 5) + task_id*np.array([0.003] * 5)\n",
        "     \n",
        "        print('*'*100)\n",
        "        print('Task {:2d} ({:s})'.format(k,data[k]['name']))\n",
        "        print('*'*100)\n",
        "        xtrain=data[k]['train']['x']\n",
        "        ytrain=data[k]['train']['y']\n",
        "        xvalid=data[k]['valid']['x']\n",
        "        yvalid=data[k]['valid']['y']\n",
        "        xtest =data[k]['test']['x']\n",
        "        ytest =data[k]['test']['y']\n",
        "        task_list.append(k)\n",
        "\n",
        "        lr = args.lr \n",
        "        best_loss=np.inf\n",
        "        print ('-'*40)\n",
        "        print ('Task ID :{} | Learning Rate : {}'.format(task_id, lr))\n",
        "        print ('-'*40)\n",
        "        \n",
        "        if task_id==0:\n",
        "            model = AlexNet(taskcla).to(device)\n",
        "            print ('Model parameters ---')\n",
        "            for k_t, (m, param) in enumerate(model.named_parameters()):\n",
        "                print (k_t,m,param.shape)\n",
        "            print ('-'*40)\n",
        "\n",
        "            best_model=get_model(model)\n",
        "            feature_list =[]\n",
        "            optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "            for epoch in range(1, args.n_epochs+1):\n",
        "                # Train\n",
        "                clock0=time.time()\n",
        "                train(args, model, device, xtrain, ytrain, optimizer, criterion, k)\n",
        "                clock1=time.time()\n",
        "                tr_loss,tr_acc = test(args, model, device, xtrain, ytrain,  criterion, k)\n",
        "                print('Epoch {:3d} | Train: loss={:.3f}, acc={:5.1f}% | time={:5.1f}ms |'.format(epoch,\\\n",
        "                                                            tr_loss,tr_acc, 1000*(clock1-clock0)),end='')\n",
        "                # Validate\n",
        "                valid_loss,valid_acc = test(args, model, device, xvalid, yvalid,  criterion, k)\n",
        "                print(' Valid: loss={:.3f}, acc={:5.1f}% |'.format(valid_loss, valid_acc),end='')\n",
        "                # Adapt lr\n",
        "                if valid_loss<best_loss:\n",
        "                    best_loss=valid_loss\n",
        "                    best_model=get_model(model)\n",
        "                    patience=args.lr_patience\n",
        "                    print(' *',end='')\n",
        "                else:\n",
        "                    patience-=1\n",
        "                    if patience<=0:\n",
        "                        lr/=args.lr_factor\n",
        "                        print(' lr={:.1e}'.format(lr),end='')\n",
        "                        if lr<args.lr_min:\n",
        "                            print()\n",
        "                            break\n",
        "                        patience=args.lr_patience\n",
        "                        adjust_learning_rate(optimizer, epoch, args)\n",
        "                print()\n",
        "            set_model_(model,best_model)\n",
        "            # Test\n",
        "            print ('-'*40)\n",
        "            test_loss, test_acc = test(args, model, device, xtest, ytest,  criterion, k)\n",
        "            print('Test: loss={:.3f} , acc={:5.1f}%'.format(test_loss,test_acc))\n",
        "            # Memory Update  \n",
        "            mat_list = get_representation_matrix (model, device, xtrain, ytrain)\n",
        "            feature_list = update_GPM (model, mat_list, threshold, feature_list)\n",
        "\n",
        "        else:\n",
        "            optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
        "            feature_mat = []\n",
        "            # Projection Matrix Precomputation\n",
        "            for i in range(len(model.act)):\n",
        "                Uf=torch.Tensor(np.dot(feature_list[i],feature_list[i].transpose())).to(device)\n",
        "                print('Layer {} - Projection Matrix shape: {}'.format(i+1,Uf.shape))\n",
        "                feature_mat.append(Uf)\n",
        "            print ('-'*40)\n",
        "            for epoch in range(1, args.n_epochs+1):\n",
        "                # Train \n",
        "                clock0=time.time()\n",
        "                train_projected(args, model,device,xtrain, ytrain,optimizer,criterion,feature_mat,k)\n",
        "                clock1=time.time()\n",
        "                tr_loss, tr_acc = test(args, model, device, xtrain, ytrain,criterion,k)\n",
        "                print('Epoch {:3d} | Train: loss={:.3f}, acc={:5.1f}% | time={:5.1f}ms |'.format(epoch,\\\n",
        "                                                        tr_loss, tr_acc, 1000*(clock1-clock0)),end='')\n",
        "                # Validate\n",
        "                valid_loss,valid_acc = test(args, model, device, xvalid, yvalid, criterion,k)\n",
        "                print(' Valid: loss={:.3f}, acc={:5.1f}% |'.format(valid_loss, valid_acc),end='')\n",
        "                # Adapt lr\n",
        "                if valid_loss<best_loss:\n",
        "                    best_loss=valid_loss\n",
        "                    best_model=get_model(model)\n",
        "                    patience=args.lr_patience\n",
        "                    print(' *',end='')\n",
        "                else:\n",
        "                    patience-=1\n",
        "                    if patience<=0:\n",
        "                        lr/=args.lr_factor\n",
        "                        print(' lr={:.1e}'.format(lr),end='')\n",
        "                        if lr<args.lr_min:\n",
        "                            print()\n",
        "                            break\n",
        "                        patience=args.lr_patience\n",
        "                        adjust_learning_rate(optimizer, epoch, args)\n",
        "                print()\n",
        "            set_model_(model,best_model)\n",
        "\n",
        "\n",
        "            #Replay\n",
        "            for epoch in range(1, 5+1):\n",
        "                # Train \n",
        "                clock0=time.time()\n",
        "                train_projected_on_replay(model,device,x_replay, y_replay,optimizer,criterion,feature_mat)\n",
        "                clock1=time.time()\n",
        "\n",
        "            # adding in replay\n",
        "            x_replay = torch.cat((x_replay, data[k]['replay']['x']))\n",
        "            y_replay = torch.cat((y_replay, data[k]['replay']['y']))\n",
        "            # \n",
        "\n",
        "            # Test \n",
        "            test_loss, test_acc = test(args, model, device, xtest, ytest,  criterion,k)\n",
        "            print('Test: loss={:.3f} , acc={:5.1f}%'.format(test_loss,test_acc))  \n",
        "            # Memory Update \n",
        "            mat_list = get_representation_matrix (model, device, xtrain, ytrain)\n",
        "            feature_list = update_GPM (model, mat_list, threshold, feature_list)\n",
        "        \n",
        "        # save accuracy \n",
        "        jj = 0 \n",
        "        for ii in np.array(task_list)[0:task_id+1]:\n",
        "            xtest =data[ii]['test']['x']\n",
        "            ytest =data[ii]['test']['y'] \n",
        "            _, acc_matrix[task_id,jj] = test(args, model, device, xtest, ytest,criterion,ii) \n",
        "            jj +=1\n",
        "        print('Accuracies =')\n",
        "        for i_a in range(task_id+1):\n",
        "            print('\\t',end='')\n",
        "            for j_a in range(acc_matrix.shape[1]):\n",
        "                print('{:5.1f}% '.format(acc_matrix[i_a,j_a]),end='')\n",
        "            print()\n",
        "        # update task id \n",
        "        task_id +=1\n",
        "    print('-'*50)\n",
        "    # Simulation Results \n",
        "    print ('Task Order : {}'.format(np.array(task_list)))\n",
        "    print ('Final Avg Accuracy: {:5.2f}%'.format(acc_matrix[-1].mean())) \n",
        "    bwt=np.mean((acc_matrix[-1]-np.diag(acc_matrix))[:-1]) \n",
        "    print ('Backward transfer: {:5.2f}%'.format(bwt))\n",
        "    print('[Elapsed time = {:.1f} ms]'.format((time.time()-tstart)*1000))\n",
        "    print('-'*50)\n",
        "    # Plots\n",
        "    array = acc_matrix\n",
        "    df_cm = pd.DataFrame(array, index = [i for i in [\"T1\",\"T2\",\"T3\",\"T4\",\"T5\",\"T6\",\"T7\",\"T8\",\"T9\",\"T10\"]],\n",
        "                      columns = [i for i in [\"T1\",\"T2\",\"T3\",\"T4\",\"T5\",\"T6\",\"T7\",\"T8\",\"T9\",\"T10\"]])\n",
        "    sn.set(font_scale=1.4) \n",
        "    sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 10})\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "5HokDGpjYL__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Training parameters\n",
        "    parser = argparse.ArgumentParser(description='Sequential PMNIST with GPM')\n",
        "    parser.add_argument('--batch_size_train', type=int, default=64, metavar='N',\n",
        "                        help='input batch size for training (default: 64)')\n",
        "    parser.add_argument('--batch_size_test', type=int, default=64, metavar='N',\n",
        "                        help='input batch size for testing (default: 64)')\n",
        "    parser.add_argument('--n_epochs', type=int, default=200, metavar='N',\n",
        "                        help='number of training epochs/task (default: 200)')\n",
        "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
        "                        help='random seed (default: 1)')\n",
        "    parser.add_argument('--pc_valid',default=0.05,type=float,\n",
        "                        help='fraction of training data used for validation')\n",
        "    # Optimizer parameters\n",
        "    parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
        "                        help='learning rate (default: 0.01)')\n",
        "    parser.add_argument('--momentum', type=float, default=0.9, metavar='M',\n",
        "                        help='SGD momentum (default: 0.9)')\n",
        "    parser.add_argument('--lr_min', type=float, default=1e-5, metavar='LRM',\n",
        "                        help='minimum lr rate (default: 1e-5)')\n",
        "    parser.add_argument('--lr_patience', type=int, default=6, metavar='LRP',\n",
        "                        help='hold before decaying lr (default: 6)')\n",
        "    parser.add_argument('--lr_factor', type=int, default=2, metavar='LRF',\n",
        "                        help='lr decay factor (default: 2)')\n",
        "\n",
        "    args, unknown = parser.parse_known_args()\n",
        "    print('='*100)\n",
        "    print('Arguments =')\n",
        "    for arg in vars(args):\n",
        "        print('\\t'+arg+':',getattr(args,arg))\n",
        "    print('='*100)\n",
        "\n",
        "    main(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ab3cce1340f741d68a2da72c34ffe80b",
            "29b00f4a8c3147ae8ba51aac39ec18ce",
            "cf770af8611b4e1488778a13cd7985a3",
            "8120e9bbf84b4dfc82ef5ffa9be88b05",
            "935343f46f3d4fb798ea531b8ad040b8",
            "d3a53a95e4ea4f27a3db95832c81a67d",
            "d5abaa6610c249fe9fc97e68da52a4df",
            "a9bafdcaf4444d08b167194c418b140f",
            "663b7f0e50844fb2a9f9811cdc24303e",
            "7b6bfd6da7d64ada9675e19335f7f41b",
            "10177a8f737f49cfa471ac8da5992169"
          ]
        },
        "id": "KyLacrROYNzX",
        "outputId": "e8b87297-58a5-4f89-adfd-09d099c76258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "Arguments =\n",
            "\tbatch_size_train: 64\n",
            "\tbatch_size_test: 64\n",
            "\tn_epochs: 200\n",
            "\tseed: 1\n",
            "\tpc_valid: 0.05\n",
            "\tlr: 0.01\n",
            "\tmomentum: 0.9\n",
            "\tlr_min: 1e-05\n",
            "\tlr_patience: 6\n",
            "\tlr_factor: 2\n",
            "====================================================================================================\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to /content/drive/MyDrive/CSN-300 Lab based project/Gradient Projection Memory for continual learning/data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/169001437 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab3cce1340f741d68a2da72c34ffe80b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/drive/MyDrive/CSN-300 Lab based project/Gradient Projection Memory for continual learning/data/cifar-100-python.tar.gz to /content/drive/MyDrive/CSN-300 Lab based project/Gradient Projection Memory for continual learning/data\n",
            "Files already downloaded and verified\n",
            "Task order = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 'ncla'])\n",
            "****************************************************************************************************\n",
            "Task  0 (cifar100-0)\n",
            "****************************************************************************************************\n",
            "----------------------------------------\n",
            "Task ID :0 | Learning Rate : 0.01\n",
            "----------------------------------------\n",
            "Model parameters ---\n",
            "0 conv1.weight torch.Size([64, 3, 4, 4])\n",
            "1 bn1.weight torch.Size([64])\n",
            "2 bn1.bias torch.Size([64])\n",
            "3 conv2.weight torch.Size([128, 64, 3, 3])\n",
            "4 bn2.weight torch.Size([128])\n",
            "5 bn2.bias torch.Size([128])\n",
            "6 conv3.weight torch.Size([256, 128, 2, 2])\n",
            "7 bn3.weight torch.Size([256])\n",
            "8 bn3.bias torch.Size([256])\n",
            "9 fc1.weight torch.Size([2048, 1024])\n",
            "10 bn4.weight torch.Size([2048])\n",
            "11 bn4.bias torch.Size([2048])\n",
            "12 fc2.weight torch.Size([2048, 2048])\n",
            "13 bn5.weight torch.Size([2048])\n",
            "14 bn5.bias torch.Size([2048])\n",
            "15 fc3.0.weight torch.Size([10, 2048])\n",
            "16 fc3.1.weight torch.Size([10, 2048])\n",
            "17 fc3.2.weight torch.Size([10, 2048])\n",
            "18 fc3.3.weight torch.Size([10, 2048])\n",
            "19 fc3.4.weight torch.Size([10, 2048])\n",
            "20 fc3.5.weight torch.Size([10, 2048])\n",
            "21 fc3.6.weight torch.Size([10, 2048])\n",
            "22 fc3.7.weight torch.Size([10, 2048])\n",
            "23 fc3.8.weight torch.Size([10, 2048])\n",
            "24 fc3.9.weight torch.Size([10, 2048])\n",
            "----------------------------------------\n",
            "Epoch   1 | Train: loss=1.559, acc= 45.7% | time=961.2ms | Valid: loss=1.613, acc= 43.6% | *\n",
            "Epoch   2 | Train: loss=1.463, acc= 51.4% | time=562.2ms | Valid: loss=1.503, acc= 51.6% | *\n",
            "Epoch   3 | Train: loss=1.267, acc= 57.4% | time=566.8ms | Valid: loss=1.400, acc= 53.6% | *\n",
            "Epoch   4 | Train: loss=1.226, acc= 59.2% | time=560.8ms | Valid: loss=1.356, acc= 54.0% | *\n",
            "Epoch   5 | Train: loss=1.073, acc= 64.2% | time=562.6ms | Valid: loss=1.292, acc= 62.0% | *\n",
            "Epoch   6 | Train: loss=0.969, acc= 67.5% | time=561.6ms | Valid: loss=1.214, acc= 61.2% | *\n",
            "Epoch   7 | Train: loss=0.961, acc= 67.8% | time=563.4ms | Valid: loss=1.192, acc= 62.4% | *\n",
            "Epoch   8 | Train: loss=0.948, acc= 68.8% | time=561.1ms | Valid: loss=1.238, acc= 62.4% |\n",
            "Epoch   9 | Train: loss=0.828, acc= 72.8% | time=565.6ms | Valid: loss=1.154, acc= 63.6% | *\n",
            "Epoch  10 | Train: loss=0.869, acc= 72.1% | time=566.1ms | Valid: loss=1.196, acc= 66.0% |\n",
            "Epoch  11 | Train: loss=0.783, acc= 74.6% | time=568.4ms | Valid: loss=1.054, acc= 67.6% | *\n",
            "Epoch  12 | Train: loss=0.751, acc= 75.6% | time=563.4ms | Valid: loss=1.111, acc= 64.4% |\n",
            "Epoch  13 | Train: loss=0.767, acc= 74.8% | time=567.0ms | Valid: loss=1.130, acc= 69.2% |\n",
            "Epoch  14 | Train: loss=0.767, acc= 75.7% | time=567.0ms | Valid: loss=1.197, acc= 66.4% |\n",
            "Epoch  15 | Train: loss=0.628, acc= 79.1% | time=568.9ms | Valid: loss=1.048, acc= 67.2% | *\n",
            "Epoch  16 | Train: loss=0.621, acc= 80.2% | time=564.5ms | Valid: loss=1.041, acc= 69.2% | *\n",
            "Epoch  17 | Train: loss=0.609, acc= 80.3% | time=562.4ms | Valid: loss=1.054, acc= 70.4% |\n",
            "Epoch  18 | Train: loss=0.628, acc= 79.0% | time=566.0ms | Valid: loss=1.088, acc= 68.0% |\n",
            "Epoch  19 | Train: loss=0.991, acc= 71.0% | time=563.5ms | Valid: loss=1.471, acc= 64.8% |\n",
            "Epoch  20 | Train: loss=0.512, acc= 83.1% | time=560.2ms | Valid: loss=1.097, acc= 67.2% |\n",
            "Epoch  21 | Train: loss=0.499, acc= 83.1% | time=565.4ms | Valid: loss=1.010, acc= 72.8% | *\n",
            "Epoch  22 | Train: loss=0.686, acc= 77.6% | time=568.6ms | Valid: loss=1.204, acc= 66.4% |\n",
            "Epoch  23 | Train: loss=0.754, acc= 76.6% | time=567.9ms | Valid: loss=1.306, acc= 68.0% |\n",
            "Epoch  24 | Train: loss=0.627, acc= 79.9% | time=565.1ms | Valid: loss=1.236, acc= 72.0% |\n",
            "Epoch  25 | Train: loss=0.498, acc= 83.1% | time=570.6ms | Valid: loss=1.175, acc= 66.8% |\n",
            "Epoch  26 | Train: loss=0.417, acc= 85.3% | time=564.6ms | Valid: loss=1.009, acc= 73.2% | *\n",
            "Epoch  27 | Train: loss=0.626, acc= 80.5% | time=568.1ms | Valid: loss=1.109, acc= 70.4% |\n",
            "Epoch  28 | Train: loss=0.423, acc= 85.2% | time=568.6ms | Valid: loss=1.109, acc= 70.4% |\n",
            "Epoch  29 | Train: loss=0.301, acc= 90.0% | time=568.3ms | Valid: loss=1.000, acc= 74.4% | *\n",
            "Epoch  30 | Train: loss=0.364, acc= 87.6% | time=564.5ms | Valid: loss=1.105, acc= 71.2% |\n",
            "Epoch  31 | Train: loss=0.331, acc= 88.8% | time=570.0ms | Valid: loss=1.018, acc= 73.6% |\n",
            "Epoch  32 | Train: loss=0.368, acc= 87.6% | time=569.5ms | Valid: loss=1.068, acc= 70.0% |\n",
            "Epoch  33 | Train: loss=0.371, acc= 87.2% | time=575.9ms | Valid: loss=1.118, acc= 69.6% |\n",
            "Epoch  34 | Train: loss=0.270, acc= 90.5% | time=568.7ms | Valid: loss=1.002, acc= 76.0% |\n",
            "Epoch  35 | Train: loss=0.339, acc= 88.7% | time=565.7ms | Valid: loss=1.220, acc= 72.0% | lr=5.0e-03\n",
            "Epoch  36 | Train: loss=0.215, acc= 92.4% | time=573.4ms | Valid: loss=0.981, acc= 72.8% | *\n",
            "Epoch  37 | Train: loss=0.192, acc= 93.5% | time=572.5ms | Valid: loss=1.040, acc= 73.6% |\n",
            "Epoch  38 | Train: loss=0.189, acc= 93.5% | time=571.7ms | Valid: loss=0.924, acc= 75.2% | *\n",
            "Epoch  39 | Train: loss=0.185, acc= 93.3% | time=566.2ms | Valid: loss=1.015, acc= 73.6% |\n",
            "Epoch  40 | Train: loss=0.159, acc= 94.4% | time=573.9ms | Valid: loss=1.042, acc= 74.8% |\n",
            "Epoch  41 | Train: loss=0.212, acc= 92.2% | time=573.0ms | Valid: loss=1.141, acc= 73.2% |\n",
            "Epoch  42 | Train: loss=0.179, acc= 93.8% | time=569.3ms | Valid: loss=0.975, acc= 74.0% |\n",
            "Epoch  43 | Train: loss=0.152, acc= 94.7% | time=862.1ms | Valid: loss=1.001, acc= 75.2% |\n",
            "Epoch  44 | Train: loss=0.154, acc= 95.0% | time=794.3ms | Valid: loss=1.006, acc= 74.0% | lr=2.5e-03\n",
            "Epoch  45 | Train: loss=0.130, acc= 95.5% | time=809.1ms | Valid: loss=0.884, acc= 78.0% | *\n",
            "Epoch  46 | Train: loss=0.131, acc= 95.8% | time=575.0ms | Valid: loss=0.914, acc= 76.0% |\n",
            "Epoch  47 | Train: loss=0.122, acc= 95.9% | time=569.9ms | Valid: loss=0.907, acc= 78.4% |\n",
            "Epoch  48 | Train: loss=0.116, acc= 96.1% | time=568.6ms | Valid: loss=0.902, acc= 77.6% |\n",
            "Epoch  49 | Train: loss=0.122, acc= 96.0% | time=569.9ms | Valid: loss=0.979, acc= 76.4% |\n",
            "Epoch  50 | Train: loss=0.119, acc= 96.2% | time=578.4ms | Valid: loss=0.950, acc= 77.2% |\n",
            "Epoch  51 | Train: loss=0.133, acc= 95.3% | time=571.1ms | Valid: loss=1.007, acc= 76.0% | lr=1.3e-03\n",
            "Epoch  52 | Train: loss=0.099, acc= 96.8% | time=570.1ms | Valid: loss=0.924, acc= 77.6% |\n",
            "Epoch  53 | Train: loss=0.099, acc= 96.8% | time=571.5ms | Valid: loss=0.939, acc= 76.0% |\n",
            "Epoch  54 | Train: loss=0.097, acc= 96.7% | time=571.0ms | Valid: loss=0.893, acc= 77.6% |\n",
            "Epoch  55 | Train: loss=0.100, acc= 96.9% | time=576.4ms | Valid: loss=0.911, acc= 78.0% |\n",
            "Epoch  56 | Train: loss=0.097, acc= 96.8% | time=569.5ms | Valid: loss=0.897, acc= 78.8% |\n",
            "Epoch  57 | Train: loss=0.090, acc= 97.2% | time=578.8ms | Valid: loss=0.915, acc= 78.8% | lr=6.3e-04\n",
            "Epoch  58 | Train: loss=0.092, acc= 97.0% | time=571.1ms | Valid: loss=0.952, acc= 77.6% |\n",
            "Epoch  59 | Train: loss=0.096, acc= 97.1% | time=572.0ms | Valid: loss=0.938, acc= 75.6% |\n",
            "Epoch  60 | Train: loss=0.092, acc= 96.9% | time=574.3ms | Valid: loss=0.948, acc= 76.4% |\n",
            "Epoch  61 | Train: loss=0.092, acc= 96.9% | time=570.5ms | Valid: loss=0.925, acc= 78.4% |\n",
            "Epoch  62 | Train: loss=0.091, acc= 97.1% | time=569.5ms | Valid: loss=0.935, acc= 77.2% |\n",
            "Epoch  63 | Train: loss=0.092, acc= 97.0% | time=574.3ms | Valid: loss=0.882, acc= 77.6% | *\n",
            "Epoch  64 | Train: loss=0.090, acc= 97.1% | time=579.8ms | Valid: loss=0.940, acc= 77.2% |\n",
            "Epoch  65 | Train: loss=0.090, acc= 97.2% | time=571.3ms | Valid: loss=0.915, acc= 77.2% |\n",
            "Epoch  66 | Train: loss=0.089, acc= 97.2% | time=573.6ms | Valid: loss=0.945, acc= 76.0% |\n",
            "Epoch  67 | Train: loss=0.090, acc= 97.1% | time=573.2ms | Valid: loss=1.017, acc= 76.4% |\n",
            "Epoch  68 | Train: loss=0.081, acc= 97.3% | time=575.4ms | Valid: loss=0.989, acc= 75.2% |\n",
            "Epoch  69 | Train: loss=0.088, acc= 97.1% | time=569.5ms | Valid: loss=0.970, acc= 76.4% | lr=3.1e-04\n",
            "Epoch  70 | Train: loss=0.088, acc= 96.9% | time=570.2ms | Valid: loss=0.961, acc= 77.2% |\n",
            "Epoch  71 | Train: loss=0.083, acc= 97.4% | time=574.5ms | Valid: loss=0.956, acc= 75.2% |\n",
            "Epoch  72 | Train: loss=0.082, acc= 97.4% | time=573.8ms | Valid: loss=1.019, acc= 76.8% |\n",
            "Epoch  73 | Train: loss=0.083, acc= 97.3% | time=573.0ms | Valid: loss=0.918, acc= 77.2% |\n",
            "Epoch  74 | Train: loss=0.084, acc= 97.1% | time=568.8ms | Valid: loss=0.920, acc= 77.6% |\n",
            "Epoch  75 | Train: loss=0.083, acc= 97.5% | time=577.9ms | Valid: loss=0.962, acc= 76.0% | lr=1.6e-04\n",
            "Epoch  76 | Train: loss=0.083, acc= 97.5% | time=575.5ms | Valid: loss=0.967, acc= 76.4% |\n",
            "Epoch  77 | Train: loss=0.080, acc= 97.4% | time=574.6ms | Valid: loss=0.982, acc= 78.8% |\n",
            "Epoch  78 | Train: loss=0.085, acc= 97.5% | time=577.3ms | Valid: loss=0.910, acc= 76.4% |\n",
            "Epoch  79 | Train: loss=0.085, acc= 97.5% | time=575.8ms | Valid: loss=0.942, acc= 77.6% |\n",
            "Epoch  80 | Train: loss=0.082, acc= 97.3% | time=578.0ms | Valid: loss=0.892, acc= 79.6% |\n",
            "Epoch  81 | Train: loss=0.081, acc= 97.7% | time=574.3ms | Valid: loss=0.949, acc= 76.8% | lr=7.8e-05\n",
            "Epoch  82 | Train: loss=0.079, acc= 97.7% | time=578.6ms | Valid: loss=0.969, acc= 76.0% |\n",
            "Epoch  83 | Train: loss=0.084, acc= 97.2% | time=572.0ms | Valid: loss=0.953, acc= 77.6% |\n",
            "Epoch  84 | Train: loss=0.081, acc= 97.6% | time=572.8ms | Valid: loss=0.900, acc= 78.8% |\n",
            "Epoch  85 | Train: loss=0.082, acc= 97.3% | time=576.2ms | Valid: loss=0.908, acc= 78.0% |\n",
            "Epoch  86 | Train: loss=0.081, acc= 97.6% | time=576.5ms | Valid: loss=0.904, acc= 77.2% |\n",
            "Epoch  87 | Train: loss=0.082, acc= 97.5% | time=575.6ms | Valid: loss=0.967, acc= 79.6% | lr=3.9e-05\n",
            "Epoch  88 | Train: loss=0.080, acc= 97.5% | time=577.6ms | Valid: loss=0.955, acc= 75.6% |\n",
            "Epoch  89 | Train: loss=0.081, acc= 97.6% | time=573.8ms | Valid: loss=0.901, acc= 77.2% |\n",
            "Epoch  90 | Train: loss=0.080, acc= 97.4% | time=576.7ms | Valid: loss=0.924, acc= 76.0% |\n",
            "Epoch  91 | Train: loss=0.083, acc= 97.4% | time=585.6ms | Valid: loss=0.941, acc= 78.8% |\n",
            "Epoch  92 | Train: loss=0.082, acc= 97.7% | time=576.9ms | Valid: loss=0.927, acc= 77.2% |\n",
            "Epoch  93 | Train: loss=0.079, acc= 97.5% | time=580.1ms | Valid: loss=0.935, acc= 77.6% | lr=2.0e-05\n",
            "Epoch  94 | Train: loss=0.084, acc= 97.3% | time=578.0ms | Valid: loss=0.911, acc= 77.2% |\n",
            "Epoch  95 | Train: loss=0.083, acc= 97.6% | time=576.5ms | Valid: loss=0.891, acc= 77.2% |\n",
            "Epoch  96 | Train: loss=0.084, acc= 97.4% | time=578.9ms | Valid: loss=0.933, acc= 76.4% |\n",
            "Epoch  97 | Train: loss=0.078, acc= 97.6% | time=574.1ms | Valid: loss=0.887, acc= 78.4% |\n",
            "Epoch  98 | Train: loss=0.080, acc= 97.5% | time=572.4ms | Valid: loss=0.897, acc= 78.4% |\n",
            "Epoch  99 | Train: loss=0.086, acc= 97.3% | time=575.5ms | Valid: loss=0.865, acc= 78.8% | *\n",
            "Epoch 100 | Train: loss=0.084, acc= 97.3% | time=580.8ms | Valid: loss=0.981, acc= 77.2% |\n",
            "Epoch 101 | Train: loss=0.082, acc= 97.5% | time=584.4ms | Valid: loss=0.972, acc= 75.6% |\n",
            "Epoch 102 | Train: loss=0.086, acc= 97.3% | time=581.4ms | Valid: loss=0.976, acc= 76.0% |\n",
            "Epoch 103 | Train: loss=0.086, acc= 97.3% | time=580.0ms | Valid: loss=0.949, acc= 77.2% |\n",
            "Epoch 104 | Train: loss=0.080, acc= 97.5% | time=575.0ms | Valid: loss=0.936, acc= 77.6% |\n",
            "Epoch 105 | Train: loss=0.080, acc= 97.7% | time=574.7ms | Valid: loss=0.932, acc= 79.2% | lr=9.8e-06\n",
            "----------------------------------------\n",
            "Test: loss=0.880 , acc= 78.2%\n",
            "------------------------------\n",
            "Representation Matrix\n",
            "------------------------------\n",
            "Layer 1 : (48, 20184)\n",
            "Layer 2 : (576, 14400)\n",
            "Layer 3 : (512, 2500)\n",
            "Layer 4 : (1024, 125)\n",
            "Layer 5 : (2048, 125)\n",
            "------------------------------\n",
            "Threshold:  [0.97 0.97 0.97 0.97 0.97]\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 9/48\n",
            "Layer 2 : 129/576\n",
            "Layer 3 : 198/512\n",
            "Layer 4 : 79/1024\n",
            "Layer 5 : 97/2048\n",
            "----------------------------------------\n",
            "Accuracies =\n",
            "\t 78.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "****************************************************************************************************\n",
            "Task  1 (cifar100-1)\n",
            "****************************************************************************************************\n",
            "----------------------------------------\n",
            "Task ID :1 | Learning Rate : 0.01\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([48, 48])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([576, 576])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([512, 512])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([1024, 1024])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([2048, 2048])\n",
            "----------------------------------------\n",
            "Epoch   1 | Train: loss=1.479, acc= 47.6% | time=1038.4ms | Valid: loss=1.410, acc= 51.2% | *\n",
            "Epoch   2 | Train: loss=1.289, acc= 55.4% | time=966.1ms | Valid: loss=1.223, acc= 56.0% | *\n",
            "Epoch   3 | Train: loss=1.233, acc= 57.7% | time=965.0ms | Valid: loss=1.196, acc= 55.6% | *\n",
            "Epoch   4 | Train: loss=1.174, acc= 59.7% | time=969.7ms | Valid: loss=1.166, acc= 60.0% | *\n",
            "Epoch   5 | Train: loss=1.091, acc= 62.1% | time=964.3ms | Valid: loss=1.131, acc= 60.0% | *\n",
            "Epoch   6 | Train: loss=1.041, acc= 64.9% | time=968.1ms | Valid: loss=1.094, acc= 63.2% | *\n",
            "Epoch   7 | Train: loss=1.031, acc= 65.2% | time=969.6ms | Valid: loss=1.080, acc= 60.8% | *\n",
            "Epoch   8 | Train: loss=0.964, acc= 67.2% | time=968.8ms | Valid: loss=1.022, acc= 64.4% | *\n",
            "Epoch   9 | Train: loss=0.940, acc= 67.8% | time=971.1ms | Valid: loss=1.068, acc= 62.0% |\n",
            "Epoch  10 | Train: loss=0.900, acc= 69.6% | time=971.0ms | Valid: loss=1.043, acc= 62.8% |\n",
            "Epoch  11 | Train: loss=0.869, acc= 70.4% | time=973.6ms | Valid: loss=1.019, acc= 64.4% | *\n",
            "Epoch  12 | Train: loss=0.836, acc= 71.7% | time=974.4ms | Valid: loss=0.984, acc= 66.4% | *\n",
            "Epoch  13 | Train: loss=0.815, acc= 72.4% | time=972.1ms | Valid: loss=1.023, acc= 66.0% |\n",
            "Epoch  14 | Train: loss=0.783, acc= 73.8% | time=973.0ms | Valid: loss=1.006, acc= 67.6% |\n",
            "Epoch  15 | Train: loss=0.782, acc= 73.7% | time=974.1ms | Valid: loss=1.039, acc= 66.0% |\n",
            "Epoch  16 | Train: loss=0.780, acc= 73.5% | time=977.5ms | Valid: loss=1.026, acc= 66.8% |\n",
            "Epoch  17 | Train: loss=0.706, acc= 76.1% | time=978.7ms | Valid: loss=0.969, acc= 66.0% | *\n",
            "Epoch  18 | Train: loss=0.683, acc= 76.8% | time=981.4ms | Valid: loss=0.993, acc= 67.6% |\n",
            "Epoch  19 | Train: loss=0.679, acc= 77.7% | time=987.3ms | Valid: loss=0.968, acc= 68.4% | *\n",
            "Epoch  20 | Train: loss=0.655, acc= 77.7% | time=987.6ms | Valid: loss=1.000, acc= 66.8% |\n",
            "Epoch  21 | Train: loss=0.647, acc= 77.6% | time=982.6ms | Valid: loss=1.013, acc= 66.0% |\n",
            "Epoch  22 | Train: loss=0.597, acc= 80.0% | time=984.4ms | Valid: loss=0.940, acc= 69.6% | *\n",
            "Epoch  23 | Train: loss=0.576, acc= 80.1% | time=990.7ms | Valid: loss=1.055, acc= 66.0% |\n",
            "Epoch  24 | Train: loss=0.563, acc= 80.6% | time=991.1ms | Valid: loss=1.004, acc= 68.4% |\n",
            "Epoch  25 | Train: loss=0.531, acc= 82.1% | time=997.7ms | Valid: loss=0.961, acc= 72.0% |\n",
            "Epoch  26 | Train: loss=0.526, acc= 82.2% | time=993.5ms | Valid: loss=1.014, acc= 70.0% |\n",
            "Epoch  27 | Train: loss=0.537, acc= 81.8% | time=994.9ms | Valid: loss=1.017, acc= 68.4% |\n",
            "Epoch  28 | Train: loss=0.485, acc= 83.5% | time=996.6ms | Valid: loss=0.993, acc= 69.6% | lr=5.0e-03\n",
            "Epoch  29 | Train: loss=0.465, acc= 84.5% | time=996.6ms | Valid: loss=1.002, acc= 72.4% |\n",
            "Epoch  30 | Train: loss=0.465, acc= 84.5% | time=999.6ms | Valid: loss=0.970, acc= 70.4% |\n",
            "Epoch  31 | Train: loss=0.459, acc= 84.3% | time=999.7ms | Valid: loss=0.990, acc= 70.0% |\n",
            "Epoch  32 | Train: loss=0.462, acc= 84.4% | time=1000.6ms | Valid: loss=0.990, acc= 69.2% |\n",
            "Epoch  33 | Train: loss=0.444, acc= 84.5% | time=1000.1ms | Valid: loss=0.969, acc= 72.4% |\n",
            "Epoch  34 | Train: loss=0.434, acc= 85.4% | time=999.9ms | Valid: loss=1.022, acc= 70.0% | lr=2.5e-03\n",
            "Epoch  35 | Train: loss=0.426, acc= 85.5% | time=1004.1ms | Valid: loss=0.959, acc= 70.8% |\n",
            "Epoch  36 | Train: loss=0.427, acc= 85.7% | time=1002.0ms | Valid: loss=0.991, acc= 71.2% |\n",
            "Epoch  37 | Train: loss=0.419, acc= 86.0% | time=1000.2ms | Valid: loss=0.957, acc= 70.4% |\n",
            "Epoch  38 | Train: loss=0.421, acc= 85.5% | time=1002.0ms | Valid: loss=0.946, acc= 69.6% |\n",
            "Epoch  39 | Train: loss=0.410, acc= 86.1% | time=1001.1ms | Valid: loss=0.986, acc= 70.8% |\n",
            "Epoch  40 | Train: loss=0.412, acc= 86.4% | time=1002.6ms | Valid: loss=1.010, acc= 71.6% | lr=1.3e-03\n",
            "Epoch  41 | Train: loss=0.401, acc= 86.8% | time=996.4ms | Valid: loss=0.968, acc= 71.2% |\n",
            "Epoch  42 | Train: loss=0.413, acc= 86.4% | time=998.2ms | Valid: loss=1.036, acc= 70.0% |\n",
            "Epoch  43 | Train: loss=0.400, acc= 86.6% | time=999.4ms | Valid: loss=0.975, acc= 70.0% |\n",
            "Epoch  44 | Train: loss=0.404, acc= 86.7% | time=999.2ms | Valid: loss=0.943, acc= 72.0% |\n",
            "Epoch  45 | Train: loss=0.404, acc= 86.8% | time=994.4ms | Valid: loss=0.959, acc= 69.6% |\n",
            "Epoch  46 | Train: loss=0.391, acc= 86.6% | time=991.3ms | Valid: loss=0.973, acc= 71.6% | lr=6.3e-04\n",
            "Epoch  47 | Train: loss=0.394, acc= 87.2% | time=999.0ms | Valid: loss=0.976, acc= 70.0% |\n",
            "Epoch  48 | Train: loss=0.393, acc= 86.8% | time=992.3ms | Valid: loss=0.927, acc= 72.0% | *\n",
            "Epoch  49 | Train: loss=0.397, acc= 86.5% | time=997.9ms | Valid: loss=0.995, acc= 68.4% |\n",
            "Epoch  50 | Train: loss=0.398, acc= 87.0% | time=990.6ms | Valid: loss=0.962, acc= 69.6% |\n",
            "Epoch  51 | Train: loss=0.393, acc= 87.1% | time=997.3ms | Valid: loss=0.972, acc= 69.2% |\n",
            "Epoch  52 | Train: loss=0.395, acc= 86.8% | time=994.9ms | Valid: loss=0.994, acc= 71.2% |\n",
            "Epoch  53 | Train: loss=0.398, acc= 86.5% | time=995.1ms | Valid: loss=0.970, acc= 70.4% |\n",
            "Epoch  54 | Train: loss=0.398, acc= 86.5% | time=1001.3ms | Valid: loss=0.962, acc= 73.6% | lr=3.1e-04\n",
            "Epoch  55 | Train: loss=0.394, acc= 87.1% | time=993.8ms | Valid: loss=0.990, acc= 71.2% |\n",
            "Epoch  56 | Train: loss=0.377, acc= 86.8% | time=992.9ms | Valid: loss=0.956, acc= 73.6% |\n",
            "Epoch  57 | Train: loss=0.386, acc= 87.1% | time=992.1ms | Valid: loss=0.938, acc= 73.6% |\n",
            "Epoch  58 | Train: loss=0.384, acc= 87.1% | time=997.3ms | Valid: loss=0.986, acc= 71.2% |\n",
            "Epoch  59 | Train: loss=0.390, acc= 86.6% | time=988.4ms | Valid: loss=0.996, acc= 72.0% |\n",
            "Epoch  60 | Train: loss=0.387, acc= 87.3% | time=996.7ms | Valid: loss=1.000, acc= 68.8% | lr=1.6e-04\n",
            "Epoch  61 | Train: loss=0.379, acc= 87.8% | time=998.1ms | Valid: loss=0.960, acc= 71.2% |\n",
            "Epoch  62 | Train: loss=0.383, acc= 87.2% | time=988.5ms | Valid: loss=0.988, acc= 70.4% |\n",
            "Epoch  63 | Train: loss=0.383, acc= 87.3% | time=994.2ms | Valid: loss=0.963, acc= 72.0% |\n",
            "Epoch  64 | Train: loss=0.388, acc= 86.7% | time=997.8ms | Valid: loss=0.969, acc= 71.6% |\n",
            "Epoch  65 | Train: loss=0.383, acc= 87.6% | time=999.3ms | Valid: loss=0.959, acc= 71.2% |\n",
            "Epoch  66 | Train: loss=0.388, acc= 87.6% | time=994.8ms | Valid: loss=0.931, acc= 72.8% | lr=7.8e-05\n",
            "Epoch  67 | Train: loss=0.384, acc= 87.2% | time=995.3ms | Valid: loss=0.931, acc= 74.0% |\n",
            "Epoch  68 | Train: loss=0.385, acc= 87.3% | time=994.0ms | Valid: loss=0.972, acc= 71.2% |\n",
            "Epoch  69 | Train: loss=0.386, acc= 87.1% | time=1000.4ms | Valid: loss=1.014, acc= 69.2% |\n",
            "Epoch  70 | Train: loss=0.383, acc= 87.3% | time=994.7ms | Valid: loss=1.010, acc= 69.6% |\n",
            "Epoch  71 | Train: loss=0.386, acc= 86.8% | time=999.1ms | Valid: loss=0.966, acc= 70.0% |\n",
            "Epoch  72 | Train: loss=0.378, acc= 86.9% | time=1000.4ms | Valid: loss=0.949, acc= 69.2% | lr=3.9e-05\n",
            "Epoch  73 | Train: loss=0.377, acc= 87.5% | time=997.2ms | Valid: loss=0.945, acc= 71.6% |\n",
            "Epoch  74 | Train: loss=0.387, acc= 86.8% | time=1001.6ms | Valid: loss=1.002, acc= 72.0% |\n",
            "Epoch  75 | Train: loss=0.386, acc= 87.2% | time=1005.1ms | Valid: loss=0.964, acc= 70.8% |\n",
            "Epoch  76 | Train: loss=0.385, acc= 87.2% | time=1004.3ms | Valid: loss=0.960, acc= 70.0% |\n",
            "Epoch  77 | Train: loss=0.382, acc= 87.1% | time=1002.7ms | Valid: loss=0.953, acc= 71.2% |\n",
            "Epoch  78 | Train: loss=0.386, acc= 87.2% | time=1004.9ms | Valid: loss=1.019, acc= 70.0% | lr=2.0e-05\n",
            "Epoch  79 | Train: loss=0.376, acc= 87.2% | time=1005.4ms | Valid: loss=0.969, acc= 70.8% |\n",
            "Epoch  80 | Train: loss=0.384, acc= 87.1% | time=1008.2ms | Valid: loss=0.980, acc= 72.8% |\n",
            "Epoch  81 | Train: loss=0.381, acc= 87.6% | time=1005.7ms | Valid: loss=0.969, acc= 72.0% |\n",
            "Epoch  82 | Train: loss=0.380, acc= 87.2% | time=1005.6ms | Valid: loss=0.933, acc= 72.8% |\n",
            "Epoch  83 | Train: loss=0.378, acc= 87.7% | time=1008.8ms | Valid: loss=0.993, acc= 71.6% |\n",
            "Epoch  84 | Train: loss=0.376, acc= 87.6% | time=1011.1ms | Valid: loss=0.951, acc= 70.4% | lr=9.8e-06\n",
            "Test: loss=0.995 , acc= 70.0%\n",
            "------------------------------\n",
            "Representation Matrix\n",
            "------------------------------\n",
            "Layer 1 : (48, 20184)\n",
            "Layer 2 : (576, 14400)\n",
            "Layer 3 : (512, 2500)\n",
            "Layer 4 : (1024, 125)\n",
            "Layer 5 : (2048, 125)\n",
            "------------------------------\n",
            "Threshold:  [0.973 0.973 0.973 0.973 0.973]\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 10/48\n",
            "Layer 2 : 178/576\n",
            "Layer 3 : 274/512\n",
            "Layer 4 : 158/1024\n",
            "Layer 5 : 196/2048\n",
            "----------------------------------------\n",
            "Accuracies =\n",
            "\t 78.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 77.6%  68.1%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "****************************************************************************************************\n",
            "Task  2 (cifar100-2)\n",
            "****************************************************************************************************\n",
            "----------------------------------------\n",
            "Task ID :2 | Learning Rate : 0.01\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([48, 48])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([576, 576])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([512, 512])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([1024, 1024])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([2048, 2048])\n",
            "----------------------------------------\n",
            "Epoch   1 | Train: loss=1.278, acc= 57.7% | time=1048.0ms | Valid: loss=1.330, acc= 56.8% | *\n",
            "Epoch   2 | Train: loss=1.145, acc= 61.9% | time=1003.5ms | Valid: loss=1.222, acc= 58.0% | *\n",
            "Epoch   3 | Train: loss=1.039, acc= 65.1% | time=994.6ms | Valid: loss=1.141, acc= 62.0% | *\n",
            "Epoch   4 | Train: loss=1.000, acc= 66.6% | time=1004.2ms | Valid: loss=1.128, acc= 65.2% | *\n",
            "Epoch   5 | Train: loss=0.940, acc= 68.5% | time=1002.1ms | Valid: loss=1.117, acc= 65.2% | *\n",
            "Epoch   6 | Train: loss=0.964, acc= 67.9% | time=1001.6ms | Valid: loss=1.121, acc= 60.8% |\n",
            "Epoch   7 | Train: loss=0.896, acc= 69.7% | time=1001.1ms | Valid: loss=1.055, acc= 65.6% | *\n",
            "Epoch   8 | Train: loss=0.859, acc= 71.2% | time=1001.7ms | Valid: loss=1.063, acc= 65.2% |\n",
            "Epoch   9 | Train: loss=0.842, acc= 71.8% | time=1001.6ms | Valid: loss=1.059, acc= 66.0% |\n",
            "Epoch  10 | Train: loss=0.805, acc= 73.4% | time=1002.4ms | Valid: loss=1.014, acc= 71.6% | *\n",
            "Epoch  11 | Train: loss=0.767, acc= 74.7% | time=999.0ms | Valid: loss=1.015, acc= 66.8% |\n",
            "Epoch  12 | Train: loss=0.754, acc= 74.7% | time=1000.9ms | Valid: loss=0.966, acc= 70.4% | *\n",
            "Epoch  13 | Train: loss=0.741, acc= 75.3% | time=1003.6ms | Valid: loss=0.993, acc= 69.6% |\n",
            "Epoch  14 | Train: loss=0.725, acc= 75.9% | time=996.2ms | Valid: loss=1.003, acc= 70.8% |\n",
            "Epoch  15 | Train: loss=0.706, acc= 76.0% | time=999.4ms | Valid: loss=1.038, acc= 71.2% |\n",
            "Epoch  16 | Train: loss=0.654, acc= 77.6% | time=1000.4ms | Valid: loss=1.019, acc= 70.0% |\n",
            "Epoch  17 | Train: loss=0.652, acc= 78.0% | time=1002.9ms | Valid: loss=0.991, acc= 72.8% |\n",
            "Epoch  18 | Train: loss=0.618, acc= 79.3% | time=997.1ms | Valid: loss=0.980, acc= 70.8% | lr=5.0e-03\n",
            "Epoch  19 | Train: loss=0.613, acc= 79.6% | time=999.8ms | Valid: loss=0.989, acc= 69.6% |\n",
            "Epoch  20 | Train: loss=0.602, acc= 79.8% | time=998.7ms | Valid: loss=1.053, acc= 72.0% |\n",
            "Epoch  21 | Train: loss=0.600, acc= 79.5% | time=996.7ms | Valid: loss=0.963, acc= 71.2% | *\n",
            "Epoch  22 | Train: loss=0.585, acc= 80.3% | time=999.0ms | Valid: loss=0.963, acc= 72.0% |\n",
            "Epoch  23 | Train: loss=0.574, acc= 80.5% | time=1001.9ms | Valid: loss=1.002, acc= 70.8% |\n",
            "Epoch  24 | Train: loss=0.572, acc= 80.9% | time=1001.3ms | Valid: loss=0.966, acc= 70.4% |\n",
            "Epoch  25 | Train: loss=0.558, acc= 81.2% | time=1001.3ms | Valid: loss=0.997, acc= 70.0% |\n",
            "Epoch  26 | Train: loss=0.547, acc= 81.8% | time=1005.6ms | Valid: loss=0.977, acc= 69.6% |\n",
            "Epoch  27 | Train: loss=0.533, acc= 81.9% | time=1003.8ms | Valid: loss=0.936, acc= 72.8% | *\n",
            "Epoch  28 | Train: loss=0.541, acc= 82.0% | time=1006.8ms | Valid: loss=0.973, acc= 72.0% |\n",
            "Epoch  29 | Train: loss=0.529, acc= 82.6% | time=1007.0ms | Valid: loss=0.926, acc= 71.2% | *\n",
            "Epoch  30 | Train: loss=0.507, acc= 83.2% | time=1007.7ms | Valid: loss=0.978, acc= 72.0% |\n",
            "Epoch  31 | Train: loss=0.509, acc= 82.5% | time=1006.5ms | Valid: loss=0.975, acc= 71.6% |\n",
            "Epoch  32 | Train: loss=0.501, acc= 83.4% | time=1006.8ms | Valid: loss=0.962, acc= 70.4% |\n",
            "Epoch  33 | Train: loss=0.495, acc= 83.6% | time=1013.8ms | Valid: loss=0.978, acc= 70.0% |\n",
            "Epoch  34 | Train: loss=0.496, acc= 83.5% | time=1009.0ms | Valid: loss=0.984, acc= 71.2% |\n",
            "Epoch  35 | Train: loss=0.481, acc= 84.0% | time=1012.1ms | Valid: loss=0.973, acc= 73.2% | lr=2.5e-03\n",
            "Epoch  36 | Train: loss=0.489, acc= 83.6% | time=1008.6ms | Valid: loss=0.960, acc= 72.8% |\n",
            "Epoch  37 | Train: loss=0.479, acc= 84.1% | time=1011.5ms | Valid: loss=0.954, acc= 72.8% |\n",
            "Epoch  38 | Train: loss=0.484, acc= 83.8% | time=1010.5ms | Valid: loss=0.962, acc= 71.6% |\n",
            "Epoch  39 | Train: loss=0.472, acc= 84.1% | time=1016.0ms | Valid: loss=0.982, acc= 73.2% |\n",
            "Epoch  40 | Train: loss=0.470, acc= 84.5% | time=1009.4ms | Valid: loss=0.947, acc= 70.8% |\n",
            "Epoch  41 | Train: loss=0.463, acc= 84.0% | time=1015.1ms | Valid: loss=0.964, acc= 70.0% | lr=1.3e-03\n",
            "Epoch  42 | Train: loss=0.461, acc= 84.6% | time=1009.3ms | Valid: loss=0.939, acc= 71.6% |\n",
            "Epoch  43 | Train: loss=0.460, acc= 84.4% | time=1013.1ms | Valid: loss=0.943, acc= 72.0% |\n",
            "Epoch  44 | Train: loss=0.465, acc= 84.8% | time=1009.7ms | Valid: loss=0.978, acc= 71.2% |\n",
            "Epoch  45 | Train: loss=0.457, acc= 84.4% | time=1016.9ms | Valid: loss=0.935, acc= 70.4% |\n",
            "Epoch  46 | Train: loss=0.465, acc= 84.2% | time=1014.2ms | Valid: loss=0.994, acc= 70.8% |\n",
            "Epoch  47 | Train: loss=0.449, acc= 85.1% | time=1012.0ms | Valid: loss=0.946, acc= 73.2% | lr=6.3e-04\n",
            "Epoch  48 | Train: loss=0.455, acc= 84.9% | time=1012.9ms | Valid: loss=0.992, acc= 68.4% |\n",
            "Epoch  49 | Train: loss=0.458, acc= 84.7% | time=1009.0ms | Valid: loss=0.980, acc= 70.4% |\n",
            "Epoch  50 | Train: loss=0.453, acc= 84.8% | time=1013.8ms | Valid: loss=0.960, acc= 73.2% |\n",
            "Epoch  51 | Train: loss=0.456, acc= 84.6% | time=1006.2ms | Valid: loss=0.939, acc= 72.8% |\n",
            "Epoch  52 | Train: loss=0.452, acc= 84.9% | time=1003.5ms | Valid: loss=0.904, acc= 72.8% | *\n",
            "Epoch  53 | Train: loss=0.448, acc= 84.7% | time=1009.8ms | Valid: loss=0.932, acc= 72.0% |\n",
            "Epoch  54 | Train: loss=0.450, acc= 85.2% | time=1010.7ms | Valid: loss=0.938, acc= 72.4% |\n",
            "Epoch  55 | Train: loss=0.447, acc= 84.9% | time=1004.4ms | Valid: loss=0.944, acc= 71.6% |\n",
            "Epoch  56 | Train: loss=0.441, acc= 85.2% | time=1002.4ms | Valid: loss=0.958, acc= 73.2% |\n",
            "Epoch  57 | Train: loss=0.445, acc= 85.0% | time=1005.3ms | Valid: loss=0.923, acc= 73.2% |\n",
            "Epoch  58 | Train: loss=0.453, acc= 85.1% | time=1007.4ms | Valid: loss=0.943, acc= 74.4% | lr=3.1e-04\n",
            "Epoch  59 | Train: loss=0.448, acc= 84.7% | time=1004.8ms | Valid: loss=0.922, acc= 73.2% |\n",
            "Epoch  60 | Train: loss=0.446, acc= 85.2% | time=1004.4ms | Valid: loss=0.952, acc= 71.6% |\n",
            "Epoch  61 | Train: loss=0.447, acc= 85.0% | time=1015.4ms | Valid: loss=0.965, acc= 70.8% |\n",
            "Epoch  62 | Train: loss=0.444, acc= 84.9% | time=1007.2ms | Valid: loss=0.949, acc= 71.6% |\n",
            "Epoch  63 | Train: loss=0.449, acc= 85.1% | time=1002.3ms | Valid: loss=0.960, acc= 70.4% |\n",
            "Epoch  64 | Train: loss=0.448, acc= 84.9% | time=1007.2ms | Valid: loss=0.960, acc= 70.8% | lr=1.6e-04\n",
            "Epoch  65 | Train: loss=0.443, acc= 85.2% | time=1003.4ms | Valid: loss=0.941, acc= 74.0% |\n",
            "Epoch  66 | Train: loss=0.444, acc= 85.0% | time=1009.2ms | Valid: loss=0.943, acc= 71.6% |\n",
            "Epoch  67 | Train: loss=0.451, acc= 84.4% | time=1002.4ms | Valid: loss=0.961, acc= 72.4% |\n",
            "Epoch  68 | Train: loss=0.435, acc= 85.8% | time=1006.6ms | Valid: loss=0.934, acc= 71.2% |\n",
            "Epoch  69 | Train: loss=0.443, acc= 85.0% | time=1009.9ms | Valid: loss=0.938, acc= 72.8% |\n",
            "Epoch  70 | Train: loss=0.447, acc= 84.9% | time=1006.6ms | Valid: loss=0.921, acc= 73.6% | lr=7.8e-05\n",
            "Epoch  71 | Train: loss=0.436, acc= 86.3% | time=1005.4ms | Valid: loss=0.942, acc= 71.6% |\n",
            "Epoch  72 | Train: loss=0.447, acc= 85.0% | time=1004.0ms | Valid: loss=0.946, acc= 71.6% |\n",
            "Epoch  73 | Train: loss=0.435, acc= 85.3% | time=1004.7ms | Valid: loss=0.958, acc= 72.8% |\n",
            "Epoch  74 | Train: loss=0.444, acc= 85.4% | time=1002.9ms | Valid: loss=0.894, acc= 74.0% | *\n",
            "Epoch  75 | Train: loss=0.445, acc= 85.0% | time=1003.2ms | Valid: loss=0.981, acc= 71.6% |\n",
            "Epoch  76 | Train: loss=0.445, acc= 85.2% | time=1003.5ms | Valid: loss=0.967, acc= 72.0% |\n",
            "Epoch  77 | Train: loss=0.439, acc= 85.2% | time=1009.2ms | Valid: loss=0.964, acc= 72.4% |\n",
            "Epoch  78 | Train: loss=0.444, acc= 85.1% | time=1001.2ms | Valid: loss=0.967, acc= 72.4% |\n",
            "Epoch  79 | Train: loss=0.433, acc= 85.8% | time=1009.3ms | Valid: loss=0.966, acc= 72.4% |\n",
            "Epoch  80 | Train: loss=0.440, acc= 85.2% | time=1006.0ms | Valid: loss=0.923, acc= 72.8% | lr=3.9e-05\n",
            "Epoch  81 | Train: loss=0.442, acc= 85.3% | time=1009.0ms | Valid: loss=0.937, acc= 71.6% |\n",
            "Epoch  82 | Train: loss=0.450, acc= 85.1% | time=1004.5ms | Valid: loss=0.943, acc= 72.8% |\n",
            "Epoch  83 | Train: loss=0.434, acc= 85.1% | time=1008.6ms | Valid: loss=0.952, acc= 72.0% |\n",
            "Epoch  84 | Train: loss=0.447, acc= 84.9% | time=1001.3ms | Valid: loss=0.947, acc= 71.6% |\n",
            "Epoch  85 | Train: loss=0.440, acc= 85.6% | time=1002.3ms | Valid: loss=0.933, acc= 73.2% |\n",
            "Epoch  86 | Train: loss=0.440, acc= 85.6% | time=1003.0ms | Valid: loss=0.937, acc= 71.6% | lr=2.0e-05\n",
            "Epoch  87 | Train: loss=0.442, acc= 85.5% | time=1004.2ms | Valid: loss=0.972, acc= 70.8% |\n",
            "Epoch  88 | Train: loss=0.436, acc= 85.5% | time=1007.3ms | Valid: loss=0.927, acc= 72.8% |\n",
            "Epoch  89 | Train: loss=0.444, acc= 84.9% | time=1003.6ms | Valid: loss=0.932, acc= 71.6% |\n",
            "Epoch  90 | Train: loss=0.435, acc= 85.5% | time=1002.3ms | Valid: loss=0.950, acc= 72.4% |\n",
            "Epoch  91 | Train: loss=0.439, acc= 85.4% | time=1005.2ms | Valid: loss=0.969, acc= 70.8% |\n",
            "Epoch  92 | Train: loss=0.440, acc= 85.0% | time=1008.8ms | Valid: loss=0.984, acc= 71.6% | lr=9.8e-06\n",
            "Test: loss=0.914 , acc= 72.5%\n",
            "------------------------------\n",
            "Representation Matrix\n",
            "------------------------------\n",
            "Layer 1 : (48, 20184)\n",
            "Layer 2 : (576, 14400)\n",
            "Layer 3 : (512, 2500)\n",
            "Layer 4 : (1024, 125)\n",
            "Layer 5 : (2048, 125)\n",
            "------------------------------\n",
            "Threshold:  [0.976 0.976 0.976 0.976 0.976]\n",
            "Skip Updating GPM for layer: 1\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 10/48\n",
            "Layer 2 : 196/576\n",
            "Layer 3 : 304/512\n",
            "Layer 4 : 230/1024\n",
            "Layer 5 : 291/2048\n",
            "----------------------------------------\n",
            "Accuracies =\n",
            "\t 78.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 77.6%  68.1%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 77.3%  68.8%  71.9%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "****************************************************************************************************\n",
            "Task  3 (cifar100-3)\n",
            "****************************************************************************************************\n",
            "----------------------------------------\n",
            "Task ID :3 | Learning Rate : 0.01\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([48, 48])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([576, 576])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([512, 512])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([1024, 1024])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([2048, 2048])\n",
            "----------------------------------------\n",
            "Epoch   1 | Train: loss=1.356, acc= 54.3% | time=1027.7ms | Valid: loss=1.408, acc= 49.2% | *\n",
            "Epoch   2 | Train: loss=1.234, acc= 57.8% | time=995.7ms | Valid: loss=1.288, acc= 54.4% | *\n",
            "Epoch   3 | Train: loss=1.153, acc= 61.1% | time=999.7ms | Valid: loss=1.207, acc= 57.2% | *\n",
            "Epoch   4 | Train: loss=1.083, acc= 63.4% | time=998.9ms | Valid: loss=1.165, acc= 58.0% | *\n",
            "Epoch   5 | Train: loss=1.052, acc= 64.8% | time=996.3ms | Valid: loss=1.148, acc= 59.6% | *\n",
            "Epoch   6 | Train: loss=1.008, acc= 66.0% | time=1002.4ms | Valid: loss=1.115, acc= 62.4% | *\n",
            "Epoch   7 | Train: loss=0.980, acc= 67.2% | time=1004.8ms | Valid: loss=1.121, acc= 61.2% |\n",
            "Epoch   8 | Train: loss=0.944, acc= 68.7% | time=1006.4ms | Valid: loss=1.119, acc= 62.8% |\n",
            "Epoch   9 | Train: loss=0.958, acc= 67.9% | time=1004.5ms | Valid: loss=1.147, acc= 61.2% |\n",
            "Epoch  10 | Train: loss=0.873, acc= 70.5% | time=1003.0ms | Valid: loss=1.033, acc= 64.0% | *\n",
            "Epoch  11 | Train: loss=0.908, acc= 69.7% | time=1003.6ms | Valid: loss=1.072, acc= 62.4% |\n",
            "Epoch  12 | Train: loss=0.852, acc= 71.6% | time=1012.2ms | Valid: loss=1.039, acc= 63.6% |\n",
            "Epoch  13 | Train: loss=0.824, acc= 72.2% | time=1008.7ms | Valid: loss=1.054, acc= 65.6% |\n",
            "Epoch  14 | Train: loss=0.823, acc= 73.0% | time=1012.2ms | Valid: loss=1.024, acc= 65.2% | *\n",
            "Epoch  15 | Train: loss=0.795, acc= 74.2% | time=1016.0ms | Valid: loss=1.034, acc= 64.4% |\n",
            "Epoch  16 | Train: loss=0.756, acc= 74.5% | time=1014.4ms | Valid: loss=1.019, acc= 65.6% | *\n",
            "Epoch  17 | Train: loss=0.754, acc= 74.8% | time=1012.1ms | Valid: loss=0.973, acc= 66.0% | *\n",
            "Epoch  18 | Train: loss=0.729, acc= 76.2% | time=1017.3ms | Valid: loss=0.995, acc= 63.2% |\n",
            "Epoch  19 | Train: loss=0.742, acc= 75.4% | time=1024.7ms | Valid: loss=1.045, acc= 66.0% |\n",
            "Epoch  20 | Train: loss=0.707, acc= 76.2% | time=1020.6ms | Valid: loss=0.969, acc= 65.6% | *\n",
            "Epoch  21 | Train: loss=0.659, acc= 78.0% | time=1022.3ms | Valid: loss=0.958, acc= 67.2% | *\n",
            "Epoch  22 | Train: loss=0.654, acc= 78.4% | time=1024.6ms | Valid: loss=0.933, acc= 68.4% | *\n",
            "Epoch  23 | Train: loss=0.646, acc= 78.5% | time=1023.2ms | Valid: loss=0.959, acc= 66.8% |\n",
            "Epoch  24 | Train: loss=0.633, acc= 79.3% | time=1020.7ms | Valid: loss=0.970, acc= 70.0% |\n",
            "Epoch  25 | Train: loss=0.622, acc= 79.1% | time=1021.7ms | Valid: loss=0.931, acc= 68.8% | *\n",
            "Epoch  26 | Train: loss=0.609, acc= 80.1% | time=1024.2ms | Valid: loss=0.988, acc= 67.2% |\n",
            "Epoch  27 | Train: loss=0.580, acc= 80.5% | time=1023.7ms | Valid: loss=0.943, acc= 69.6% |\n",
            "Epoch  28 | Train: loss=0.568, acc= 81.4% | time=1019.8ms | Valid: loss=0.924, acc= 67.6% | *\n",
            "Epoch  29 | Train: loss=0.572, acc= 80.7% | time=1015.4ms | Valid: loss=0.952, acc= 68.0% |\n",
            "Epoch  30 | Train: loss=0.562, acc= 80.9% | time=1011.8ms | Valid: loss=0.966, acc= 68.0% |\n",
            "Epoch  31 | Train: loss=0.531, acc= 82.8% | time=1015.3ms | Valid: loss=0.898, acc= 69.2% | *\n",
            "Epoch  32 | Train: loss=0.522, acc= 82.6% | time=1013.0ms | Valid: loss=0.920, acc= 67.6% |\n",
            "Epoch  33 | Train: loss=0.524, acc= 82.8% | time=1013.3ms | Valid: loss=0.924, acc= 70.8% |\n",
            "Epoch  34 | Train: loss=0.493, acc= 83.6% | time=1005.1ms | Valid: loss=0.915, acc= 69.6% |\n",
            "Epoch  35 | Train: loss=0.482, acc= 84.1% | time=1011.8ms | Valid: loss=0.908, acc= 71.2% |\n",
            "Epoch  36 | Train: loss=0.476, acc= 84.7% | time=1008.8ms | Valid: loss=0.896, acc= 72.0% | *\n",
            "Epoch  37 | Train: loss=0.449, acc= 85.0% | time=1009.0ms | Valid: loss=0.888, acc= 70.4% | *\n",
            "Epoch  38 | Train: loss=0.471, acc= 84.9% | time=1009.8ms | Valid: loss=0.921, acc= 68.8% |\n",
            "Epoch  39 | Train: loss=0.437, acc= 85.5% | time=1006.0ms | Valid: loss=0.940, acc= 69.6% |\n",
            "Epoch  40 | Train: loss=0.430, acc= 85.9% | time=1007.7ms | Valid: loss=0.929, acc= 70.0% |\n",
            "Epoch  41 | Train: loss=0.412, acc= 86.3% | time=1009.9ms | Valid: loss=0.917, acc= 69.6% |\n",
            "Epoch  42 | Train: loss=0.405, acc= 86.6% | time=1008.4ms | Valid: loss=0.897, acc= 72.0% |\n",
            "Epoch  43 | Train: loss=0.400, acc= 86.7% | time=1009.0ms | Valid: loss=0.944, acc= 68.0% | lr=5.0e-03\n",
            "Epoch  44 | Train: loss=0.395, acc= 86.9% | time=1005.5ms | Valid: loss=0.939, acc= 71.2% |\n",
            "Epoch  45 | Train: loss=0.388, acc= 87.2% | time=1009.5ms | Valid: loss=0.953, acc= 69.2% |\n",
            "Epoch  46 | Train: loss=0.367, acc= 88.0% | time=1014.6ms | Valid: loss=0.889, acc= 73.2% |\n",
            "Epoch  47 | Train: loss=0.378, acc= 87.7% | time=1004.8ms | Valid: loss=0.875, acc= 70.4% | *\n",
            "Epoch  48 | Train: loss=0.372, acc= 87.5% | time=1004.6ms | Valid: loss=0.871, acc= 72.8% | *\n",
            "Epoch  49 | Train: loss=0.368, acc= 87.5% | time=1011.9ms | Valid: loss=0.927, acc= 69.6% |\n",
            "Epoch  50 | Train: loss=0.374, acc= 87.6% | time=1005.8ms | Valid: loss=0.904, acc= 72.0% |\n",
            "Epoch  51 | Train: loss=0.349, acc= 88.5% | time=1009.9ms | Valid: loss=0.864, acc= 72.4% | *\n",
            "Epoch  52 | Train: loss=0.356, acc= 88.3% | time=1004.3ms | Valid: loss=0.925, acc= 72.0% |\n",
            "Epoch  53 | Train: loss=0.354, acc= 88.1% | time=1007.8ms | Valid: loss=0.923, acc= 71.6% |\n",
            "Epoch  54 | Train: loss=0.343, acc= 88.6% | time=1000.5ms | Valid: loss=0.881, acc= 71.6% |\n",
            "Epoch  55 | Train: loss=0.324, acc= 89.5% | time=999.7ms | Valid: loss=0.938, acc= 71.2% |\n",
            "Epoch  56 | Train: loss=0.338, acc= 88.7% | time=1004.0ms | Valid: loss=0.888, acc= 69.6% |\n",
            "Epoch  57 | Train: loss=0.332, acc= 88.9% | time=1007.7ms | Valid: loss=0.946, acc= 72.4% | lr=2.5e-03\n",
            "Epoch  58 | Train: loss=0.321, acc= 89.8% | time=1008.0ms | Valid: loss=0.885, acc= 70.8% |\n",
            "Epoch  59 | Train: loss=0.321, acc= 89.5% | time=1004.2ms | Valid: loss=0.924, acc= 70.0% |\n",
            "Epoch  60 | Train: loss=0.318, acc= 89.3% | time=1007.2ms | Valid: loss=0.916, acc= 69.6% |\n",
            "Epoch  61 | Train: loss=0.319, acc= 89.3% | time=1003.3ms | Valid: loss=0.883, acc= 71.6% |\n",
            "Epoch  62 | Train: loss=0.321, acc= 89.6% | time=1004.4ms | Valid: loss=0.894, acc= 70.4% |\n",
            "Epoch  63 | Train: loss=0.312, acc= 90.0% | time=1002.2ms | Valid: loss=0.918, acc= 71.2% | lr=1.3e-03\n",
            "Epoch  64 | Train: loss=0.325, acc= 89.3% | time=1002.8ms | Valid: loss=0.904, acc= 70.4% |\n",
            "Epoch  65 | Train: loss=0.310, acc= 89.9% | time=1008.4ms | Valid: loss=0.927, acc= 69.2% |\n",
            "Epoch  66 | Train: loss=0.309, acc= 89.9% | time=1008.8ms | Valid: loss=0.843, acc= 74.4% | *\n",
            "Epoch  67 | Train: loss=0.309, acc= 90.2% | time=1004.5ms | Valid: loss=0.886, acc= 72.4% |\n",
            "Epoch  68 | Train: loss=0.312, acc= 89.9% | time=1002.2ms | Valid: loss=0.987, acc= 69.6% |\n",
            "Epoch  69 | Train: loss=0.307, acc= 89.9% | time=1003.2ms | Valid: loss=0.859, acc= 72.0% |\n",
            "Epoch  70 | Train: loss=0.307, acc= 90.5% | time=1007.6ms | Valid: loss=0.881, acc= 71.6% |\n",
            "Epoch  71 | Train: loss=0.303, acc= 90.4% | time=1004.2ms | Valid: loss=0.889, acc= 72.4% |\n",
            "Epoch  72 | Train: loss=0.316, acc= 89.8% | time=1007.9ms | Valid: loss=0.950, acc= 70.8% | lr=6.3e-04\n",
            "Epoch  73 | Train: loss=0.306, acc= 89.9% | time=1008.6ms | Valid: loss=0.886, acc= 71.2% |\n",
            "Epoch  74 | Train: loss=0.305, acc= 90.0% | time=1002.7ms | Valid: loss=0.914, acc= 69.6% |\n",
            "Epoch  75 | Train: loss=0.303, acc= 89.8% | time=1004.9ms | Valid: loss=0.872, acc= 73.2% |\n",
            "Epoch  76 | Train: loss=0.301, acc= 90.3% | time=1003.5ms | Valid: loss=0.901, acc= 71.6% |\n",
            "Epoch  77 | Train: loss=0.309, acc= 90.0% | time=1005.2ms | Valid: loss=0.947, acc= 69.6% |\n",
            "Epoch  78 | Train: loss=0.307, acc= 89.9% | time=1008.7ms | Valid: loss=0.897, acc= 72.0% | lr=3.1e-04\n",
            "Epoch  79 | Train: loss=0.292, acc= 90.3% | time=1013.7ms | Valid: loss=0.889, acc= 72.0% |\n",
            "Epoch  80 | Train: loss=0.299, acc= 90.2% | time=1016.1ms | Valid: loss=0.935, acc= 70.0% |\n",
            "Epoch  81 | Train: loss=0.303, acc= 90.1% | time=1008.7ms | Valid: loss=0.872, acc= 72.4% |\n",
            "Epoch  82 | Train: loss=0.294, acc= 90.3% | time=1008.9ms | Valid: loss=0.875, acc= 73.2% |\n",
            "Epoch  83 | Train: loss=0.299, acc= 89.9% | time=1006.0ms | Valid: loss=0.905, acc= 72.0% |\n",
            "Epoch  84 | Train: loss=0.298, acc= 90.6% | time=1010.2ms | Valid: loss=0.886, acc= 70.0% | lr=1.6e-04\n",
            "Epoch  85 | Train: loss=0.304, acc= 90.0% | time=1006.5ms | Valid: loss=0.913, acc= 71.6% |\n",
            "Epoch  86 | Train: loss=0.308, acc= 89.9% | time=1010.1ms | Valid: loss=0.882, acc= 73.2% |\n",
            "Epoch  87 | Train: loss=0.303, acc= 90.0% | time=1006.3ms | Valid: loss=0.889, acc= 72.8% |\n",
            "Epoch  88 | Train: loss=0.299, acc= 90.2% | time=1005.8ms | Valid: loss=0.910, acc= 70.8% |\n",
            "Epoch  89 | Train: loss=0.300, acc= 90.0% | time=1011.2ms | Valid: loss=0.902, acc= 71.2% |\n",
            "Epoch  90 | Train: loss=0.297, acc= 90.1% | time=1011.6ms | Valid: loss=0.898, acc= 71.2% | lr=7.8e-05\n",
            "Epoch  91 | Train: loss=0.295, acc= 90.5% | time=1019.4ms | Valid: loss=1.006, acc= 70.4% |\n",
            "Epoch  92 | Train: loss=0.306, acc= 89.8% | time=1009.9ms | Valid: loss=0.897, acc= 70.4% |\n",
            "Epoch  93 | Train: loss=0.302, acc= 90.0% | time=1008.8ms | Valid: loss=0.898, acc= 70.4% |\n",
            "Epoch  94 | Train: loss=0.298, acc= 90.6% | time=1013.2ms | Valid: loss=0.874, acc= 73.2% |\n",
            "Epoch  95 | Train: loss=0.297, acc= 90.6% | time=1014.3ms | Valid: loss=0.898, acc= 72.4% |\n",
            "Epoch  96 | Train: loss=0.299, acc= 89.9% | time=1014.6ms | Valid: loss=0.875, acc= 71.6% | lr=3.9e-05\n",
            "Epoch  97 | Train: loss=0.300, acc= 90.3% | time=1010.7ms | Valid: loss=0.877, acc= 71.6% |\n",
            "Epoch  98 | Train: loss=0.299, acc= 90.3% | time=1006.1ms | Valid: loss=0.951, acc= 72.8% |\n",
            "Epoch  99 | Train: loss=0.303, acc= 89.6% | time=1008.8ms | Valid: loss=0.873, acc= 72.0% |\n",
            "Epoch 100 | Train: loss=0.300, acc= 90.2% | time=1012.1ms | Valid: loss=0.901, acc= 72.8% |\n",
            "Epoch 101 | Train: loss=0.295, acc= 90.1% | time=1009.4ms | Valid: loss=0.901, acc= 71.6% |\n",
            "Epoch 102 | Train: loss=0.297, acc= 90.1% | time=1003.0ms | Valid: loss=0.906, acc= 70.4% | lr=2.0e-05\n",
            "Epoch 103 | Train: loss=0.305, acc= 90.2% | time=1002.8ms | Valid: loss=0.837, acc= 72.8% | *\n",
            "Epoch 104 | Train: loss=0.298, acc= 90.3% | time=1011.1ms | Valid: loss=0.886, acc= 72.0% |\n",
            "Epoch 105 | Train: loss=0.302, acc= 89.9% | time=1011.5ms | Valid: loss=0.879, acc= 72.0% |\n",
            "Epoch 106 | Train: loss=0.302, acc= 90.3% | time=1007.5ms | Valid: loss=0.905, acc= 71.2% |\n",
            "Epoch 107 | Train: loss=0.301, acc= 90.1% | time=1004.2ms | Valid: loss=0.908, acc= 70.4% |\n",
            "Epoch 108 | Train: loss=0.296, acc= 90.3% | time=1009.8ms | Valid: loss=0.856, acc= 72.8% |\n",
            "Epoch 109 | Train: loss=0.303, acc= 89.7% | time=1007.9ms | Valid: loss=0.927, acc= 72.0% | lr=9.8e-06\n",
            "Test: loss=0.925 , acc= 69.9%\n",
            "------------------------------\n",
            "Representation Matrix\n",
            "------------------------------\n",
            "Layer 1 : (48, 20184)\n",
            "Layer 2 : (576, 14400)\n",
            "Layer 3 : (512, 2500)\n",
            "Layer 4 : (1024, 125)\n",
            "Layer 5 : (2048, 125)\n",
            "------------------------------\n",
            "Threshold:  [0.979 0.979 0.979 0.979 0.979]\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 11/48\n",
            "Layer 2 : 223/576\n",
            "Layer 3 : 331/512\n",
            "Layer 4 : 304/1024\n",
            "Layer 5 : 389/2048\n",
            "----------------------------------------\n",
            "Accuracies =\n",
            "\t 78.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 77.6%  68.1%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 77.3%  68.8%  71.9%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 75.8%  68.5%  72.5%  71.4%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "****************************************************************************************************\n",
            "Task  4 (cifar100-4)\n",
            "****************************************************************************************************\n",
            "----------------------------------------\n",
            "Task ID :4 | Learning Rate : 0.01\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([48, 48])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([576, 576])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([512, 512])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([1024, 1024])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([2048, 2048])\n",
            "----------------------------------------\n",
            "Epoch   1 | Train: loss=1.177, acc= 60.8% | time=1001.2ms | Valid: loss=1.286, acc= 59.2% | *\n",
            "Epoch   2 | Train: loss=1.025, acc= 65.0% | time=1000.0ms | Valid: loss=1.187, acc= 62.0% | *\n",
            "Epoch   3 | Train: loss=0.944, acc= 68.3% | time=996.6ms | Valid: loss=1.121, acc= 65.2% | *\n",
            "Epoch   4 | Train: loss=0.909, acc= 69.6% | time=1004.5ms | Valid: loss=1.090, acc= 65.6% | *\n",
            "Epoch   5 | Train: loss=0.885, acc= 71.0% | time=1004.8ms | Valid: loss=1.091, acc= 67.6% |\n",
            "Epoch   6 | Train: loss=0.848, acc= 72.3% | time=1007.0ms | Valid: loss=1.075, acc= 66.0% | *\n",
            "Epoch   7 | Train: loss=0.831, acc= 72.3% | time=1001.9ms | Valid: loss=1.055, acc= 67.2% | *\n",
            "Epoch   8 | Train: loss=0.797, acc= 73.6% | time=1002.7ms | Valid: loss=1.032, acc= 64.8% | *\n",
            "Epoch   9 | Train: loss=0.789, acc= 73.6% | time=1001.0ms | Valid: loss=1.004, acc= 68.8% | *\n",
            "Epoch  10 | Train: loss=0.785, acc= 73.8% | time=1007.8ms | Valid: loss=1.061, acc= 66.0% |\n",
            "Epoch  11 | Train: loss=0.736, acc= 75.4% | time=1009.8ms | Valid: loss=0.995, acc= 66.4% | *\n",
            "Epoch  12 | Train: loss=0.706, acc= 76.1% | time=1012.7ms | Valid: loss=0.951, acc= 66.8% | *\n",
            "Epoch  13 | Train: loss=0.694, acc= 77.0% | time=1009.2ms | Valid: loss=0.989, acc= 66.4% |\n",
            "Epoch  14 | Train: loss=0.709, acc= 75.7% | time=1008.6ms | Valid: loss=1.026, acc= 68.8% |\n",
            "Epoch  15 | Train: loss=0.654, acc= 78.0% | time=1014.5ms | Valid: loss=0.954, acc= 69.6% |\n",
            "Epoch  16 | Train: loss=0.671, acc= 77.5% | time=1014.7ms | Valid: loss=1.012, acc= 64.8% |\n",
            "Epoch  17 | Train: loss=0.634, acc= 78.1% | time=1017.2ms | Valid: loss=0.968, acc= 68.0% |\n",
            "Epoch  18 | Train: loss=0.633, acc= 78.5% | time=1019.6ms | Valid: loss=0.989, acc= 68.0% | lr=5.0e-03\n",
            "Epoch  19 | Train: loss=0.612, acc= 79.5% | time=1018.3ms | Valid: loss=0.952, acc= 67.6% |\n",
            "Epoch  20 | Train: loss=0.613, acc= 79.8% | time=1023.3ms | Valid: loss=0.985, acc= 68.8% |\n",
            "Epoch  21 | Train: loss=0.606, acc= 79.7% | time=1020.6ms | Valid: loss=0.993, acc= 68.0% |\n",
            "Epoch  22 | Train: loss=0.597, acc= 80.0% | time=1021.6ms | Valid: loss=0.972, acc= 69.6% |\n",
            "Epoch  23 | Train: loss=0.568, acc= 81.3% | time=1025.7ms | Valid: loss=0.919, acc= 69.2% | *\n",
            "Epoch  24 | Train: loss=0.585, acc= 80.5% | time=1025.1ms | Valid: loss=0.989, acc= 68.4% |\n",
            "Epoch  25 | Train: loss=0.583, acc= 80.5% | time=1018.7ms | Valid: loss=0.971, acc= 65.2% |\n",
            "Epoch  26 | Train: loss=0.564, acc= 81.4% | time=1019.6ms | Valid: loss=0.918, acc= 69.2% | *\n",
            "Epoch  27 | Train: loss=0.557, acc= 80.8% | time=1013.0ms | Valid: loss=0.945, acc= 69.2% |\n",
            "Epoch  28 | Train: loss=0.548, acc= 81.6% | time=1020.8ms | Valid: loss=0.944, acc= 71.2% |\n",
            "Epoch  29 | Train: loss=0.547, acc= 81.6% | time=1017.1ms | Valid: loss=0.958, acc= 70.0% |\n",
            "Epoch  30 | Train: loss=0.553, acc= 81.0% | time=1018.0ms | Valid: loss=0.980, acc= 68.4% |\n",
            "Epoch  31 | Train: loss=0.533, acc= 81.7% | time=1010.7ms | Valid: loss=0.941, acc= 71.2% |\n",
            "Epoch  32 | Train: loss=0.522, acc= 82.2% | time=1004.9ms | Valid: loss=0.933, acc= 69.2% | lr=2.5e-03\n",
            "Epoch  33 | Train: loss=0.526, acc= 81.9% | time=1012.7ms | Valid: loss=0.936, acc= 72.4% |\n",
            "Epoch  34 | Train: loss=0.516, acc= 82.3% | time=1008.8ms | Valid: loss=0.916, acc= 70.4% | *\n",
            "Epoch  35 | Train: loss=0.517, acc= 82.4% | time=1009.0ms | Valid: loss=0.947, acc= 69.6% |\n",
            "Epoch  36 | Train: loss=0.512, acc= 82.1% | time=1005.2ms | Valid: loss=0.957, acc= 69.6% |\n",
            "Epoch  37 | Train: loss=0.515, acc= 82.8% | time=1004.1ms | Valid: loss=0.948, acc= 68.8% |\n",
            "Epoch  38 | Train: loss=0.506, acc= 82.6% | time=1010.4ms | Valid: loss=0.917, acc= 70.4% |\n",
            "Epoch  39 | Train: loss=0.507, acc= 82.8% | time=1013.2ms | Valid: loss=0.980, acc= 70.4% |\n",
            "Epoch  40 | Train: loss=0.509, acc= 82.8% | time=1006.9ms | Valid: loss=0.900, acc= 70.0% | *\n",
            "Epoch  41 | Train: loss=0.507, acc= 83.0% | time=1009.5ms | Valid: loss=0.943, acc= 69.2% |\n",
            "Epoch  42 | Train: loss=0.484, acc= 83.2% | time=1012.6ms | Valid: loss=0.932, acc= 70.0% |\n",
            "Epoch  43 | Train: loss=0.493, acc= 83.1% | time=1009.0ms | Valid: loss=0.890, acc= 71.6% | *\n",
            "Epoch  44 | Train: loss=0.483, acc= 83.7% | time=1003.8ms | Valid: loss=0.921, acc= 71.6% |\n",
            "Epoch  45 | Train: loss=0.483, acc= 84.0% | time=1004.5ms | Valid: loss=0.900, acc= 69.2% |\n",
            "Epoch  46 | Train: loss=0.486, acc= 83.7% | time=1012.5ms | Valid: loss=0.937, acc= 67.2% |\n",
            "Epoch  47 | Train: loss=0.489, acc= 83.5% | time=1006.5ms | Valid: loss=0.948, acc= 69.6% |\n",
            "Epoch  48 | Train: loss=0.470, acc= 84.0% | time=1002.0ms | Valid: loss=0.913, acc= 69.2% |\n",
            "Epoch  49 | Train: loss=0.473, acc= 83.7% | time=999.1ms | Valid: loss=0.943, acc= 72.0% | lr=1.3e-03\n",
            "Epoch  50 | Train: loss=0.464, acc= 84.1% | time=1008.6ms | Valid: loss=0.939, acc= 70.4% |\n",
            "Epoch  51 | Train: loss=0.471, acc= 84.0% | time=1004.5ms | Valid: loss=0.932, acc= 70.0% |\n",
            "Epoch  52 | Train: loss=0.474, acc= 83.9% | time=1001.2ms | Valid: loss=0.949, acc= 69.2% |\n",
            "Epoch  53 | Train: loss=0.479, acc= 83.5% | time=1002.3ms | Valid: loss=0.921, acc= 68.4% |\n",
            "Epoch  54 | Train: loss=0.471, acc= 83.9% | time=1005.3ms | Valid: loss=0.909, acc= 70.4% |\n",
            "Epoch  55 | Train: loss=0.467, acc= 84.1% | time=1002.1ms | Valid: loss=0.920, acc= 68.8% | lr=6.3e-04\n",
            "Epoch  56 | Train: loss=0.475, acc= 84.0% | time=1000.1ms | Valid: loss=0.946, acc= 69.2% |\n",
            "Epoch  57 | Train: loss=0.471, acc= 83.6% | time=1002.9ms | Valid: loss=0.884, acc= 70.8% | *\n",
            "Epoch  58 | Train: loss=0.469, acc= 83.6% | time=1006.8ms | Valid: loss=0.969, acc= 67.6% |\n",
            "Epoch  59 | Train: loss=0.465, acc= 84.4% | time=1002.6ms | Valid: loss=0.910, acc= 71.2% |\n",
            "Epoch  60 | Train: loss=0.466, acc= 83.8% | time=1009.8ms | Valid: loss=0.911, acc= 70.0% |\n",
            "Epoch  61 | Train: loss=0.467, acc= 84.2% | time=1003.3ms | Valid: loss=0.955, acc= 68.8% |\n",
            "Epoch  62 | Train: loss=0.466, acc= 84.1% | time=1003.8ms | Valid: loss=0.961, acc= 68.0% |\n",
            "Epoch  63 | Train: loss=0.457, acc= 83.9% | time=1002.5ms | Valid: loss=0.888, acc= 70.4% | lr=3.1e-04\n",
            "Epoch  64 | Train: loss=0.463, acc= 84.2% | time=1006.8ms | Valid: loss=0.924, acc= 69.6% |\n",
            "Epoch  65 | Train: loss=0.466, acc= 84.2% | time=1005.6ms | Valid: loss=0.953, acc= 69.2% |\n",
            "Epoch  66 | Train: loss=0.466, acc= 84.3% | time=1004.3ms | Valid: loss=0.888, acc= 71.2% |\n",
            "Epoch  67 | Train: loss=0.466, acc= 84.1% | time=1002.0ms | Valid: loss=0.940, acc= 71.6% |\n",
            "Epoch  68 | Train: loss=0.455, acc= 84.7% | time=1010.1ms | Valid: loss=0.921, acc= 70.4% |\n",
            "Epoch  69 | Train: loss=0.468, acc= 83.6% | time=1003.3ms | Valid: loss=0.939, acc= 69.6% | lr=1.6e-04\n",
            "Epoch  70 | Train: loss=0.464, acc= 84.0% | time=1003.3ms | Valid: loss=0.927, acc= 69.6% |\n",
            "Epoch  71 | Train: loss=0.461, acc= 84.3% | time=1007.2ms | Valid: loss=0.902, acc= 70.8% |\n",
            "Epoch  72 | Train: loss=0.465, acc= 83.9% | time=1002.7ms | Valid: loss=0.892, acc= 70.8% |\n",
            "Epoch  73 | Train: loss=0.455, acc= 84.8% | time=1006.4ms | Valid: loss=0.901, acc= 70.0% |\n",
            "Epoch  74 | Train: loss=0.461, acc= 84.2% | time=1007.8ms | Valid: loss=0.929, acc= 72.8% |\n",
            "Epoch  75 | Train: loss=0.464, acc= 84.1% | time=1006.9ms | Valid: loss=0.974, acc= 68.8% | lr=7.8e-05\n",
            "Epoch  76 | Train: loss=0.460, acc= 84.5% | time=1006.8ms | Valid: loss=0.922, acc= 70.0% |\n",
            "Epoch  77 | Train: loss=0.456, acc= 84.3% | time=1010.5ms | Valid: loss=0.948, acc= 69.6% |\n",
            "Epoch  78 | Train: loss=0.464, acc= 84.2% | time=1006.2ms | Valid: loss=0.919, acc= 69.2% |\n",
            "Epoch  79 | Train: loss=0.456, acc= 84.5% | time=1012.6ms | Valid: loss=0.920, acc= 71.2% |\n",
            "Epoch  80 | Train: loss=0.466, acc= 84.4% | time=1004.5ms | Valid: loss=0.931, acc= 69.6% |\n",
            "Epoch  81 | Train: loss=0.463, acc= 84.4% | time=1006.1ms | Valid: loss=0.898, acc= 68.8% | lr=3.9e-05\n",
            "Epoch  82 | Train: loss=0.462, acc= 84.3% | time=1011.3ms | Valid: loss=0.913, acc= 71.6% |\n",
            "Epoch  83 | Train: loss=0.462, acc= 83.9% | time=1010.2ms | Valid: loss=0.962, acc= 70.0% |\n",
            "Epoch  84 | Train: loss=0.462, acc= 84.0% | time=1006.0ms | Valid: loss=0.946, acc= 70.4% |\n",
            "Epoch  85 | Train: loss=0.456, acc= 84.2% | time=1011.2ms | Valid: loss=0.909, acc= 70.4% |\n",
            "Epoch  86 | Train: loss=0.463, acc= 84.1% | time=1007.6ms | Valid: loss=0.935, acc= 70.4% |\n",
            "Epoch  87 | Train: loss=0.460, acc= 84.3% | time=1011.7ms | Valid: loss=0.927, acc= 71.2% | lr=2.0e-05\n",
            "Epoch  88 | Train: loss=0.459, acc= 84.2% | time=1011.7ms | Valid: loss=0.921, acc= 70.8% |\n",
            "Epoch  89 | Train: loss=0.470, acc= 83.6% | time=1006.0ms | Valid: loss=0.904, acc= 71.6% |\n",
            "Epoch  90 | Train: loss=0.461, acc= 84.6% | time=1007.7ms | Valid: loss=0.933, acc= 69.6% |\n",
            "Epoch  91 | Train: loss=0.463, acc= 83.7% | time=1010.9ms | Valid: loss=0.883, acc= 70.8% | *\n",
            "Epoch  92 | Train: loss=0.457, acc= 84.6% | time=1007.4ms | Valid: loss=0.902, acc= 71.6% |\n",
            "Epoch  93 | Train: loss=0.461, acc= 84.3% | time=1004.8ms | Valid: loss=0.963, acc= 68.8% |\n",
            "Epoch  94 | Train: loss=0.455, acc= 84.7% | time=1006.0ms | Valid: loss=0.933, acc= 69.2% |\n",
            "Epoch  95 | Train: loss=0.454, acc= 84.4% | time=1005.0ms | Valid: loss=0.914, acc= 70.8% |\n",
            "Epoch  96 | Train: loss=0.463, acc= 84.2% | time=1004.6ms | Valid: loss=0.884, acc= 69.2% |\n",
            "Epoch  97 | Train: loss=0.455, acc= 84.4% | time=1004.1ms | Valid: loss=0.969, acc= 70.0% | lr=9.8e-06\n",
            "Test: loss=0.883 , acc= 73.2%\n",
            "------------------------------\n",
            "Representation Matrix\n",
            "------------------------------\n",
            "Layer 1 : (48, 20184)\n",
            "Layer 2 : (576, 14400)\n",
            "Layer 3 : (512, 2500)\n",
            "Layer 4 : (1024, 125)\n",
            "Layer 5 : (2048, 125)\n",
            "------------------------------\n",
            "Threshold:  [0.982 0.982 0.982 0.982 0.982]\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 12/48\n",
            "Layer 2 : 258/576\n",
            "Layer 3 : 357/512\n",
            "Layer 4 : 377/1024\n",
            "Layer 5 : 487/2048\n",
            "----------------------------------------\n",
            "Accuracies =\n",
            "\t 78.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 77.6%  68.1%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 77.3%  68.8%  71.9%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 75.8%  68.5%  72.5%  71.4%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 76.4%  69.6%  71.0%  71.5%  75.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "****************************************************************************************************\n",
            "Task  5 (cifar100-5)\n",
            "****************************************************************************************************\n",
            "----------------------------------------\n",
            "Task ID :5 | Learning Rate : 0.01\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([48, 48])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([576, 576])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([512, 512])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([1024, 1024])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([2048, 2048])\n",
            "----------------------------------------\n",
            "Epoch   1 | Train: loss=1.170, acc= 59.4% | time=1001.2ms | Valid: loss=1.164, acc= 56.8% | *\n",
            "Epoch   2 | Train: loss=1.046, acc= 63.3% | time=1002.5ms | Valid: loss=1.094, acc= 59.2% | *\n",
            "Epoch   3 | Train: loss=0.968, acc= 65.7% | time=1003.9ms | Valid: loss=1.062, acc= 60.8% | *\n",
            "Epoch   4 | Train: loss=0.924, acc= 67.0% | time=1004.6ms | Valid: loss=0.995, acc= 63.2% | *\n",
            "Epoch   5 | Train: loss=0.919, acc= 67.3% | time=1005.0ms | Valid: loss=1.009, acc= 64.0% |\n",
            "Epoch   6 | Train: loss=0.911, acc= 68.1% | time=1006.6ms | Valid: loss=0.978, acc= 66.4% | *\n",
            "Epoch   7 | Train: loss=0.858, acc= 69.6% | time=1004.2ms | Valid: loss=0.927, acc= 65.6% | *\n",
            "Epoch   8 | Train: loss=0.801, acc= 71.4% | time=1003.5ms | Valid: loss=0.881, acc= 67.2% | *\n",
            "Epoch   9 | Train: loss=0.796, acc= 71.6% | time=1008.0ms | Valid: loss=0.864, acc= 67.2% | *\n",
            "Epoch  10 | Train: loss=0.784, acc= 72.4% | time=1004.3ms | Valid: loss=0.858, acc= 67.6% | *\n",
            "Epoch  11 | Train: loss=0.765, acc= 72.2% | time=1008.4ms | Valid: loss=0.881, acc= 66.8% |\n",
            "Epoch  12 | Train: loss=0.739, acc= 73.7% | time=1013.2ms | Valid: loss=0.871, acc= 65.6% |\n",
            "Epoch  13 | Train: loss=0.733, acc= 73.9% | time=1011.5ms | Valid: loss=0.827, acc= 68.4% | *\n",
            "Epoch  14 | Train: loss=0.727, acc= 73.6% | time=1013.0ms | Valid: loss=0.827, acc= 69.2% |\n",
            "Epoch  15 | Train: loss=0.708, acc= 75.0% | time=1016.6ms | Valid: loss=0.865, acc= 67.2% |\n",
            "Epoch  16 | Train: loss=0.675, acc= 75.9% | time=1022.3ms | Valid: loss=0.912, acc= 65.6% |\n",
            "Epoch  17 | Train: loss=0.710, acc= 74.7% | time=1024.4ms | Valid: loss=0.862, acc= 68.8% |\n",
            "Epoch  18 | Train: loss=0.674, acc= 76.1% | time=1022.1ms | Valid: loss=0.844, acc= 69.2% |\n",
            "Epoch  19 | Train: loss=0.668, acc= 76.1% | time=1019.7ms | Valid: loss=0.850, acc= 70.0% | lr=5.0e-03\n",
            "Epoch  20 | Train: loss=0.638, acc= 77.5% | time=1019.3ms | Valid: loss=0.837, acc= 67.6% |\n",
            "Epoch  21 | Train: loss=0.634, acc= 77.7% | time=1023.0ms | Valid: loss=0.792, acc= 72.0% | *\n",
            "Epoch  22 | Train: loss=0.620, acc= 78.1% | time=1024.2ms | Valid: loss=0.813, acc= 67.6% |\n",
            "Epoch  23 | Train: loss=0.622, acc= 78.1% | time=1018.5ms | Valid: loss=0.823, acc= 70.0% |\n",
            "Epoch  24 | Train: loss=0.619, acc= 77.7% | time=1020.8ms | Valid: loss=0.801, acc= 69.2% |\n",
            "Epoch  25 | Train: loss=0.611, acc= 78.4% | time=1018.3ms | Valid: loss=0.835, acc= 69.6% |\n",
            "Epoch  26 | Train: loss=0.612, acc= 78.1% | time=1014.6ms | Valid: loss=0.831, acc= 68.8% |\n",
            "Epoch  27 | Train: loss=0.592, acc= 79.2% | time=1022.8ms | Valid: loss=0.825, acc= 70.8% | lr=2.5e-03\n",
            "Epoch  28 | Train: loss=0.597, acc= 79.7% | time=1011.6ms | Valid: loss=0.816, acc= 71.2% |\n",
            "Epoch  29 | Train: loss=0.588, acc= 79.1% | time=1016.0ms | Valid: loss=0.811, acc= 68.0% |\n",
            "Epoch  30 | Train: loss=0.584, acc= 79.7% | time=1011.3ms | Valid: loss=0.816, acc= 70.4% |\n",
            "Epoch  31 | Train: loss=0.592, acc= 79.1% | time=1015.4ms | Valid: loss=0.851, acc= 68.0% |\n",
            "Epoch  32 | Train: loss=0.580, acc= 79.8% | time=1010.4ms | Valid: loss=0.817, acc= 70.8% |\n",
            "Epoch  33 | Train: loss=0.589, acc= 78.7% | time=1008.9ms | Valid: loss=0.783, acc= 70.4% | *\n",
            "Epoch  34 | Train: loss=0.575, acc= 79.3% | time=1008.8ms | Valid: loss=0.773, acc= 72.0% | *\n",
            "Epoch  35 | Train: loss=0.580, acc= 79.5% | time=1009.5ms | Valid: loss=0.776, acc= 71.2% |\n",
            "Epoch  36 | Train: loss=0.581, acc= 79.6% | time=1008.5ms | Valid: loss=0.828, acc= 71.2% |\n",
            "Epoch  37 | Train: loss=0.571, acc= 79.9% | time=1016.2ms | Valid: loss=0.764, acc= 71.6% | *\n",
            "Epoch  38 | Train: loss=0.563, acc= 79.9% | time=1303.0ms | Valid: loss=0.798, acc= 70.8% |\n",
            "Epoch  39 | Train: loss=0.572, acc= 80.0% | time=1145.2ms | Valid: loss=0.826, acc= 72.8% |\n",
            "Epoch  40 | Train: loss=0.569, acc= 79.2% | time=1197.0ms | Valid: loss=0.785, acc= 70.8% |\n",
            "Epoch  41 | Train: loss=0.562, acc= 80.2% | time=1014.9ms | Valid: loss=0.808, acc= 69.6% |\n",
            "Epoch  42 | Train: loss=0.564, acc= 80.7% | time=1008.5ms | Valid: loss=0.794, acc= 71.2% |\n",
            "Epoch  43 | Train: loss=0.547, acc= 80.7% | time=1008.6ms | Valid: loss=0.772, acc= 71.6% | lr=1.3e-03\n",
            "Epoch  44 | Train: loss=0.546, acc= 80.7% | time=1003.3ms | Valid: loss=0.779, acc= 72.0% |\n",
            "Epoch  45 | Train: loss=0.551, acc= 80.2% | time=1006.8ms | Valid: loss=0.784, acc= 69.2% |\n",
            "Epoch  46 | Train: loss=0.553, acc= 80.1% | time=1008.4ms | Valid: loss=0.781, acc= 71.6% |\n",
            "Epoch  47 | Train: loss=0.557, acc= 80.4% | time=1001.7ms | Valid: loss=0.791, acc= 70.0% |\n",
            "Epoch  48 | Train: loss=0.532, acc= 81.2% | time=1000.8ms | Valid: loss=0.765, acc= 71.6% |\n",
            "Epoch  49 | Train: loss=0.555, acc= 80.2% | time=1015.7ms | Valid: loss=0.805, acc= 70.0% | lr=6.3e-04\n",
            "Epoch  50 | Train: loss=0.547, acc= 81.1% | time=1003.9ms | Valid: loss=0.754, acc= 71.6% | *\n",
            "Epoch  51 | Train: loss=0.545, acc= 80.9% | time=1001.9ms | Valid: loss=0.786, acc= 72.4% |\n",
            "Epoch  52 | Train: loss=0.548, acc= 80.0% | time=1002.7ms | Valid: loss=0.794, acc= 70.0% |\n",
            "Epoch  53 | Train: loss=0.540, acc= 81.3% | time=1001.0ms | Valid: loss=0.819, acc= 72.0% |\n",
            "Epoch  54 | Train: loss=0.540, acc= 81.5% | time=1003.1ms | Valid: loss=0.792, acc= 73.6% |\n",
            "Epoch  55 | Train: loss=0.537, acc= 80.8% | time=1003.5ms | Valid: loss=0.776, acc= 72.0% |\n",
            "Epoch  56 | Train: loss=0.548, acc= 80.4% | time=998.6ms | Valid: loss=0.754, acc= 72.0% | *\n",
            "Epoch  57 | Train: loss=0.541, acc= 80.5% | time=999.9ms | Valid: loss=0.837, acc= 69.6% |\n",
            "Epoch  58 | Train: loss=0.529, acc= 81.8% | time=1000.9ms | Valid: loss=0.748, acc= 71.2% | *\n",
            "Epoch  59 | Train: loss=0.537, acc= 81.5% | time=1005.4ms | Valid: loss=0.776, acc= 72.4% |\n",
            "Epoch  60 | Train: loss=0.544, acc= 81.2% | time=1003.9ms | Valid: loss=0.782, acc= 72.0% |\n",
            "Epoch  61 | Train: loss=0.535, acc= 80.8% | time=1006.6ms | Valid: loss=0.778, acc= 70.8% |\n",
            "Epoch  62 | Train: loss=0.547, acc= 80.4% | time=1003.8ms | Valid: loss=0.795, acc= 70.8% |\n",
            "Epoch  63 | Train: loss=0.538, acc= 80.9% | time=1001.8ms | Valid: loss=0.820, acc= 71.6% |\n",
            "Epoch  64 | Train: loss=0.538, acc= 81.2% | time=1005.6ms | Valid: loss=0.774, acc= 71.6% | lr=3.1e-04\n",
            "Epoch  65 | Train: loss=0.547, acc= 80.9% | time=1008.7ms | Valid: loss=0.785, acc= 69.2% |\n",
            "Epoch  66 | Train: loss=0.533, acc= 81.4% | time=1005.9ms | Valid: loss=0.786, acc= 71.2% |\n",
            "Epoch  67 | Train: loss=0.532, acc= 81.2% | time=1007.0ms | Valid: loss=0.783, acc= 69.6% |\n",
            "Epoch  68 | Train: loss=0.537, acc= 81.4% | time=1007.5ms | Valid: loss=0.770, acc= 70.0% |\n",
            "Epoch  69 | Train: loss=0.533, acc= 80.9% | time=1000.0ms | Valid: loss=0.770, acc= 69.6% |\n",
            "Epoch  70 | Train: loss=0.535, acc= 81.5% | time=1015.1ms | Valid: loss=0.758, acc= 70.4% | lr=1.6e-04\n",
            "Epoch  71 | Train: loss=0.533, acc= 81.5% | time=1011.0ms | Valid: loss=0.773, acc= 72.8% |\n",
            "Epoch  72 | Train: loss=0.533, acc= 81.6% | time=1003.0ms | Valid: loss=0.778, acc= 70.4% |\n",
            "Epoch  73 | Train: loss=0.532, acc= 81.2% | time=1008.6ms | Valid: loss=0.791, acc= 69.6% |\n",
            "Epoch  74 | Train: loss=0.528, acc= 81.3% | time=1009.3ms | Valid: loss=0.786, acc= 70.4% |\n",
            "Epoch  75 | Train: loss=0.529, acc= 81.6% | time=1008.3ms | Valid: loss=0.808, acc= 68.8% |\n",
            "Epoch  76 | Train: loss=0.538, acc= 81.1% | time=1004.8ms | Valid: loss=0.776, acc= 70.4% | lr=7.8e-05\n",
            "Epoch  77 | Train: loss=0.535, acc= 81.4% | time=1008.7ms | Valid: loss=0.766, acc= 72.0% |\n",
            "Epoch  78 | Train: loss=0.530, acc= 81.0% | time=1010.6ms | Valid: loss=0.806, acc= 69.6% |\n",
            "Epoch  79 | Train: loss=0.537, acc= 81.1% | time=1011.6ms | Valid: loss=0.777, acc= 70.0% |\n",
            "Epoch  80 | Train: loss=0.532, acc= 81.6% | time=1010.9ms | Valid: loss=0.779, acc= 70.8% |\n",
            "Epoch  81 | Train: loss=0.531, acc= 80.9% | time=1006.7ms | Valid: loss=0.781, acc= 69.6% |\n",
            "Epoch  82 | Train: loss=0.528, acc= 81.3% | time=1009.7ms | Valid: loss=0.804, acc= 71.2% | lr=3.9e-05\n",
            "Epoch  83 | Train: loss=0.531, acc= 81.6% | time=1015.9ms | Valid: loss=0.774, acc= 70.0% |\n",
            "Epoch  84 | Train: loss=0.532, acc= 80.8% | time=1013.8ms | Valid: loss=0.789, acc= 72.0% |\n",
            "Epoch  85 | Train: loss=0.530, acc= 81.7% | time=1012.4ms | Valid: loss=0.759, acc= 71.2% |\n",
            "Epoch  86 | Train: loss=0.526, acc= 81.6% | time=1136.6ms | Valid: loss=0.781, acc= 68.4% |\n",
            "Epoch  87 | Train: loss=0.535, acc= 81.2% | time=1089.6ms | Valid: loss=0.775, acc= 70.8% |\n",
            "Epoch  88 | Train: loss=0.525, acc= 81.6% | time=1008.8ms | Valid: loss=0.768, acc= 71.2% | lr=2.0e-05\n",
            "Epoch  89 | Train: loss=0.537, acc= 81.2% | time=1010.7ms | Valid: loss=0.772, acc= 70.8% |\n",
            "Epoch  90 | Train: loss=0.530, acc= 81.1% | time=1010.1ms | Valid: loss=0.788, acc= 73.6% |\n",
            "Epoch  91 | Train: loss=0.536, acc= 80.9% | time=1010.6ms | Valid: loss=0.770, acc= 70.8% |\n",
            "Epoch  92 | Train: loss=0.530, acc= 81.1% | time=1004.7ms | Valid: loss=0.778, acc= 70.0% |\n",
            "Epoch  93 | Train: loss=0.526, acc= 81.1% | time=1014.8ms | Valid: loss=0.785, acc= 70.4% |\n",
            "Epoch  94 | Train: loss=0.535, acc= 81.1% | time=1014.7ms | Valid: loss=0.807, acc= 69.2% | lr=9.8e-06\n",
            "Test: loss=0.851 , acc= 70.2%\n",
            "------------------------------\n",
            "Representation Matrix\n",
            "------------------------------\n",
            "Layer 1 : (48, 20184)\n",
            "Layer 2 : (576, 14400)\n",
            "Layer 3 : (512, 2500)\n",
            "Layer 4 : (1024, 125)\n",
            "Layer 5 : (2048, 125)\n",
            "------------------------------\n",
            "Threshold:  [0.985 0.985 0.985 0.985 0.985]\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 13/48\n",
            "Layer 2 : 272/576\n",
            "Layer 3 : 378/512\n",
            "Layer 4 : 450/1024\n",
            "Layer 5 : 587/2048\n",
            "----------------------------------------\n",
            "Accuracies =\n",
            "\t 78.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 77.6%  68.1%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 77.3%  68.8%  71.9%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 75.8%  68.5%  72.5%  71.4%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 76.4%  69.6%  71.0%  71.5%  75.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 76.6%  68.6%  71.9%  71.8%  74.5%  70.7%   0.0%   0.0%   0.0%   0.0% \n",
            "****************************************************************************************************\n",
            "Task  6 (cifar100-6)\n",
            "****************************************************************************************************\n",
            "----------------------------------------\n",
            "Task ID :6 | Learning Rate : 0.01\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([48, 48])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([576, 576])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([512, 512])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([1024, 1024])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([2048, 2048])\n",
            "----------------------------------------\n",
            "Epoch   1 | Train: loss=1.133, acc= 61.5% | time=1003.2ms | Valid: loss=1.226, acc= 54.4% | *\n",
            "Epoch   2 | Train: loss=0.996, acc= 65.3% | time=1008.4ms | Valid: loss=1.131, acc= 58.4% | *\n",
            "Epoch   3 | Train: loss=0.939, acc= 66.9% | time=1010.2ms | Valid: loss=1.084, acc= 60.0% | *\n",
            "Epoch   4 | Train: loss=0.921, acc= 67.7% | time=1005.9ms | Valid: loss=1.120, acc= 60.0% |\n",
            "Epoch   5 | Train: loss=0.863, acc= 70.1% | time=1002.2ms | Valid: loss=1.092, acc= 59.2% |\n",
            "Epoch   6 | Train: loss=0.852, acc= 70.2% | time=1008.8ms | Valid: loss=1.127, acc= 59.2% |\n",
            "Epoch   7 | Train: loss=0.825, acc= 71.2% | time=1010.3ms | Valid: loss=1.033, acc= 64.0% | *\n",
            "Epoch   8 | Train: loss=0.836, acc= 70.5% | time=1008.9ms | Valid: loss=1.076, acc= 62.0% |\n",
            "Epoch   9 | Train: loss=0.848, acc= 70.0% | time=1010.9ms | Valid: loss=1.085, acc= 63.6% |\n",
            "Epoch  10 | Train: loss=0.790, acc= 71.9% | time=1010.5ms | Valid: loss=1.054, acc= 63.2% |\n",
            "Epoch  11 | Train: loss=0.782, acc= 73.0% | time=1013.1ms | Valid: loss=1.143, acc= 60.8% |\n",
            "Epoch  12 | Train: loss=0.758, acc= 73.2% | time=1022.5ms | Valid: loss=1.046, acc= 64.0% |\n",
            "Epoch  13 | Train: loss=0.729, acc= 74.2% | time=1019.6ms | Valid: loss=1.042, acc= 64.4% | lr=5.0e-03\n",
            "Epoch  14 | Train: loss=0.741, acc= 73.7% | time=1006.8ms | Valid: loss=1.074, acc= 64.0% |\n",
            "Epoch  15 | Train: loss=0.745, acc= 73.5% | time=1023.8ms | Valid: loss=1.051, acc= 62.4% |\n",
            "Epoch  16 | Train: loss=0.723, acc= 74.2% | time=1020.9ms | Valid: loss=1.099, acc= 62.0% |\n",
            "Epoch  17 | Train: loss=0.713, acc= 74.8% | time=1022.2ms | Valid: loss=1.037, acc= 65.6% |\n",
            "Epoch  18 | Train: loss=0.697, acc= 75.4% | time=1018.3ms | Valid: loss=1.046, acc= 62.8% |\n",
            "Epoch  19 | Train: loss=0.689, acc= 75.9% | time=1027.6ms | Valid: loss=1.043, acc= 65.6% | lr=2.5e-03\n",
            "Epoch  20 | Train: loss=0.686, acc= 75.7% | time=1026.8ms | Valid: loss=1.049, acc= 65.2% |\n",
            "Epoch  21 | Train: loss=0.681, acc= 75.7% | time=1027.7ms | Valid: loss=1.029, acc= 64.0% | *\n",
            "Epoch  22 | Train: loss=0.677, acc= 76.8% | time=1024.9ms | Valid: loss=1.012, acc= 66.4% | *\n",
            "Epoch  23 | Train: loss=0.672, acc= 76.3% | time=1022.4ms | Valid: loss=1.041, acc= 64.0% |\n",
            "Epoch  24 | Train: loss=0.662, acc= 76.3% | time=1023.8ms | Valid: loss=1.045, acc= 65.2% |\n",
            "Epoch  25 | Train: loss=0.678, acc= 76.1% | time=1024.5ms | Valid: loss=1.074, acc= 64.8% |\n",
            "Epoch  26 | Train: loss=0.669, acc= 76.8% | time=1023.3ms | Valid: loss=1.052, acc= 65.2% |\n",
            "Epoch  27 | Train: loss=0.668, acc= 76.0% | time=1014.7ms | Valid: loss=1.010, acc= 66.0% | *\n",
            "Epoch  28 | Train: loss=0.673, acc= 76.3% | time=1013.3ms | Valid: loss=1.041, acc= 64.8% |\n",
            "Epoch  29 | Train: loss=0.669, acc= 76.7% | time=1019.2ms | Valid: loss=1.073, acc= 62.0% |\n",
            "Epoch  30 | Train: loss=0.651, acc= 76.8% | time=1014.1ms | Valid: loss=1.022, acc= 65.2% |\n",
            "Epoch  31 | Train: loss=0.661, acc= 76.9% | time=1016.2ms | Valid: loss=1.035, acc= 66.8% |\n",
            "Epoch  32 | Train: loss=0.646, acc= 77.4% | time=1005.8ms | Valid: loss=1.004, acc= 63.6% | *\n",
            "Epoch  33 | Train: loss=0.659, acc= 77.4% | time=1010.0ms | Valid: loss=1.038, acc= 64.4% |\n",
            "Epoch  34 | Train: loss=0.643, acc= 76.9% | time=1011.4ms | Valid: loss=1.071, acc= 64.0% |\n",
            "Epoch  35 | Train: loss=0.640, acc= 77.5% | time=1008.4ms | Valid: loss=1.056, acc= 64.0% |\n",
            "Epoch  36 | Train: loss=0.649, acc= 77.1% | time=1006.9ms | Valid: loss=1.074, acc= 65.2% |\n",
            "Epoch  37 | Train: loss=0.633, acc= 77.8% | time=1006.3ms | Valid: loss=1.028, acc= 65.2% |\n",
            "Epoch  38 | Train: loss=0.639, acc= 76.9% | time=1005.4ms | Valid: loss=1.041, acc= 65.6% | lr=1.3e-03\n",
            "Epoch  39 | Train: loss=0.632, acc= 77.9% | time=1005.5ms | Valid: loss=1.070, acc= 64.4% |\n",
            "Epoch  40 | Train: loss=0.633, acc= 78.0% | time=1011.4ms | Valid: loss=1.020, acc= 66.4% |\n",
            "Epoch  41 | Train: loss=0.629, acc= 77.9% | time=1006.2ms | Valid: loss=1.053, acc= 65.6% |\n",
            "Epoch  42 | Train: loss=0.629, acc= 77.9% | time=1002.8ms | Valid: loss=1.009, acc= 67.2% |\n",
            "Epoch  43 | Train: loss=0.646, acc= 77.3% | time=1003.7ms | Valid: loss=1.026, acc= 65.2% |\n",
            "Epoch  44 | Train: loss=0.627, acc= 78.5% | time=1007.6ms | Valid: loss=1.101, acc= 63.6% | lr=6.3e-04\n",
            "Epoch  45 | Train: loss=0.628, acc= 77.9% | time=1006.7ms | Valid: loss=1.030, acc= 64.4% |\n",
            "Epoch  46 | Train: loss=0.633, acc= 78.1% | time=1011.5ms | Valid: loss=1.091, acc= 65.2% |\n",
            "Epoch  47 | Train: loss=0.621, acc= 77.9% | time=1003.7ms | Valid: loss=1.006, acc= 64.8% |\n",
            "Epoch  48 | Train: loss=0.618, acc= 78.0% | time=1001.9ms | Valid: loss=1.016, acc= 65.6% |\n",
            "Epoch  49 | Train: loss=0.618, acc= 78.5% | time=1003.4ms | Valid: loss=1.065, acc= 64.0% |\n",
            "Epoch  50 | Train: loss=0.625, acc= 77.7% | time=1003.9ms | Valid: loss=1.063, acc= 66.8% | lr=3.1e-04\n",
            "Epoch  51 | Train: loss=0.619, acc= 78.5% | time=1006.3ms | Valid: loss=1.085, acc= 64.8% |\n",
            "Epoch  52 | Train: loss=0.617, acc= 78.5% | time=1002.8ms | Valid: loss=1.045, acc= 64.8% |\n",
            "Epoch  53 | Train: loss=0.626, acc= 78.2% | time=1005.1ms | Valid: loss=1.030, acc= 65.2% |\n",
            "Epoch  54 | Train: loss=0.614, acc= 78.4% | time=1003.3ms | Valid: loss=1.037, acc= 63.2% |\n",
            "Epoch  55 | Train: loss=0.627, acc= 78.2% | time=1004.8ms | Valid: loss=1.071, acc= 64.4% |\n",
            "Epoch  56 | Train: loss=0.623, acc= 77.8% | time=1003.4ms | Valid: loss=1.062, acc= 64.8% | lr=1.6e-04\n",
            "Epoch  57 | Train: loss=0.618, acc= 78.4% | time=1006.6ms | Valid: loss=1.019, acc= 64.4% |\n",
            "Epoch  58 | Train: loss=0.619, acc= 78.1% | time=1002.6ms | Valid: loss=1.025, acc= 65.2% |\n",
            "Epoch  59 | Train: loss=0.619, acc= 78.8% | time=1003.7ms | Valid: loss=1.065, acc= 63.6% |\n",
            "Epoch  60 | Train: loss=0.625, acc= 78.9% | time=1002.4ms | Valid: loss=1.050, acc= 65.2% |\n",
            "Epoch  61 | Train: loss=0.617, acc= 78.5% | time=1008.9ms | Valid: loss=1.002, acc= 66.0% | *\n",
            "Epoch  62 | Train: loss=0.619, acc= 78.2% | time=1002.4ms | Valid: loss=1.022, acc= 65.2% |\n",
            "Epoch  63 | Train: loss=0.621, acc= 77.8% | time=1004.0ms | Valid: loss=1.033, acc= 65.2% |\n",
            "Epoch  64 | Train: loss=0.619, acc= 78.0% | time=1001.6ms | Valid: loss=1.056, acc= 64.4% |\n",
            "Epoch  65 | Train: loss=0.620, acc= 78.1% | time=1006.0ms | Valid: loss=1.056, acc= 64.8% |\n",
            "Epoch  66 | Train: loss=0.626, acc= 78.1% | time=1004.1ms | Valid: loss=1.030, acc= 64.4% |\n",
            "Epoch  67 | Train: loss=0.628, acc= 78.1% | time=1003.2ms | Valid: loss=1.048, acc= 64.0% | lr=7.8e-05\n",
            "Epoch  68 | Train: loss=0.618, acc= 78.2% | time=1008.7ms | Valid: loss=1.078, acc= 63.6% |\n",
            "Epoch  69 | Train: loss=0.621, acc= 78.1% | time=1009.9ms | Valid: loss=1.039, acc= 65.2% |\n",
            "Epoch  70 | Train: loss=0.611, acc= 78.4% | time=1003.2ms | Valid: loss=1.013, acc= 64.8% |\n",
            "Epoch  71 | Train: loss=0.619, acc= 78.4% | time=1008.6ms | Valid: loss=1.058, acc= 65.2% |\n",
            "Epoch  72 | Train: loss=0.617, acc= 78.4% | time=1010.0ms | Valid: loss=1.013, acc= 67.2% |\n",
            "Epoch  73 | Train: loss=0.616, acc= 78.3% | time=1009.2ms | Valid: loss=1.026, acc= 65.2% | lr=3.9e-05\n",
            "Epoch  74 | Train: loss=0.615, acc= 78.2% | time=1010.5ms | Valid: loss=1.025, acc= 63.6% |\n",
            "Epoch  75 | Train: loss=0.621, acc= 78.5% | time=1016.6ms | Valid: loss=1.017, acc= 65.6% |\n",
            "Epoch  76 | Train: loss=0.622, acc= 78.2% | time=1005.5ms | Valid: loss=1.038, acc= 64.0% |\n",
            "Epoch  77 | Train: loss=0.623, acc= 77.8% | time=1008.6ms | Valid: loss=1.055, acc= 63.6% |\n",
            "Epoch  78 | Train: loss=0.625, acc= 78.3% | time=1009.8ms | Valid: loss=1.071, acc= 64.4% |\n",
            "Epoch  79 | Train: loss=0.619, acc= 78.4% | time=1006.6ms | Valid: loss=1.038, acc= 65.6% | lr=2.0e-05\n",
            "Epoch  80 | Train: loss=0.624, acc= 77.7% | time=1005.4ms | Valid: loss=1.036, acc= 66.0% |\n",
            "Epoch  81 | Train: loss=0.626, acc= 78.1% | time=1011.2ms | Valid: loss=1.059, acc= 66.0% |\n",
            "Epoch  82 | Train: loss=0.613, acc= 79.1% | time=1017.4ms | Valid: loss=1.027, acc= 64.8% |\n",
            "Epoch  83 | Train: loss=0.623, acc= 78.4% | time=1010.3ms | Valid: loss=1.028, acc= 65.2% |\n",
            "Epoch  84 | Train: loss=0.620, acc= 78.3% | time=1009.9ms | Valid: loss=1.065, acc= 64.8% |\n",
            "Epoch  85 | Train: loss=0.623, acc= 78.0% | time=1010.6ms | Valid: loss=1.034, acc= 63.6% | lr=9.8e-06\n",
            "Test: loss=0.901 , acc= 68.9%\n",
            "------------------------------\n",
            "Representation Matrix\n",
            "------------------------------\n",
            "Layer 1 : (48, 20184)\n",
            "Layer 2 : (576, 14400)\n",
            "Layer 3 : (512, 2500)\n",
            "Layer 4 : (1024, 125)\n",
            "Layer 5 : (2048, 125)\n",
            "------------------------------\n",
            "Threshold:  [0.988 0.988 0.988 0.988 0.988]\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 15/48\n",
            "Layer 2 : 295/576\n",
            "Layer 3 : 395/512\n",
            "Layer 4 : 521/1024\n",
            "Layer 5 : 686/2048\n",
            "----------------------------------------\n",
            "Accuracies =\n",
            "\t 78.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 77.6%  68.1%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 77.3%  68.8%  71.9%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 75.8%  68.5%  72.5%  71.4%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 76.4%  69.6%  71.0%  71.5%  75.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 76.6%  68.6%  71.9%  71.8%  74.5%  70.7%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 76.9%  67.6%  73.4%  71.2%  74.3%  70.5%  68.2%   0.0%   0.0%   0.0% \n",
            "****************************************************************************************************\n",
            "Task  7 (cifar100-7)\n",
            "****************************************************************************************************\n",
            "----------------------------------------\n",
            "Task ID :7 | Learning Rate : 0.01\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([48, 48])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([576, 576])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([512, 512])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([1024, 1024])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([2048, 2048])\n",
            "----------------------------------------\n",
            "Epoch   1 | Train: loss=1.175, acc= 60.8% | time=1005.2ms | Valid: loss=1.197, acc= 58.4% | *\n",
            "Epoch   2 | Train: loss=1.082, acc= 63.0% | time=1006.0ms | Valid: loss=1.113, acc= 60.4% | *\n",
            "Epoch   3 | Train: loss=1.016, acc= 65.1% | time=1005.6ms | Valid: loss=1.150, acc= 64.0% |\n",
            "Epoch   4 | Train: loss=0.991, acc= 66.2% | time=1009.0ms | Valid: loss=1.100, acc= 64.8% | *\n",
            "Epoch   5 | Train: loss=0.982, acc= 66.2% | time=1003.2ms | Valid: loss=1.099, acc= 63.6% | *\n",
            "Epoch   6 | Train: loss=0.923, acc= 68.0% | time=1007.6ms | Valid: loss=1.032, acc= 67.6% | *\n",
            "Epoch   7 | Train: loss=0.929, acc= 68.0% | time=1006.1ms | Valid: loss=1.096, acc= 63.6% |\n",
            "Epoch   8 | Train: loss=0.913, acc= 68.8% | time=1011.5ms | Valid: loss=1.021, acc= 64.4% | *\n",
            "Epoch   9 | Train: loss=0.878, acc= 69.5% | time=1010.7ms | Valid: loss=1.017, acc= 65.6% | *\n",
            "Epoch  10 | Train: loss=0.889, acc= 69.3% | time=1007.9ms | Valid: loss=1.078, acc= 63.2% |\n",
            "Epoch  11 | Train: loss=0.841, acc= 71.2% | time=1012.3ms | Valid: loss=1.066, acc= 65.2% |\n",
            "Epoch  12 | Train: loss=0.823, acc= 71.7% | time=1013.4ms | Valid: loss=1.018, acc= 69.2% |\n",
            "Epoch  13 | Train: loss=0.821, acc= 71.7% | time=1016.3ms | Valid: loss=1.017, acc= 67.6% | *\n",
            "Epoch  14 | Train: loss=0.804, acc= 72.6% | time=1018.4ms | Valid: loss=1.010, acc= 67.2% | *\n",
            "Epoch  15 | Train: loss=0.795, acc= 72.1% | time=1019.4ms | Valid: loss=1.022, acc= 67.2% |\n",
            "Epoch  16 | Train: loss=0.773, acc= 73.6% | time=1016.8ms | Valid: loss=1.002, acc= 66.4% | *\n",
            "Epoch  17 | Train: loss=0.795, acc= 73.0% | time=1020.0ms | Valid: loss=1.054, acc= 66.4% |\n",
            "Epoch  18 | Train: loss=0.769, acc= 73.9% | time=1019.9ms | Valid: loss=1.032, acc= 68.0% |\n",
            "Epoch  19 | Train: loss=0.761, acc= 73.4% | time=1028.9ms | Valid: loss=1.033, acc= 64.4% |\n",
            "Epoch  20 | Train: loss=0.753, acc= 74.2% | time=1025.7ms | Valid: loss=1.027, acc= 66.8% |\n",
            "Epoch  21 | Train: loss=0.758, acc= 73.8% | time=1026.2ms | Valid: loss=1.052, acc= 63.2% |\n",
            "Epoch  22 | Train: loss=0.724, acc= 75.5% | time=1022.2ms | Valid: loss=1.026, acc= 68.8% | lr=5.0e-03\n",
            "Epoch  23 | Train: loss=0.710, acc= 75.4% | time=1018.4ms | Valid: loss=1.015, acc= 67.2% |\n",
            "Epoch  24 | Train: loss=0.711, acc= 75.9% | time=1020.1ms | Valid: loss=1.027, acc= 68.0% |\n",
            "Epoch  25 | Train: loss=0.701, acc= 75.4% | time=1022.4ms | Valid: loss=1.028, acc= 68.0% |\n",
            "Epoch  26 | Train: loss=0.701, acc= 75.6% | time=1021.0ms | Valid: loss=1.017, acc= 70.0% |\n",
            "Epoch  27 | Train: loss=0.691, acc= 76.4% | time=1020.1ms | Valid: loss=1.000, acc= 68.4% | *\n",
            "Epoch  28 | Train: loss=0.695, acc= 76.1% | time=1012.2ms | Valid: loss=1.030, acc= 66.8% |\n",
            "Epoch  29 | Train: loss=0.699, acc= 76.2% | time=1017.3ms | Valid: loss=1.036, acc= 66.0% |\n",
            "Epoch  30 | Train: loss=0.679, acc= 76.5% | time=1012.6ms | Valid: loss=0.987, acc= 70.0% | *\n",
            "Epoch  31 | Train: loss=0.672, acc= 76.4% | time=1014.6ms | Valid: loss=1.020, acc= 67.2% |\n",
            "Epoch  32 | Train: loss=0.681, acc= 76.5% | time=1012.8ms | Valid: loss=1.025, acc= 67.2% |\n",
            "Epoch  33 | Train: loss=0.672, acc= 76.4% | time=1011.0ms | Valid: loss=1.035, acc= 68.0% |\n",
            "Epoch  34 | Train: loss=0.681, acc= 76.4% | time=1012.7ms | Valid: loss=1.037, acc= 67.2% |\n",
            "Epoch  35 | Train: loss=0.665, acc= 77.2% | time=1014.4ms | Valid: loss=1.037, acc= 67.2% |\n",
            "Epoch  36 | Train: loss=0.679, acc= 77.0% | time=1009.5ms | Valid: loss=1.001, acc= 68.4% | lr=2.5e-03\n",
            "Epoch  37 | Train: loss=0.661, acc= 77.5% | time=1009.5ms | Valid: loss=1.049, acc= 65.6% |\n",
            "Epoch  38 | Train: loss=0.665, acc= 77.2% | time=1009.1ms | Valid: loss=1.034, acc= 67.6% |\n",
            "Epoch  39 | Train: loss=0.665, acc= 77.2% | time=1008.4ms | Valid: loss=1.043, acc= 69.2% |\n",
            "Epoch  40 | Train: loss=0.654, acc= 77.3% | time=1009.8ms | Valid: loss=1.004, acc= 68.0% |\n",
            "Epoch  41 | Train: loss=0.643, acc= 77.6% | time=1009.7ms | Valid: loss=0.973, acc= 67.6% | *\n",
            "Epoch  42 | Train: loss=0.641, acc= 77.5% | time=1008.8ms | Valid: loss=0.974, acc= 67.6% |\n",
            "Epoch  43 | Train: loss=0.646, acc= 77.1% | time=1008.1ms | Valid: loss=1.013, acc= 68.0% |\n",
            "Epoch  44 | Train: loss=0.652, acc= 77.5% | time=1003.3ms | Valid: loss=1.020, acc= 68.0% |\n",
            "Epoch  45 | Train: loss=0.643, acc= 77.6% | time=1003.6ms | Valid: loss=1.005, acc= 66.0% |\n",
            "Epoch  46 | Train: loss=0.644, acc= 77.9% | time=1002.3ms | Valid: loss=1.004, acc= 68.8% |\n",
            "Epoch  47 | Train: loss=0.634, acc= 77.9% | time=1004.3ms | Valid: loss=1.023, acc= 68.0% | lr=1.3e-03\n",
            "Epoch  48 | Train: loss=0.630, acc= 77.9% | time=1004.0ms | Valid: loss=1.005, acc= 68.0% |\n",
            "Epoch  49 | Train: loss=0.628, acc= 78.4% | time=1002.8ms | Valid: loss=0.999, acc= 68.8% |\n",
            "Epoch  50 | Train: loss=0.634, acc= 78.4% | time=1004.9ms | Valid: loss=1.003, acc= 67.2% |\n",
            "Epoch  51 | Train: loss=0.643, acc= 77.5% | time=1009.3ms | Valid: loss=0.996, acc= 68.8% |\n",
            "Epoch  52 | Train: loss=0.635, acc= 78.3% | time=1010.8ms | Valid: loss=1.003, acc= 68.4% |\n",
            "Epoch  53 | Train: loss=0.626, acc= 78.7% | time=1006.9ms | Valid: loss=1.002, acc= 66.0% | lr=6.3e-04\n",
            "Epoch  54 | Train: loss=0.633, acc= 78.2% | time=1004.3ms | Valid: loss=0.997, acc= 67.6% |\n",
            "Epoch  55 | Train: loss=0.638, acc= 78.3% | time=1001.9ms | Valid: loss=1.014, acc= 68.4% |\n",
            "Epoch  56 | Train: loss=0.631, acc= 78.4% | time=1000.8ms | Valid: loss=0.994, acc= 68.0% |\n",
            "Epoch  57 | Train: loss=0.629, acc= 78.7% | time=1002.1ms | Valid: loss=1.015, acc= 68.4% |\n",
            "Epoch  58 | Train: loss=0.619, acc= 78.0% | time=1003.3ms | Valid: loss=0.993, acc= 69.6% |\n",
            "Epoch  59 | Train: loss=0.637, acc= 78.1% | time=1002.0ms | Valid: loss=1.015, acc= 68.0% | lr=3.1e-04\n",
            "Epoch  60 | Train: loss=0.642, acc= 77.9% | time=1002.8ms | Valid: loss=0.990, acc= 68.8% |\n",
            "Epoch  61 | Train: loss=0.627, acc= 78.2% | time=1005.6ms | Valid: loss=0.991, acc= 68.0% |\n",
            "Epoch  62 | Train: loss=0.626, acc= 78.6% | time=1007.6ms | Valid: loss=1.011, acc= 68.4% |\n",
            "Epoch  63 | Train: loss=0.626, acc= 78.1% | time=1001.9ms | Valid: loss=1.009, acc= 70.4% |\n",
            "Epoch  64 | Train: loss=0.625, acc= 78.3% | time=1010.1ms | Valid: loss=0.983, acc= 68.4% |\n",
            "Epoch  65 | Train: loss=0.633, acc= 77.7% | time=1003.5ms | Valid: loss=1.047, acc= 65.6% | lr=1.6e-04\n",
            "Epoch  66 | Train: loss=0.629, acc= 78.3% | time=1014.1ms | Valid: loss=0.994, acc= 70.4% |\n",
            "Epoch  67 | Train: loss=0.633, acc= 78.0% | time=1004.9ms | Valid: loss=1.002, acc= 67.2% |\n",
            "Epoch  68 | Train: loss=0.626, acc= 78.8% | time=1007.7ms | Valid: loss=1.036, acc= 69.6% |\n",
            "Epoch  69 | Train: loss=0.626, acc= 78.5% | time=1006.1ms | Valid: loss=1.051, acc= 66.4% |\n",
            "Epoch  70 | Train: loss=0.629, acc= 78.1% | time=1008.3ms | Valid: loss=0.999, acc= 67.6% |\n",
            "Epoch  71 | Train: loss=0.629, acc= 78.1% | time=1007.5ms | Valid: loss=1.035, acc= 68.4% | lr=7.8e-05\n",
            "Epoch  72 | Train: loss=0.627, acc= 78.6% | time=1004.3ms | Valid: loss=1.025, acc= 68.0% |\n",
            "Epoch  73 | Train: loss=0.627, acc= 78.1% | time=1012.1ms | Valid: loss=1.008, acc= 68.8% |\n",
            "Epoch  74 | Train: loss=0.632, acc= 78.2% | time=1009.9ms | Valid: loss=1.024, acc= 68.4% |\n",
            "Epoch  75 | Train: loss=0.630, acc= 78.5% | time=1010.1ms | Valid: loss=0.996, acc= 68.4% |\n",
            "Epoch  76 | Train: loss=0.637, acc= 78.0% | time=1009.0ms | Valid: loss=1.019, acc= 66.4% |\n",
            "Epoch  77 | Train: loss=0.633, acc= 77.6% | time=1009.5ms | Valid: loss=1.028, acc= 69.2% | lr=3.9e-05\n",
            "Epoch  78 | Train: loss=0.623, acc= 78.6% | time=1003.3ms | Valid: loss=1.021, acc= 68.8% |\n",
            "Epoch  79 | Train: loss=0.627, acc= 78.3% | time=1010.4ms | Valid: loss=0.974, acc= 70.0% |\n",
            "Epoch  80 | Train: loss=0.629, acc= 78.3% | time=1004.4ms | Valid: loss=1.012, acc= 67.6% |\n",
            "Epoch  81 | Train: loss=0.632, acc= 78.1% | time=1014.5ms | Valid: loss=1.019, acc= 68.0% |\n",
            "Epoch  82 | Train: loss=0.624, acc= 78.7% | time=1004.7ms | Valid: loss=1.048, acc= 66.4% |\n",
            "Epoch  83 | Train: loss=0.624, acc= 78.5% | time=1013.8ms | Valid: loss=1.065, acc= 66.4% | lr=2.0e-05\n",
            "Epoch  84 | Train: loss=0.629, acc= 78.1% | time=1013.0ms | Valid: loss=1.028, acc= 66.8% |\n",
            "Epoch  85 | Train: loss=0.622, acc= 78.7% | time=1011.4ms | Valid: loss=1.037, acc= 67.6% |\n",
            "Epoch  86 | Train: loss=0.625, acc= 78.0% | time=1010.1ms | Valid: loss=0.993, acc= 68.4% |\n",
            "Epoch  87 | Train: loss=0.636, acc= 77.9% | time=1009.0ms | Valid: loss=0.991, acc= 68.0% |\n",
            "Epoch  88 | Train: loss=0.633, acc= 78.4% | time=1008.8ms | Valid: loss=1.016, acc= 67.2% |\n",
            "Epoch  89 | Train: loss=0.620, acc= 78.7% | time=1011.7ms | Valid: loss=1.005, acc= 66.4% | lr=9.8e-06\n",
            "Test: loss=0.869 , acc= 69.3%\n",
            "------------------------------\n",
            "Representation Matrix\n",
            "------------------------------\n",
            "Layer 1 : (48, 20184)\n",
            "Layer 2 : (576, 14400)\n",
            "Layer 3 : (512, 2500)\n",
            "Layer 4 : (1024, 125)\n",
            "Layer 5 : (2048, 125)\n",
            "------------------------------\n",
            "Threshold:  [0.991 0.991 0.991 0.991 0.991]\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 16/48\n",
            "Layer 2 : 323/576\n",
            "Layer 3 : 415/512\n",
            "Layer 4 : 594/1024\n",
            "Layer 5 : 788/2048\n",
            "----------------------------------------\n",
            "Accuracies =\n",
            "\t 78.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 77.6%  68.1%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 77.3%  68.8%  71.9%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 75.8%  68.5%  72.5%  71.4%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 76.4%  69.6%  71.0%  71.5%  75.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 76.6%  68.6%  71.9%  71.8%  74.5%  70.7%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 76.9%  67.6%  73.4%  71.2%  74.3%  70.5%  68.2%   0.0%   0.0%   0.0% \n",
            "\t 77.5%  68.1%  71.6%  70.9%  75.0%  70.4%  68.9%  70.8%   0.0%   0.0% \n",
            "****************************************************************************************************\n",
            "Task  8 (cifar100-8)\n",
            "****************************************************************************************************\n",
            "----------------------------------------\n",
            "Task ID :8 | Learning Rate : 0.01\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([48, 48])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([576, 576])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([512, 512])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([1024, 1024])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([2048, 2048])\n",
            "----------------------------------------\n",
            "Epoch   1 | Train: loss=1.146, acc= 62.2% | time=1008.3ms | Valid: loss=1.278, acc= 56.4% | *\n",
            "Epoch   2 | Train: loss=1.066, acc= 64.2% | time=1003.5ms | Valid: loss=1.235, acc= 56.8% | *\n",
            "Epoch   3 | Train: loss=0.964, acc= 67.9% | time=1004.0ms | Valid: loss=1.198, acc= 60.4% | *\n",
            "Epoch   4 | Train: loss=0.942, acc= 68.1% | time=1006.4ms | Valid: loss=1.166, acc= 60.0% | *\n",
            "Epoch   5 | Train: loss=0.924, acc= 68.8% | time=1001.5ms | Valid: loss=1.180, acc= 60.4% |\n",
            "Epoch   6 | Train: loss=0.880, acc= 70.5% | time=1004.4ms | Valid: loss=1.168, acc= 63.2% |\n",
            "Epoch   7 | Train: loss=0.868, acc= 70.8% | time=1005.2ms | Valid: loss=1.130, acc= 61.6% | *\n",
            "Epoch   8 | Train: loss=0.868, acc= 70.8% | time=1010.0ms | Valid: loss=1.159, acc= 62.4% |\n",
            "Epoch   9 | Train: loss=0.809, acc= 73.1% | time=1007.4ms | Valid: loss=1.094, acc= 62.0% | *\n",
            "Epoch  10 | Train: loss=0.799, acc= 73.3% | time=1005.2ms | Valid: loss=1.111, acc= 62.0% |\n",
            "Epoch  11 | Train: loss=0.772, acc= 74.8% | time=1006.6ms | Valid: loss=1.072, acc= 64.0% | *\n",
            "Epoch  12 | Train: loss=0.783, acc= 73.8% | time=1011.1ms | Valid: loss=1.095, acc= 64.8% |\n",
            "Epoch  13 | Train: loss=0.742, acc= 75.0% | time=1015.2ms | Valid: loss=1.023, acc= 67.2% | *\n",
            "Epoch  14 | Train: loss=0.758, acc= 74.6% | time=1016.7ms | Valid: loss=1.057, acc= 66.4% |\n",
            "Epoch  15 | Train: loss=0.748, acc= 75.1% | time=1020.8ms | Valid: loss=1.093, acc= 63.6% |\n",
            "Epoch  16 | Train: loss=0.739, acc= 76.2% | time=1020.4ms | Valid: loss=1.099, acc= 65.2% |\n",
            "Epoch  17 | Train: loss=0.715, acc= 75.7% | time=1022.2ms | Valid: loss=1.083, acc= 63.6% |\n",
            "Epoch  18 | Train: loss=0.704, acc= 76.1% | time=1027.2ms | Valid: loss=1.037, acc= 68.0% |\n",
            "Epoch  19 | Train: loss=0.690, acc= 76.9% | time=1019.2ms | Valid: loss=1.054, acc= 67.6% | lr=5.0e-03\n",
            "Epoch  20 | Train: loss=0.689, acc= 76.9% | time=1023.5ms | Valid: loss=1.061, acc= 64.0% |\n",
            "Epoch  21 | Train: loss=0.673, acc= 77.5% | time=1021.6ms | Valid: loss=1.084, acc= 65.2% |\n",
            "Epoch  22 | Train: loss=0.678, acc= 77.7% | time=1022.0ms | Valid: loss=1.072, acc= 66.0% |\n",
            "Epoch  23 | Train: loss=0.670, acc= 77.2% | time=1020.9ms | Valid: loss=1.046, acc= 66.8% |\n",
            "Epoch  24 | Train: loss=0.660, acc= 78.3% | time=1019.7ms | Valid: loss=1.031, acc= 65.6% |\n",
            "Epoch  25 | Train: loss=0.668, acc= 77.7% | time=1017.0ms | Valid: loss=1.076, acc= 66.4% | lr=2.5e-03\n",
            "Epoch  26 | Train: loss=0.651, acc= 78.2% | time=1017.6ms | Valid: loss=1.042, acc= 65.6% |\n",
            "Epoch  27 | Train: loss=0.661, acc= 77.7% | time=1020.4ms | Valid: loss=1.045, acc= 66.4% |\n",
            "Epoch  28 | Train: loss=0.641, acc= 78.4% | time=1013.5ms | Valid: loss=1.012, acc= 67.6% | *\n",
            "Epoch  29 | Train: loss=0.646, acc= 78.7% | time=1013.8ms | Valid: loss=1.095, acc= 62.8% |\n",
            "Epoch  30 | Train: loss=0.638, acc= 79.2% | time=1014.2ms | Valid: loss=1.031, acc= 67.2% |\n",
            "Epoch  31 | Train: loss=0.651, acc= 77.8% | time=1009.4ms | Valid: loss=1.062, acc= 68.4% |\n",
            "Epoch  32 | Train: loss=0.637, acc= 79.2% | time=1011.6ms | Valid: loss=1.034, acc= 64.8% |\n",
            "Epoch  33 | Train: loss=0.635, acc= 79.0% | time=1014.4ms | Valid: loss=1.062, acc= 65.2% |\n",
            "Epoch  34 | Train: loss=0.634, acc= 78.6% | time=1011.5ms | Valid: loss=1.014, acc= 66.8% | lr=1.3e-03\n",
            "Epoch  35 | Train: loss=0.643, acc= 78.4% | time=1023.9ms | Valid: loss=1.081, acc= 64.4% |\n",
            "Epoch  36 | Train: loss=0.627, acc= 78.7% | time=1010.7ms | Valid: loss=1.037, acc= 66.8% |\n",
            "Epoch  37 | Train: loss=0.631, acc= 78.7% | time=1015.8ms | Valid: loss=1.039, acc= 64.4% |\n",
            "Epoch  38 | Train: loss=0.637, acc= 78.5% | time=1008.3ms | Valid: loss=1.029, acc= 66.4% |\n",
            "Epoch  39 | Train: loss=0.635, acc= 78.8% | time=1015.5ms | Valid: loss=1.032, acc= 68.4% |\n",
            "Epoch  40 | Train: loss=0.625, acc= 78.7% | time=1004.7ms | Valid: loss=1.019, acc= 67.2% | lr=6.3e-04\n",
            "Epoch  41 | Train: loss=0.627, acc= 79.1% | time=1006.7ms | Valid: loss=1.020, acc= 66.8% |\n",
            "Epoch  42 | Train: loss=0.627, acc= 79.0% | time=1004.7ms | Valid: loss=1.036, acc= 66.0% |\n",
            "Epoch  43 | Train: loss=0.636, acc= 78.4% | time=1009.0ms | Valid: loss=1.000, acc= 67.6% | *\n",
            "Epoch  44 | Train: loss=0.634, acc= 78.8% | time=1007.9ms | Valid: loss=1.031, acc= 66.0% |\n",
            "Epoch  45 | Train: loss=0.632, acc= 78.7% | time=1107.0ms | Valid: loss=1.055, acc= 67.2% |\n",
            "Epoch  46 | Train: loss=0.623, acc= 79.0% | time=1002.4ms | Valid: loss=1.036, acc= 66.4% |\n",
            "Epoch  47 | Train: loss=0.627, acc= 79.0% | time=1000.7ms | Valid: loss=1.018, acc= 64.0% |\n",
            "Epoch  48 | Train: loss=0.625, acc= 79.3% | time=1007.2ms | Valid: loss=1.052, acc= 62.4% |\n",
            "Epoch  49 | Train: loss=0.626, acc= 79.3% | time=1008.0ms | Valid: loss=1.051, acc= 64.8% | lr=3.1e-04\n",
            "Epoch  50 | Train: loss=0.617, acc= 79.5% | time=1004.4ms | Valid: loss=1.053, acc= 66.8% |\n",
            "Epoch  51 | Train: loss=0.623, acc= 79.4% | time=1006.7ms | Valid: loss=1.023, acc= 69.6% |\n",
            "Epoch  52 | Train: loss=0.617, acc= 79.2% | time=1058.1ms | Valid: loss=1.033, acc= 66.4% |\n",
            "Epoch  53 | Train: loss=0.617, acc= 79.0% | time=1008.0ms | Valid: loss=1.021, acc= 64.8% |\n",
            "Epoch  54 | Train: loss=0.618, acc= 79.2% | time=1001.8ms | Valid: loss=1.017, acc= 66.8% |\n",
            "Epoch  55 | Train: loss=0.626, acc= 79.2% | time=1005.0ms | Valid: loss=1.041, acc= 66.4% | lr=1.6e-04\n",
            "Epoch  56 | Train: loss=0.616, acc= 79.0% | time=1011.8ms | Valid: loss=1.021, acc= 66.0% |\n",
            "Epoch  57 | Train: loss=0.616, acc= 79.2% | time=1008.8ms | Valid: loss=1.051, acc= 67.2% |\n",
            "Epoch  58 | Train: loss=0.615, acc= 79.3% | time=1002.4ms | Valid: loss=1.024, acc= 66.0% |\n",
            "Epoch  59 | Train: loss=0.618, acc= 79.7% | time=1002.7ms | Valid: loss=0.997, acc= 67.2% | *\n",
            "Epoch  60 | Train: loss=0.617, acc= 79.6% | time=999.2ms | Valid: loss=1.048, acc= 64.4% |\n",
            "Epoch  61 | Train: loss=0.619, acc= 79.3% | time=1001.5ms | Valid: loss=1.055, acc= 66.0% |\n",
            "Epoch  62 | Train: loss=0.618, acc= 78.9% | time=1005.1ms | Valid: loss=1.047, acc= 66.4% |\n",
            "Epoch  63 | Train: loss=0.628, acc= 79.4% | time=1003.3ms | Valid: loss=1.043, acc= 68.0% |\n",
            "Epoch  64 | Train: loss=0.620, acc= 79.5% | time=1005.2ms | Valid: loss=1.061, acc= 68.4% |\n",
            "Epoch  65 | Train: loss=0.622, acc= 79.0% | time=1011.7ms | Valid: loss=0.985, acc= 67.2% | *\n",
            "Epoch  66 | Train: loss=0.616, acc= 79.0% | time=1010.5ms | Valid: loss=1.047, acc= 66.8% |\n",
            "Epoch  67 | Train: loss=0.618, acc= 79.1% | time=1005.5ms | Valid: loss=1.003, acc= 67.6% |\n",
            "Epoch  68 | Train: loss=0.614, acc= 79.2% | time=1008.3ms | Valid: loss=1.051, acc= 64.0% |\n",
            "Epoch  69 | Train: loss=0.622, acc= 79.0% | time=1004.0ms | Valid: loss=1.065, acc= 62.8% |\n",
            "Epoch  70 | Train: loss=0.617, acc= 78.8% | time=1003.4ms | Valid: loss=1.029, acc= 67.2% |\n",
            "Epoch  71 | Train: loss=0.615, acc= 79.3% | time=1008.2ms | Valid: loss=1.021, acc= 69.2% | lr=7.8e-05\n",
            "Epoch  72 | Train: loss=0.609, acc= 79.9% | time=1008.2ms | Valid: loss=1.060, acc= 66.4% |\n",
            "Epoch  73 | Train: loss=0.614, acc= 79.3% | time=1016.9ms | Valid: loss=1.051, acc= 65.2% |\n",
            "Epoch  74 | Train: loss=0.622, acc= 79.0% | time=1016.4ms | Valid: loss=1.090, acc= 67.2% |\n",
            "Epoch  75 | Train: loss=0.617, acc= 79.1% | time=1007.7ms | Valid: loss=1.063, acc= 66.4% |\n",
            "Epoch  76 | Train: loss=0.624, acc= 79.1% | time=1004.4ms | Valid: loss=1.067, acc= 65.2% |\n",
            "Epoch  77 | Train: loss=0.619, acc= 79.3% | time=1010.1ms | Valid: loss=0.996, acc= 67.6% | lr=3.9e-05\n",
            "Epoch  78 | Train: loss=0.618, acc= 79.3% | time=1013.9ms | Valid: loss=1.021, acc= 68.0% |\n",
            "Epoch  79 | Train: loss=0.615, acc= 79.3% | time=1012.0ms | Valid: loss=1.070, acc= 66.8% |\n",
            "Epoch  80 | Train: loss=0.614, acc= 79.3% | time=1015.6ms | Valid: loss=1.047, acc= 65.6% |\n",
            "Epoch  81 | Train: loss=0.614, acc= 79.5% | time=1016.5ms | Valid: loss=1.090, acc= 66.4% |\n",
            "Epoch  82 | Train: loss=0.615, acc= 79.6% | time=1010.0ms | Valid: loss=1.044, acc= 66.4% |\n",
            "Epoch  83 | Train: loss=0.616, acc= 79.4% | time=1007.8ms | Valid: loss=1.058, acc= 66.8% | lr=2.0e-05\n",
            "Epoch  84 | Train: loss=0.613, acc= 79.0% | time=1013.4ms | Valid: loss=1.027, acc= 66.8% |\n",
            "Epoch  85 | Train: loss=0.624, acc= 79.5% | time=1017.1ms | Valid: loss=1.029, acc= 66.0% |\n",
            "Epoch  86 | Train: loss=0.613, acc= 79.4% | time=1009.1ms | Valid: loss=1.013, acc= 68.0% |\n",
            "Epoch  87 | Train: loss=0.615, acc= 79.4% | time=1005.4ms | Valid: loss=1.038, acc= 66.4% |\n",
            "Epoch  88 | Train: loss=0.618, acc= 79.2% | time=1013.4ms | Valid: loss=1.049, acc= 68.0% |\n",
            "Epoch  89 | Train: loss=0.617, acc= 79.2% | time=1012.9ms | Valid: loss=1.055, acc= 65.6% | lr=9.8e-06\n",
            "Test: loss=0.852 , acc= 71.8%\n",
            "------------------------------\n",
            "Representation Matrix\n",
            "------------------------------\n",
            "Layer 1 : (48, 20184)\n",
            "Layer 2 : (576, 14400)\n",
            "Layer 3 : (512, 2500)\n",
            "Layer 4 : (1024, 125)\n",
            "Layer 5 : (2048, 125)\n",
            "------------------------------\n",
            "Threshold:  [0.994 0.994 0.994 0.994 0.994]\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 20/48\n",
            "Layer 2 : 384/576\n",
            "Layer 3 : 449/512\n",
            "Layer 4 : 678/1024\n",
            "Layer 5 : 898/2048\n",
            "----------------------------------------\n",
            "Accuracies =\n",
            "\t 78.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 77.6%  68.1%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 77.3%  68.8%  71.9%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 75.8%  68.5%  72.5%  71.4%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 76.4%  69.6%  71.0%  71.5%  75.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 76.6%  68.6%  71.9%  71.8%  74.5%  70.7%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 76.9%  67.6%  73.4%  71.2%  74.3%  70.5%  68.2%   0.0%   0.0%   0.0% \n",
            "\t 77.5%  68.1%  71.6%  70.9%  75.0%  70.4%  68.9%  70.8%   0.0%   0.0% \n",
            "\t 77.0%  69.2%  70.0%  70.5%  74.0%  69.4%  68.0%  70.5%  70.4%   0.0% \n",
            "****************************************************************************************************\n",
            "Task  9 (cifar100-9)\n",
            "****************************************************************************************************\n",
            "----------------------------------------\n",
            "Task ID :9 | Learning Rate : 0.01\n",
            "----------------------------------------\n",
            "Layer 1 - Projection Matrix shape: torch.Size([48, 48])\n",
            "Layer 2 - Projection Matrix shape: torch.Size([576, 576])\n",
            "Layer 3 - Projection Matrix shape: torch.Size([512, 512])\n",
            "Layer 4 - Projection Matrix shape: torch.Size([1024, 1024])\n",
            "Layer 5 - Projection Matrix shape: torch.Size([2048, 2048])\n",
            "----------------------------------------\n",
            "Epoch   1 | Train: loss=1.013, acc= 66.6% | time=1006.4ms | Valid: loss=1.091, acc= 64.8% | *\n",
            "Epoch   2 | Train: loss=0.891, acc= 69.9% | time=1003.4ms | Valid: loss=1.004, acc= 65.2% | *\n",
            "Epoch   3 | Train: loss=0.855, acc= 71.0% | time=1009.1ms | Valid: loss=0.928, acc= 71.2% | *\n",
            "Epoch   4 | Train: loss=0.826, acc= 72.4% | time=1001.5ms | Valid: loss=0.926, acc= 69.2% | *\n",
            "Epoch   5 | Train: loss=0.785, acc= 73.9% | time=1003.3ms | Valid: loss=0.893, acc= 71.6% | *\n",
            "Epoch   6 | Train: loss=0.790, acc= 74.1% | time=1005.6ms | Valid: loss=0.931, acc= 69.6% |\n",
            "Epoch   7 | Train: loss=0.743, acc= 75.3% | time=1006.2ms | Valid: loss=0.886, acc= 72.4% | *\n",
            "Epoch   8 | Train: loss=0.741, acc= 75.3% | time=1002.0ms | Valid: loss=0.921, acc= 70.0% |\n",
            "Epoch   9 | Train: loss=0.734, acc= 75.3% | time=1010.7ms | Valid: loss=0.907, acc= 69.6% |\n",
            "Epoch  10 | Train: loss=0.726, acc= 75.5% | time=1008.0ms | Valid: loss=0.907, acc= 73.2% |\n",
            "Epoch  11 | Train: loss=0.712, acc= 76.5% | time=1008.9ms | Valid: loss=0.896, acc= 71.2% |\n",
            "Epoch  12 | Train: loss=0.695, acc= 77.1% | time=1011.8ms | Valid: loss=0.886, acc= 72.8% | *\n",
            "Epoch  13 | Train: loss=0.671, acc= 78.0% | time=1007.0ms | Valid: loss=0.851, acc= 74.8% | *\n",
            "Epoch  14 | Train: loss=0.661, acc= 78.1% | time=1019.6ms | Valid: loss=0.869, acc= 74.0% |\n",
            "Epoch  15 | Train: loss=0.671, acc= 77.3% | time=1015.4ms | Valid: loss=0.885, acc= 74.0% |\n",
            "Epoch  16 | Train: loss=0.668, acc= 77.6% | time=1022.3ms | Valid: loss=0.897, acc= 70.8% |\n",
            "Epoch  17 | Train: loss=0.628, acc= 79.2% | time=1021.4ms | Valid: loss=0.840, acc= 74.4% | *\n",
            "Epoch  18 | Train: loss=0.638, acc= 79.2% | time=1024.5ms | Valid: loss=0.898, acc= 72.8% |\n",
            "Epoch  19 | Train: loss=0.639, acc= 78.5% | time=1030.6ms | Valid: loss=0.938, acc= 71.2% |\n",
            "Epoch  20 | Train: loss=0.609, acc= 79.8% | time=1029.6ms | Valid: loss=0.839, acc= 74.8% | *\n",
            "Epoch  21 | Train: loss=0.621, acc= 79.0% | time=1020.7ms | Valid: loss=0.868, acc= 73.6% |\n",
            "Epoch  22 | Train: loss=0.613, acc= 79.9% | time=1024.0ms | Valid: loss=0.841, acc= 74.0% |\n",
            "Epoch  23 | Train: loss=0.597, acc= 80.1% | time=1028.7ms | Valid: loss=0.838, acc= 73.6% | *\n",
            "Epoch  24 | Train: loss=0.582, acc= 80.2% | time=1024.0ms | Valid: loss=0.875, acc= 74.0% |\n",
            "Epoch  25 | Train: loss=0.597, acc= 80.0% | time=1022.0ms | Valid: loss=0.847, acc= 72.4% |\n",
            "Epoch  26 | Train: loss=0.578, acc= 80.6% | time=1018.3ms | Valid: loss=0.853, acc= 74.8% |\n",
            "Epoch  27 | Train: loss=0.592, acc= 80.0% | time=1014.2ms | Valid: loss=0.869, acc= 71.2% |\n",
            "Epoch  28 | Train: loss=0.573, acc= 80.5% | time=1018.1ms | Valid: loss=0.869, acc= 73.2% |\n",
            "Epoch  29 | Train: loss=0.568, acc= 80.9% | time=1014.3ms | Valid: loss=0.835, acc= 72.8% | *\n",
            "Epoch  30 | Train: loss=0.561, acc= 81.0% | time=1012.5ms | Valid: loss=0.846, acc= 73.6% |\n",
            "Epoch  31 | Train: loss=0.543, acc= 81.7% | time=1014.2ms | Valid: loss=0.815, acc= 73.2% | *\n",
            "Epoch  32 | Train: loss=0.541, acc= 82.4% | time=1014.8ms | Valid: loss=0.835, acc= 73.2% |\n",
            "Epoch  33 | Train: loss=0.533, acc= 82.4% | time=1015.5ms | Valid: loss=0.803, acc= 75.2% | *\n",
            "Epoch  34 | Train: loss=0.529, acc= 82.4% | time=1006.4ms | Valid: loss=0.861, acc= 73.6% |\n",
            "Epoch  35 | Train: loss=0.528, acc= 81.9% | time=1013.8ms | Valid: loss=0.848, acc= 74.0% |\n",
            "Epoch  36 | Train: loss=0.551, acc= 81.4% | time=1008.1ms | Valid: loss=0.822, acc= 74.8% |\n",
            "Epoch  37 | Train: loss=0.519, acc= 82.4% | time=1011.1ms | Valid: loss=0.782, acc= 74.0% | *\n",
            "Epoch  38 | Train: loss=0.541, acc= 81.4% | time=1008.6ms | Valid: loss=0.879, acc= 74.8% |\n",
            "Epoch  39 | Train: loss=0.507, acc= 83.0% | time=1012.7ms | Valid: loss=0.832, acc= 74.0% |\n",
            "Epoch  40 | Train: loss=0.493, acc= 83.5% | time=1008.8ms | Valid: loss=0.822, acc= 76.0% |\n",
            "Epoch  41 | Train: loss=0.528, acc= 82.1% | time=1008.1ms | Valid: loss=0.891, acc= 73.6% |\n",
            "Epoch  42 | Train: loss=0.486, acc= 83.6% | time=1007.5ms | Valid: loss=0.797, acc= 76.8% |\n",
            "Epoch  43 | Train: loss=0.483, acc= 83.5% | time=1005.9ms | Valid: loss=0.845, acc= 74.4% | lr=5.0e-03\n",
            "Epoch  44 | Train: loss=0.492, acc= 83.4% | time=1014.6ms | Valid: loss=0.863, acc= 75.6% |\n",
            "Epoch  45 | Train: loss=0.477, acc= 83.7% | time=1001.6ms | Valid: loss=0.802, acc= 76.0% |\n",
            "Epoch  46 | Train: loss=0.466, acc= 84.3% | time=1027.2ms | Valid: loss=0.811, acc= 74.8% |\n",
            "Epoch  47 | Train: loss=0.463, acc= 84.3% | time=1009.1ms | Valid: loss=0.796, acc= 76.8% |\n",
            "Epoch  48 | Train: loss=0.470, acc= 84.2% | time=1007.9ms | Valid: loss=0.814, acc= 77.6% |\n",
            "Epoch  49 | Train: loss=0.467, acc= 84.5% | time=1003.5ms | Valid: loss=0.807, acc= 76.4% | lr=2.5e-03\n",
            "Epoch  50 | Train: loss=0.468, acc= 84.5% | time=1004.5ms | Valid: loss=0.806, acc= 74.4% |\n",
            "Epoch  51 | Train: loss=0.469, acc= 83.9% | time=1004.7ms | Valid: loss=0.825, acc= 73.6% |\n",
            "Epoch  52 | Train: loss=0.470, acc= 83.9% | time=1010.0ms | Valid: loss=0.827, acc= 75.6% |\n",
            "Epoch  53 | Train: loss=0.460, acc= 84.6% | time=1003.4ms | Valid: loss=0.852, acc= 77.2% |\n",
            "Epoch  54 | Train: loss=0.470, acc= 84.1% | time=1007.6ms | Valid: loss=0.865, acc= 74.8% |\n",
            "Epoch  55 | Train: loss=0.462, acc= 84.4% | time=1002.7ms | Valid: loss=0.794, acc= 76.8% | lr=1.3e-03\n",
            "Epoch  56 | Train: loss=0.450, acc= 84.9% | time=1009.3ms | Valid: loss=0.833, acc= 75.6% |\n",
            "Epoch  57 | Train: loss=0.463, acc= 84.0% | time=1009.2ms | Valid: loss=0.875, acc= 74.8% |\n",
            "Epoch  58 | Train: loss=0.454, acc= 85.1% | time=1009.8ms | Valid: loss=0.817, acc= 75.2% |\n",
            "Epoch  59 | Train: loss=0.457, acc= 84.6% | time=1008.0ms | Valid: loss=0.840, acc= 75.2% |\n",
            "Epoch  60 | Train: loss=0.456, acc= 84.9% | time=1008.6ms | Valid: loss=0.831, acc= 76.8% |\n",
            "Epoch  61 | Train: loss=0.459, acc= 84.6% | time=1013.1ms | Valid: loss=0.844, acc= 75.6% | lr=6.3e-04\n",
            "Epoch  62 | Train: loss=0.462, acc= 84.1% | time=1004.2ms | Valid: loss=0.824, acc= 77.2% |\n",
            "Epoch  63 | Train: loss=0.458, acc= 84.5% | time=1004.2ms | Valid: loss=0.826, acc= 74.4% |\n",
            "Epoch  64 | Train: loss=0.447, acc= 85.0% | time=1002.9ms | Valid: loss=0.855, acc= 75.2% |\n",
            "Epoch  65 | Train: loss=0.456, acc= 84.6% | time=1009.7ms | Valid: loss=0.828, acc= 77.2% |\n",
            "Epoch  66 | Train: loss=0.456, acc= 84.6% | time=1008.9ms | Valid: loss=0.823, acc= 76.0% |\n",
            "Epoch  67 | Train: loss=0.467, acc= 84.6% | time=1009.4ms | Valid: loss=0.840, acc= 75.2% | lr=3.1e-04\n",
            "Epoch  68 | Train: loss=0.451, acc= 84.7% | time=1009.5ms | Valid: loss=0.819, acc= 76.0% |\n",
            "Epoch  69 | Train: loss=0.455, acc= 85.1% | time=1005.8ms | Valid: loss=0.808, acc= 76.4% |\n",
            "Epoch  70 | Train: loss=0.453, acc= 85.0% | time=1011.8ms | Valid: loss=0.827, acc= 74.4% |\n",
            "Epoch  71 | Train: loss=0.453, acc= 84.7% | time=1011.4ms | Valid: loss=0.833, acc= 76.0% |\n",
            "Epoch  72 | Train: loss=0.451, acc= 84.6% | time=1008.4ms | Valid: loss=0.815, acc= 76.4% |\n",
            "Epoch  73 | Train: loss=0.459, acc= 84.6% | time=1002.7ms | Valid: loss=0.871, acc= 74.4% | lr=1.6e-04\n",
            "Epoch  74 | Train: loss=0.455, acc= 84.4% | time=1004.2ms | Valid: loss=0.848, acc= 74.8% |\n",
            "Epoch  75 | Train: loss=0.452, acc= 84.9% | time=1004.0ms | Valid: loss=0.801, acc= 76.0% |\n",
            "Epoch  76 | Train: loss=0.455, acc= 84.5% | time=1005.4ms | Valid: loss=0.832, acc= 75.6% |\n",
            "Epoch  77 | Train: loss=0.462, acc= 84.4% | time=1010.1ms | Valid: loss=0.853, acc= 76.4% |\n",
            "Epoch  78 | Train: loss=0.454, acc= 84.4% | time=1010.1ms | Valid: loss=0.822, acc= 76.8% |\n",
            "Epoch  79 | Train: loss=0.459, acc= 84.6% | time=1017.6ms | Valid: loss=0.824, acc= 76.0% | lr=7.8e-05\n",
            "Epoch  80 | Train: loss=0.459, acc= 84.6% | time=1013.5ms | Valid: loss=0.816, acc= 77.6% |\n",
            "Epoch  81 | Train: loss=0.459, acc= 84.7% | time=1013.3ms | Valid: loss=0.811, acc= 77.6% |\n",
            "Epoch  82 | Train: loss=0.448, acc= 85.0% | time=1004.1ms | Valid: loss=0.844, acc= 76.0% |\n",
            "Epoch  83 | Train: loss=0.457, acc= 84.4% | time=1010.7ms | Valid: loss=0.775, acc= 74.4% | *\n",
            "Epoch  84 | Train: loss=0.451, acc= 84.6% | time=1009.7ms | Valid: loss=0.808, acc= 76.8% |\n",
            "Epoch  85 | Train: loss=0.452, acc= 84.7% | time=1012.2ms | Valid: loss=0.831, acc= 75.6% |\n",
            "Epoch  86 | Train: loss=0.448, acc= 84.6% | time=1005.8ms | Valid: loss=0.818, acc= 76.4% |\n",
            "Epoch  87 | Train: loss=0.449, acc= 84.6% | time=1008.1ms | Valid: loss=0.842, acc= 74.8% |\n",
            "Epoch  88 | Train: loss=0.458, acc= 84.2% | time=1008.8ms | Valid: loss=0.855, acc= 74.8% |\n",
            "Epoch  89 | Train: loss=0.454, acc= 84.6% | time=1008.7ms | Valid: loss=0.844, acc= 74.4% | lr=3.9e-05\n",
            "Epoch  90 | Train: loss=0.450, acc= 84.7% | time=1007.9ms | Valid: loss=0.798, acc= 75.6% |\n",
            "Epoch  91 | Train: loss=0.449, acc= 84.7% | time=1008.1ms | Valid: loss=0.830, acc= 72.4% |\n",
            "Epoch  92 | Train: loss=0.450, acc= 85.0% | time=1010.2ms | Valid: loss=0.819, acc= 75.2% |\n",
            "Epoch  93 | Train: loss=0.452, acc= 84.6% | time=1010.1ms | Valid: loss=0.900, acc= 74.0% |\n",
            "Epoch  94 | Train: loss=0.462, acc= 84.1% | time=1010.9ms | Valid: loss=0.818, acc= 75.2% |\n",
            "Epoch  95 | Train: loss=0.455, acc= 84.7% | time=1012.1ms | Valid: loss=0.836, acc= 72.4% | lr=2.0e-05\n",
            "Epoch  96 | Train: loss=0.449, acc= 84.7% | time=1166.3ms | Valid: loss=0.870, acc= 75.6% |\n",
            "Epoch  97 | Train: loss=0.457, acc= 84.5% | time=1004.9ms | Valid: loss=0.821, acc= 75.2% |\n",
            "Epoch  98 | Train: loss=0.450, acc= 85.0% | time=1010.4ms | Valid: loss=0.838, acc= 74.8% |\n",
            "Epoch  99 | Train: loss=0.457, acc= 84.5% | time=1006.8ms | Valid: loss=0.784, acc= 76.0% |\n",
            "Epoch 100 | Train: loss=0.452, acc= 84.4% | time=1012.9ms | Valid: loss=0.843, acc= 76.4% |\n",
            "Epoch 101 | Train: loss=0.456, acc= 84.4% | time=1006.4ms | Valid: loss=0.829, acc= 75.2% | lr=9.8e-06\n",
            "Test: loss=0.763 , acc= 76.2%\n",
            "------------------------------\n",
            "Representation Matrix\n",
            "------------------------------\n",
            "Layer 1 : (48, 20184)\n",
            "Layer 2 : (576, 14400)\n",
            "Layer 3 : (512, 2500)\n",
            "Layer 4 : (1024, 125)\n",
            "Layer 5 : (2048, 125)\n",
            "------------------------------\n",
            "Threshold:  [0.997 0.997 0.997 0.997 0.997]\n",
            "----------------------------------------\n",
            "Gradient Constraints Summary\n",
            "----------------------------------------\n",
            "Layer 1 : 21/48\n",
            "Layer 2 : 430/576\n",
            "Layer 3 : 475/512\n",
            "Layer 4 : 764/1024\n",
            "Layer 5 : 1012/2048\n",
            "----------------------------------------\n",
            "Accuracies =\n",
            "\t 78.2%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 77.6%  68.1%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 77.3%  68.8%  71.9%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 75.8%  68.5%  72.5%  71.4%   0.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 76.4%  69.6%  71.0%  71.5%  75.0%   0.0%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 76.6%  68.6%  71.9%  71.8%  74.5%  70.7%   0.0%   0.0%   0.0%   0.0% \n",
            "\t 76.9%  67.6%  73.4%  71.2%  74.3%  70.5%  68.2%   0.0%   0.0%   0.0% \n",
            "\t 77.5%  68.1%  71.6%  70.9%  75.0%  70.4%  68.9%  70.8%   0.0%   0.0% \n",
            "\t 77.0%  69.2%  70.0%  70.5%  74.0%  69.4%  68.0%  70.5%  70.4%   0.0% \n",
            "\t 76.2%  69.0%  71.8%  71.8%  74.3%  70.3%  71.5%  70.2%  70.4%  75.7% \n",
            "--------------------------------------------------\n",
            "Task Order : [0 1 2 3 4 5 6 7 8 9]\n",
            "Final Avg Accuracy: 72.12%\n",
            "Backward transfer:  0.09%\n",
            "[Elapsed time = 1243414.0 ms]\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wHTGbN-NKU8o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}